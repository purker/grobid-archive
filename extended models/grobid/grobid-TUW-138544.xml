<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Users\Angela\git\grobid\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-12-29T00:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MODELLING OF VISUAL FEATURE DERIVATION IN THE VIZIR FRAMEWORK Horst Eidenberger Institute of Software Technology and Interactive Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology Favoritenstrasse</orgName>
								<address>
									<addrLine>9-11</addrLine>
									<postCode>A-1040</postCode>
									<settlement>Wien</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MODELLING OF VISUAL FEATURE DERIVATION IN THE VIZIR FRAMEWORK Horst Eidenberger Institute of Software Technology and Interactive Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>If visual information retrieval should make further progress, it will be necessary to identify new ways to derive visual properties from higher levels of understanding than the pixel level (e.g. from low-level features). The paper outlines the implementation of modelling of feature hierarchies in the visual information retrieval framework VizIR (free under GPL). The approach allows for the derivation of high-level features from low-level features by aggregation and localisa-tion as well as semantic enrichment with additional knowledge. The technical implementation is based on the MPEG-7 structures for aggregation and specialisation. 1. INTRODUCTION Visual information retrieval (VIR) research is driven by the desire to derive semantically meaningful information directly from the content of media objects. Recent years have seen considerable efforts to overcome the enormous gravity of the pixel and to extract more than just colour histograms, edge information and other low-level features. The MPEG-7 standard [1] supports these efforts in two ways: Firstly, it provides aggregation and localisation structures for spatio-temporal feature enrichment. Secondly, it standardises cookbooks for the most prominent low-level features and, by that, provides a foundation for semantic enrichment of low-level features. Below, we will regard aggregated/localised and semantically enriched as two relevant types of high-level features. The paper describes the way high-level feature structures (e.g. based on MPEG-7 descriptors) can be implemented in the VIR framework VizIR. The VizIR project [2] aims at providing VIR researchers with a workbench of feature extraction , querying and evaluation tools. The paper is organised as follows: Section 2 gives background information on relevant MPEG-7 models and principles of semantic feature design. Section 3 shortly sketches the VizIR project. Section 4 describes the architecture of high-level feature modelling in VizIR. Additionally, Subsection 4.4 covers important implementation aspects.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic feature enrichment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">MPEG-7 aggregation and localisation structures</head><p>The visual part of the MPEG-7 standard (e.g. <ref type="bibr">[4]</ref>) provides a set of content-based descriptors for colour, texture, shape</p><p>As human beings we derive our visual similarity perception from generally perceived (e.g. colour distributions) and spe- cifically perceived (recognized) media properties. Today's VIR systems are only capable of extracting generally per- ceived (low-level) features. Therefore, retrieval results are often unsatisfactory for us. To overcome this shortcoming, considerable research effort is undertaken to enrich low- level features with semantic information.</p><p>Generally, three sources of information are available to enhance features: <ref type="bibr">(1</ref>) information on the application domain (e.g. on media content), (2) information on the user (e.g. re- trieval preferences) and (3) information on the characteristics of the descriptors used (e.g. statistical properties). Techni- cally, additional knowledge can be induced by methods from statistics, artificial intelligence (e.g. neural networks), etc. For example, domain knowledge about football could be used to identify ball and players from shape features (e.g. circularity, edge distribution).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE VIZIR PROJECT</head><p>The next three subsections describe the VizIR project in general and, in greater detail, the environment, in which we are applying descriptor aggregation, localisation and en- richment techniques to enhance features and improve con- tent-based retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The VizIR framework is an open and extendible software workbench for content-based video and image retrieval. It implements state of the art technologies such as the visual MPEG-7 descriptors, the Multimedia Retrieval Markup Language <ref type="bibr">[5]</ref> for loose coupling of query engines and user interfaces, etc. and novel paradigms for feature extraction, querying (e.g. 3D user interfaces for integrated browsing and retrieval) and evaluation.</p><p>VizIR is free software: it is released as source code un- der GNU Public License. The VizIR project intends to pro- vide a common software platform that can be used by re- searchers as a workbench for further VIR research, by soft- ware engineers for the development of VIR components for media and database applications and by lecturers for teaching VIR concepts. The VizIR framework was carefully designed to guarantee that these requirements can be met.</p><p>Technically, the VizIR framework components are based on the Java programming language, the Java SDK, the Java Media Framework for media processing and other freely available software libraries. The current status of the project, software releases, documentation and development resources can be found on the project website <ref type="bibr">[6]</ref>. VizIR is an open project: new users and contributors are always welcome.</p><p>MRML communication classes, the service kernel and para- digms for database access. All VizIR components are based on an object-oriented database model: If desired, the re- sources of instances of any class in the framework can be serialised and kept persistent in a database. This feature is guaranteed by an underlying persistence system. The object- oriented database system may be chosen arbitrarily. In our test environment we are currently using a relational database (MySQL) and an object mapping tool (Hibernate). See <ref type="bibr">[2]</ref> and <ref type="bibr">[3]</ref> for more information on the VizIR architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Visual feature modelling</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">General framework design</head><p>The most important part of VizIR is a class framework for feature extraction, querying, refinement, VIR user inter- faces, communication, evaluation and benchmarking. Cen- tral element is a service kernel. This class is responsible for media administration and query execution. It communicates with query engines, user interfaces and media databases through XML messages (based on the Multimedia Retrieval Markup Language, MRML <ref type="bibr">[5]</ref>) and web services.</p><p>Media access is hidden in a class that enables accessing the view of visual media (at arbitrary resolution and based on an arbitrary colour model) at any point in time. By that, im- ages and videos can be accessed with a uniform API. De- scriptors and media renderer classes make use of the media access class to derive features and to visualise media objects in user interfaces. All elements of user interfaces (including query definition and refinement panels, metadata panels, sketch drawing panels, etc.) are modelled as independent classes that interact with each other through well-defined events and listener methods (locally) or through XML-based web services (remotely). They can be combined arbitrarily to create VIR user interfaces and easily be supplemented by additional querying methods.</p><p>VizIR query engines are derived from a common model. This model defines how queries are executed technically (not how the querying logic works). This includes the interface to Implementation of visual descriptors is a key requirement in the VizIR framework. Descriptor data should be calculated directly from media content and it has to be guaranteed that the descriptor designer does not have to care for storing the descriptor data in the database. VizIR provides two types of classes for the implementation of visual descriptors:</p><p>DescriptorInfo classes DescriptorLogic classes Derivates of DescriptorInfo classes hold the (XML) descrip- tions extracted by features. These classes have a unique name and their objects have unique IDs. Objects can be stored to and read from a database. DescriptorInfo classes are also factories that can be used to create their associated DescriptorLogic objects.</p><p>DescriptorLogic classes contain just two methods: ex- tractFeature() to extract feature data from given media con- tent and calculateDistance() to measure distance to a second instance of the same descriptor (a DescriptorInfo object). Since DescriptorLogic classes contain no relevant status in- formation, they do not need to be made persistent and may have arbitrary names.</p><p>The VizIR framework can easily be extended with new descriptors by creating a new DescriptorInfo class, creating a new mapping (if the default mapping is not sufficient) and implementing a private DescriptorLogic class with the fea- ture extraction logic. New descriptors can be used as soon as the database mapping (an XML document) is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FEATURE DERIVATION MODELLING</head><p>Below, it will be discussed how the described descriptor models can be adapted to allow for feature aggregation, lo- calisation and semantic enrichment. Additionally, in Subsec- tion 4.4 relevant implementation details will be sketched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>Generally, descriptors could simply be added to the frame- work as new classes that make use of already existing algo- rithms. To enable this scenario, the algorithms used in De- scriptorLogic classes (e.g. time to frequency transforma- tions, edge operators) would have to be implemented with a well-designed configurable API and collected in software libraries. Still, for the sake of transparency, good software design and maximum code reuse, it would be desirable to have more sophisticated descriptor extension mechanisms available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DescriptorInfo create DescriptorLogic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DescriptorModel use</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>parameterise</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DescriptorLogicA</head><p>DescriptorLogicB ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic feature enrichment</head><p>Lower-level descriptor Higher-level descriptor Figure 1 describes the general architecture of descriptor design and derivation in the VizIR framework. The left side of the figure shows the data classes. The right side shows the algorithms. The top half shows a low-level descriptor. The bottom half shows a derived descriptor. The design depicted in the figure will be discussed in the next two subsections. Essentially, the idea is that semantically enriched descriptors should be derived from data classes, since they may use completely different algorithms. Aggregated and localised descriptors should be derived from the algorithm classes, because they produce different data classes by using the same or similar algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aggregation / localisation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DescriptorInfo DescriptorLogic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>create</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Feature aggregation and localisation</head><p>In VizIR, descriptors are stored to databases through an ob- ject-oriented mapping technique. Instances of descriptors containing media-specific data are serialised to BLOBs. The BLOBs are referenced by unique IDs (including the class name). For this approach it is necessary that descriptors that create specific output have unique names.</p><p>Unfortunately, for example, in the MPEG-7 standard, visual descriptors can be configured to create different de- scriptions (e.g. Scalable Colour histograms may have 32 or 64 bins). If the descriptor classes creating these descriptions would be of the same name and be configured for specific use (e.g. by getters/setters), incompatible descriptions could not be distinguished in VizIR. Therefore, as a first step for aggregation/localisation it is necessary to find an appropriate solution for descriptor configuration.</p><p>The solution in VizIR, shown in the top right of Figure 1, is straight-forward: The fundamental description procedure is implemented in a DescriptorLogic class. This class may be defined as being abstract. Optionally, the algorithmic details may be laid down in a separate DescriptorModel class (e.g. transformations, visual operators). For parameterisation, the DescriptorLogic class has a constructor with all relevant pa- rameters. To use a specific version of the descriptor it is sub- classed with a default descriptor that calls the super descrip- tor with the desired parameters (e.g. histogram size). Since the sub-class needs to have a unique name, its instances can easily be stored to a database and be distinguished from other versions of the same descriptor.</p><p>The same pattern is used for aggregation and localisa- tion. This feature is implemented as a parameter of type Spa- tio-Temporal Locator <ref type="bibr">(MPEG-7</ref>; in VizIR: a Java class). Then, basically, a spatially and/or temporally specific version of a descriptor is a sub-class of the general descriptor algo- rithm. In case of aggregation, if an additional envelope is required (e.g. a Time Series container or a Figure Trajectory, see Subsection 2.1) it is necessary to overload the corre- sponding DescriptorInfo class of DescriptorLogic as well. Again, since the class name of the derived class is unique, this means no problem for the persistence system.</p><p>Figure 2 shows a further case of simple localisation and aggregation. If the specialised feature is the result of sub- sampling of existing descriptor data, the aggrega- tion/localisation process can be performed by an XSL trans- former encapsulated in a DescriptorLogic class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Semantic feature enrichment</head><p>In contrast to aggregation and localisation, completely dif- ferent workflows and algorithms are used for semantic en- richment of features. In consequence, it would not make sense to derive semantic descriptors on the algorithm level (DescriptorLogic). In VizIR, semantic feature classes are descriptions (DescriptorInfo objects) derived from existing descriptions. Figure 3 sketches this process. Descriptor data and additional knowledge are used to create semantic fea- tures. information is available as XML structured data, again, an XSL transformer is sufficient to create the semantic feature. If a more sophisticated logic (e.g. a statistical procedure) is applied for semantic enrichment, it is recommended to embed the enrichment process in a DescriptorLogic class that is not derived from the feature extraction classes used for the low-level features. This paradigm guarantees the existence of reasonable data and logic classes for any type of feature. Consequently, arbitrarily long chains of semantic enrichment, aggregation and localisation of features can be modelled and implemented in VizIR.</p><p>VizIR. Considered manipulations are aggregation of feature data over time, localisation in time and/or space and seman- tic enrichment of features with additional knowledge. Solu- tions are software patterns for the derivation of feature logic classes and data classes as well as interfaces to helpful ex- ternal components (e.g. XSL transformers). The presented solutions will be implemented in the VizIR framework and be made available to the VIR community as free software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Implementation details</head><p>VizIR is based on the Java programming language. Although persistence management is based on an object-oriented da- tabase model, it is an important design goal that descriptors are stored into the database in a valid XML format (e.g. the MPEG-7 schemes). Non-VizIR applications (e.g. XSL trans- formers) have to be able to read the descriptions as well. Internally, descriptions are represented by appropriate mem- ory structures (essentially, one class per tag). Handling is based on the Document Object Model (DOM) of the World Wide Web Consortium. The JDom package is used for de- scription parsing and writing. To guarantee that the database requirement is met, JDom is used to (redundantly) serialise the description DOMs to string variables. These strings are stored in the database and used as starting point for semantic enrichment of features.</p><p>As pointed out above, XSL transformers could solve some of the problems associated with feature aggregation, localisation and enrichment. At the moment, several frame- works for XSL transformation are available and under devel- opment. We are currently preferring the Cocoon framework of the Apache project <ref type="bibr">[7]</ref>, as it is Java-based, in a mature state and easy to install and use. For the applications pro- posed above, implementing an appropriate transformation style-sheet would be sufficient.</p><p>The author would like to thank Christian Breiteneder and Roman Divotkey for their valuable suggestions for im- provement. The VizIR project is supported by the Austrian Scientific Research Fund FWF und grant number P16111- N05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REFERENCES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we sketch solutions for the manipulation of visual features in the visual information retrieval framework <ref type="bibr">[1]</ref> S.F. Chang, T. Sikora and A. Puri, "Overview of the MPEG-7 standard", IEEE Transactions on Circuits and  <ref type="bibr">[4]</ref> B.S. Manjunath, J.R. Ohm, V.V. Vasudevan and A. Ya- mada, "Color and texture descriptors", IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 703-715, June 2001. <ref type="bibr">[5]</ref> University of Geneva, Multimedia Retrieval Markup Language website, http://www.mrml.net/, last visited 2004-01-07. <ref type="bibr">[6]</ref> Vienna University of Technology, VizIR project website, http://vizir.ims.tuwien.ac.at/, last visited 2004-01-07. <ref type="bibr">[7]</ref> Apache project, </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Figure 1 :</head><label>Figure 1</label><figDesc></figDesc><table>General architecture of high-level feature modelling in VizIR. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>If the enrichment process is linear and all required</head><label></label><figDesc></figDesc><table>MPEG-7 aggreg-
ation / localisa-
tion structures 

Descriptor data 

Descriptor data 

... 

High-level 
descriptor logic 

XSL 
Trans-
former 

MPEG-7 
descriptor 
data 

Derived 
MPEG-7 
compliant 
descriptor 

Additional 
knowledge 

... 

Framework components 

High-level 
descriptor 
information 

Figure 3: Semantic enrichment of features in VizIR. 

Figure 2: Simple aggregation/localisation of features. 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
