<Publication>
  <id>TUW-247741</id>
  <title>A FORMAL METHOD FOR SELECTING EVALUATION METRICS FOR IMAGE</title>
  <note>SEGMENTATION. Abdel Aziz Taha, Allan Hanbury Oscar A. Jimenez del Toro Vienna University of Technology Univ. of Applied Sciences Western Swizerland</note>
  <abstractText>Evaluating the quality of segmentations is an important process in image processing, especially in the medical domain. Many evaluation metrics have been used in evaluating segmentation. There exists no formal way to choose the most suitable metric(s) for a particular segmentation task and/or particular data. In this paper we propose a formal method for choosing the most suitable metrics for evaluating the quality of segmenta-tions with respect to ground truth segmentations. The proposed method depends on measuring the bias of metrics towards/against the properties of the the seg-mentations being evaluated. We firstly demonstrate how metrics can have bias towards/against particular properties and then we propose a general method for ranking metrics according to their overall bias. We finally demonstrate for 3D medical image segmentations that ranking produced using metrics with low overall bias strongly correlate with manual rankings done by an expert. Index Terms-image segmentation; evaluation met-rics; selection 1 Introduction 1.1 The need to understand metrics: Many evaluation metrics for image segmentation have been introduced; most researchers choose the evaluation metrics arbitrarily or according to their popularity. Investigating met-rics would help researchers to better understand them and help companies and stakeholders to save effort and time reaching optimal systems [1]. A poorly defined metric may lead to inaccurate conclusions like selecting suboptimal models when comparing the performance of classifiers [2]. Many researchers have investigated the drawbacks of particular metrics given particular properties of the data being classified. As a special case of classification, image segmentation is also affected by these drawbacks. The following are some examples: Hausdorff distance is very sensitive to noise and least squares based evaluation methods are very sensitive to out-liers [3]. Mutual information doesn&apos;t utilize spatial information inherited in images because only voxel relationships are considered but not the neighborhoods [4]. Information theoretical measures have a non-convergent baseline which depends on the ratio between the number of data points and the number of classes. Therefore this class of measure needs chance correction [5]. Commonly used measures (precision, recall and F-measures) are biased and don&apos;t consider the level of chance [6]. Choosing evaluation metrics is very important and application-dependent; when evaluating imbalanced datasets, the metric choice is not obvious [2]. Metrics have different properties with respect to their correlation with user satisfaction criteria and their ease of interpretation [7]. Benhabiles et al. [8] validated 250 automatic segmentations against their corresponding ground truth segmentations using four different evaluation metrics. The results were then compared with manual ratings from 40 human observers. They found that the correlations between the ranking based on the manual ratings and the rankings based on the evaluation metrics vary between 30% and 80% depending on the used metric. Research in the last decades generally results in the relative system improvement achieved becoming smaller and smaller. As a result, sensitivity and fidelity of evaluation metrics become increasingly critical. When improvements are small, metrics with high sensitivity are needed to measure small but real improvements and also with high fidelity to distinguish</abstractText>
  <keywords/>
  <authors/>
  <affiliations/>
  <sections>
    <Section>
      <level>1.2</level>
      <title>Problem</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3</level>
      <title>Proposed Methods</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2</level>
      <title>Related Work</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.1</level>
      <title>Constructing</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>iâˆˆP</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.3</level>
      <title>Discussion:</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.2</level>
      <title>Inferring</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4</level>
      <title>Experiments</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>metric</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.818</level>
      <title>1 33.5 2 Adjusted Rand Index</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.818</level>
      <title>1 33.1 1 Interclass Correlation</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.818</level>
      <title>1 33.5 2 Probabilistic distance</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.802</level>
      <title>2 34.7 5 Dice</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.800</level>
      <title>3 33.6 3 Average Distance</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.798</level>
      <title>4 33.9 4 Accuracy</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.791</level>
      <title>5 64.0 14 Rand Index</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.791</level>
      <title>5 64.0 14 Variation of Inform. 6 62.0 13 Mutual Information</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>0.753</level>
      <title>7 46.5 12 Mahalanobis</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>5</level>
      <title>Conclusion and future work</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>6</level>
      <title>Acknowledgments</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>7</level>
      <title>References</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
  </sections>
  <citationContexts/>
  <references/>
</Publication>