<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Users\Angela\git\grobid\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-12-29T00:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Clustering of Social Events</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zeppelzauer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maia</forename><surname>Zaharieva</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Del</forename><surname>Fabro</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Klagenfurt University</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Clustering of Social Events</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Interactive Media Sys. Group University of Vienna, Austria Research Group Multimedia Information Systems</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes our contribution to the social event detection (SED) task of the MediaEval Benchmark 2013. We present a robust unsupervised approach for the clustering of tagged photos and videos into social events. Results on the SED datasets show that the proposed approach yields an excellent generalization ability and state-of-the-art clustering performance. 1. INTRODUCTION</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>based on topic detection <ref type="bibr">[5]</ref>. The authors perform topic detection by Latent Dirichlet Allocation (LDA) for each city in the image collection. Additionally, the authors manually identify topics that are typical for a specific event cluster.</p><p>From related approaches we observe that many assump- tions are made on the training set and (partially manual) optimizations are required which limits general applicabil- ity. Our unsupervised approach minimizes the assumptions on the data and avoids manual intervention. The approach exhibits a strong generalization ability and results show that the sensitivity to the involved parameters is reasonably low.</p><p>We participated in challenge 1 of the Social Event De- tection (SED) task <ref type="bibr">[4]</ref>. The goal of the task is to build photo clusters belonging to unique social events in a large collection of tagged flicker images. Thereby the total num- ber of events is not provided. In an additional subtask we assign unlabeled videos to the previously discovered photo clusters. The development set comprises 300k images from 14882 unique events. For the test set of 131k images no ground truth is available.</p><p>We consider challenge 1 as an unsupervised data mining task. The basic idea is to rely on robust heuristics and to reduce the number of parameters of the approach to a minimum to obtain a good generalization ability between different datasets. Additionally, the proposed approach does not require any external (online) data sources.</p><p>In the course of the SED2013 task, we focus on the fol- lowing research questions: (i) Which level of clustering per- formance can be obtained by relying on simple but robust heuristics for unsupervised clustering and how do the results compare to more complex clustering methods? (ii) How well does the proposed approach generalize to unknown data?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Full Clustering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Many existing approaches for event detection in image collections require a separate training <ref type="bibr">[1,</ref><ref type="bibr">3]</ref>. Becker et al. create separate clusters for each feature such as title, descrip- tion, time, etc. The authors employ single-pass incremental clustering whereas the threshold for each cluster is tuned based on a set of training data <ref type="bibr">[1]</ref>. Reuter and Cimiano em- ploy machine learning techniques to detect events in social streams. The authors employ SVMs to classify Flickr images annotated by machine tags from last.fm into events <ref type="bibr">[3]</ref>.</p><p>Vavliakis et al. propose a social event detection approach Copyright is held by the author/owner(s).</p><p>The input to the approach are the available metadata of the SED dataset (capture data, location, title, tags, descrip- tion) and a stopword list. No other data sources are re- quired. In a first step, the metadata are preprocessed: Since a user cannot be at two locations at the same time, we as- sign locations of photos taken by the same user at the same time to the user's non-geotagged photos. Additionally, the textual metadata are filtered by the stopword list.</p><p>In a next step, we perform three independent cluster- ings in parallel: temporal clustering, location clustering, and topic clustering. For temporal clustering we employ mean- shift and set the bandwidth parameter βT in a way that the resulting clusters span between 2 and 6 hours, which is a reasonable temporal resolution for social events. For lo- cation clustering we observe that the performance gain of meanshift clustering does not justify the computational ef- forts. Hence, we skip meanshift clustering and assign each individual and unique location in the data a separate cluster ID. Topic clustering is based on topic extraction by LDA. We perform topic modeling on the textual descriptions of each photo (title, tags, description) using LDA and extract T topics for the employed dataset. For each photo i, we estimate the likelihoods li,1 and li,2 of the first-and second- best matching topics. If the difference of the likelihoods is larger than a threshold τ (li,1 − li,2 &gt; τ ) the most likely topic is assigned to the photo otherwise no topic is assigned. Parameter τ is set to 0.3 for all experiments.</p><p>The three independent clusterings are the basis for the generation of initial event clusters. Photos which share the same temporal cluster, location cluster, and topic cluster are assigned the same unique event ID. The remaining pho- tos are assigned to existing and new events in a number of matching steps.   the same user and capture time as photos in already ex- isting events are assigned to the respective events. If sev- eral events share the same users and capture times, the events are merged. Second, remaining photos without loca- tion information are matched to existing events by time and topic. If no match to an existing event can be established, a new (non-geotagged event cluster) is generated. For photos where no location and no topic is available we generate new events by their capture time. The resulting sets of events (refined event clusters and non-geotagged event clusters) may oversegment the true event distribution. Hence, we merge events that share similar time, location, and topic to obtain the final event clusters.</p><p>The three approaches submitted to the video subtask show different results. The supervised approach trained on the de- velopment data performs suboptimally <ref type="bibr">(F1=0.42, NMI=0.68)</ref>. The reason for this may be that the events of the test data are inferred from the events in the development data. If an event is not included in the development data, it cannot be inferred. The second approach shows that comparing the metadata of single videos with the accumulated LDA key- words from clusters is not well-suited to link single videos to clusters <ref type="bibr">(F1=0.34, NMI=0.77)</ref>. The unsupervised LDA- based approach performs best <ref type="bibr">(F1=0.69, NMI=0.85</ref>) and builds a promising baseline for future improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Full Clustering of Media using Videos</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS AND OUTLOOK</head><p>For the video subtask, we apply the above described topic modeling to the stopword-filtered textual descriptions of the videos (title, description, keywords). Temporal clustering and location clustering are neglected, because most videos do not contain location information and a capturing date. As a consequence, parameter τ is set to 0.0 for all experi- ments to achieve a complete clustering of all videos.</p><p>We investigate three different approaches for generating the video clusters: (i) LDA is applied to train a topic model with 200 topics on the development data from which the topics of the test data are derived; (ii) each video constitutes a topic on its own; and (iii) an unsupervised LDA-based approach is used to detect 70 topics in the test data. After the video clusters are created, we link them to the previously generated photo clusters. The keywords of video clusters V are compared to the keywords of the photo clusters P using the Jaccard similarity coefficient. Each video cluster is linked to the photo cluster with the highest similarity.</p><p>In this paper we presented our contribution to the SED challenge of the MediaEval 2013 Benchmark. We proposed a robust unsupervised method for the clustering of photos and videos into social events. The method exhibits strong gen- eralization ability, low sensitivity to parameters, and yields state-of-the-art performance. Future work focuses on more sophisticated event refinements and visual content analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">REFERENCES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS AND RESULTS</head><p>We use the same parameters for experiments on the de- velopment and test set. To estimate the numbers of topics, we assume that each topic is constituted in average by 100- 200 photos. Additionally, we evaluate different values of βT corresponding to an event duration of 2-6 hours. The results of the proposed approach for both sets demonstrate its ex- cellent generalization ability (see <ref type="table" target="#tab_2">Table 1</ref>). Results for the test set are even better than for the development set. The clustering performance is comparable to (more complex) su- pervised state-of-the-art methods. The approach by Petkos et al., for example, yields NMI values of 0.92 (average of best <ref type="bibr">[1]</ref> H. Becker, M. Naaman, and L. Gravano. Learning similarity metrics for event identification in social media. In ACM WSDM, pp. <ref type="bibr">291-300, 2010. [2]</ref> G. Petkos, S. Papadopoulos, and Y. Kompatsiaris.</p><p>Social event detection using multimodal clustering and integrating supervisory signals. In ACM ICMR, pp. <ref type="bibr">23:1-8, 2012. [3]</ref> T. Reuter and P. Cimiano. Event-based classification of social media streams. In ACM ICMR, pp. <ref type="bibr">22:1-8, 2012. [4]</ref> T. Reuter, S. Papadopoulos, V. Mezaris, P. Cimiano, C. de Vries, and S. Geva. Social Event Detection at MediaEval 2013: Challenges, datasets, and evaluation. In MediaEval 2013 Workshop, 2013. <ref type="bibr">[5]</ref> K. N. Vavliakis, F. A. Tzima, and P. A. Mitkas. Event detection via LDA for the MediaEval2012 SED Task. In MediaEval 2012 Workshop, 2012.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>First, remaining photos which share</head><label></label><figDesc></figDesc><table>metadata 

location 
description 
time 

preprocessing 

stop 
words 

topic clustering 

location clustering temporal clustering 

merge clusterings 

results) and 0.69 (average performance) on a portion of the 
SED2011 dataset (no F1 reported) [2]. Becker et al. [1] yield 
NMI values between 0.92 and 0.94 and F1 values from 0.77 
to 0.82 on a test set consisting of 270k photos (10 splits). 
Reuter and Cimiano report an F1 of 0.74 for a dataset of 
700k photos (7 splits, no NMI reported) [3]. 

initial clusters 
unassigned fotos 

match 
user + time 

update merge 

all 

match 
time + topic 

no location 
update, merge 

no location, no topic 
new 

non-geotagged event clusters 
refined event clusters 

merge events 

final event clusters 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Figure 1 : Overview of the approach</head><label>Figure 1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 : Results for Full Clustering</head><label>1</label><figDesc></figDesc><table>Development Set 
Test Set 
βT 
Topics 
F1 
NMI Topics 
F1 
NMI 
0.2 
2000 
0.74 0.94 
1000 
0.78 0.94 
0.2 
3000 
0.74 0.94 
1500 
0.78 0.94 
0.2 
1600 
0.74 0.94 
800 
0.78 0.94 
0.1 
2000 
0.73 0.93 
1000 
0.76 0.94 
0.5 
2000 
0.72 0.93 
1000 
0.77 0.94 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
