<Publication>
  <id>TUW-182899</id>
  <title>Teachers&apos; and Tutors&apos; Social Reflection around SenseCam Images</title>
  <abstractText>As photographic technologies continue to develop, so too do the social practices surrounding their use. The focus of this paper is on the social practices surrounding images captured from a new photographic device-SenseCam-which, rather than capturing individual images when triggered by the user, automatically captures a series of images. This paper is concerned with the use of SenseCam digital images in social contexts where there is a professional purpose: supporting the collaborative reflective practices of school teachers and university tutors as part of their professional development. Analysis of video data collected from 16 in-situ case studies of reflective discussions show evidence that reflection took place as defined in the literature. Further, the phototalk around SenseCam images was found to benefit reflection in these social situations through promoting a rich shared understanding of the lesson context: supporting return to the experience, sharing of background context, grounding conversations, illustrating and providing evidence, and allowing people to see more. The paper concludes with a discussion on how different features of SenseCam images, such as variable quality, lack of audio, incompleteness, helped in this reflection or not. Finally implications from this work and participants comments are used to suggest ways in which SenseCam may be used in the future in teacher and tutors social reflection. With advances in digital photography there has been a growing interest in the novel ways that these photos are brought into social practices and the ways in which people are evolving their photographic habits. Whilst most of this work is focussed on the digital form of the stills camera, a different type of digital photo is emerging in the sphere of lifelogging. SenseCam is a prototype lifelogging device currently under development at Microsoft Research in Cambridge (e.g. Williams and Wood 2004; Cherry 2005). It is a small wearable device combining a digital camera with a number of built in sensors and is made to be worn by a person around their neck like a pendant (see Figure 1). The sensors, which measure light, motion, sound, infra-red and ambient temperature, are used to trigger digital still images to be taken at &apos;good&apos; times when something interesting may be happening. Currently &apos;good&apos; is defined by the developer as when there is a sudden change in light (which might happen when we move from one room to another), sound or temperature, or when the infra-red data combined with motion detection suggests another person is nearby. On average 3 or 4 photos per minute are triggered in this way. The camera also has a very wide angle, fish-eye lens which captures most of what is the field of view of the wearer from a first person perspective. These combined features allow the wearer to passively capture a whole day&apos;s worth of images without having to press a trigger or aim the camera, leaving their hands and attention free to get on with their everyday tasks. When downloaded to a PC, the images can be viewed using a rapid serial visualization tool, playing somewhat like a sped up movie (see Figures 2-7 for example images), and the whole day may only take around 10 minutes to review. In this way, SenseCam can be considered a &apos;life-logging&apos; tool. Much research to date with SenseCam has focused on its potential to record life experience as a support to memory-indeed it has been shown to be an effective tool in supporting people with severe memory-loss (Cherry 2005), and to support different aspects of &apos;remembering&apos; and knowing&apos; for people with a normal memory (Sellen et al. 2007). More recently, research has suggested that SenseCam images can also evoke reflection on past life experiences (Harper et al. 2007; Harper et al. 2008); and that sharing such images with others prompts reflection on own and others&apos; lives (Lindley et al. 2009). The focus of this research has been very much on everyday life-the way SenseCam as a life-logging tool was envisaged to be used. We have also shown that SenseCam can support reflection in a learning context, where students used the images from a field trip to reflect on their experiences (Fleck and Fitzpatrick 2006). In this paper, however, we consider the value of SenseCam images in a work setting: we explore the potential of the device to capture aspects of professional experience and share these with others, espoused as part of being a good reflective practitioner (Moon 1999). The professional practice we focus on is that of teaching-in both school and university contexts. This is a domain in which another visual experience-recording technology, video, has been advocated for over thirty years (Zuber-Skerritt 1984). We have previously undertaken research with individual school teachers and university tutors using SenseCam for self-reflection and have shown it to be useful (Fleck 2008). Here we expand on these findings and focus on how SenseCam might be used in schools and universities to support reflection in social contexts: specifically we look at how it can support reflective practice conversations between novice teacher peers, novice teachers and their mentors, and between trainee university tutors.</abstractText>
  <keywords>
    <string>SenseCam, passive image capture</string>
    <string>reflective practice</string>
    <string>teacher training 1 Corresponding Author&apos;s Present Address Department of Psychology University of Sussex Falmer Brighton BN1 9QH rmmfleck@sussexacuk tel: 01273 678530 fax: 01273 678058 1 Introduction</string>
  </keywords>
  <authors>
    <Author>
      <firstNames/>
      <affiliations>
        <Affiliation>
          <id>aff0</id>
          <institution>Rowanne Fleck a1 Geraldine Fitzpatrick b a Department of Informatics University of Sussex Falmer Brighton Department of Informatics University of Sussex Falmer Brighton</institution>
        </Affiliation>
      </affiliations>
    </Author>
  </authors>
  <affiliations>
    <Affiliation reference="/Publication[1]/authors[1]/Author[1]/affiliations[1]/Affiliation[1]"/>
  </affiliations>
  <sections>
    <Section>
      <level>2</level>
      <title>Teachers&apos; reflective practice</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.1</level>
      <title>Social reflection and discussion</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.1.1</level>
      <title>Current practices of social reflection</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.1.2</level>
      <title>Technology and social reflection</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3</level>
      <title>Methodology</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.1</level>
      <title>Participants</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.2</level>
      <title>Design</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P8: PGCE</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>18</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P7: PGCE</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>7</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P3: PGCE P4: PGCE</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>14</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P5: PGCE P6: GTP</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>20</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P10: RQT</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>24</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P14: NQT</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>25</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P15: NQT</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>26</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P16: NQT</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>27</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P17: RQT P18: NQT P19: PGCE</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>28</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>P20: PGCE P21: PGCE</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>12</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>T10 T11</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>3</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>T2 T3</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>4</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>T3 T4</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>11</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>T8 T9</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>13</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.3</level>
      <title>Analysis</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4</level>
      <title>Findings</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.1</level>
      <title>Images support a return to experience</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.2</level>
      <title>Images prompt discussion of thoughts at the time</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.3</level>
      <title>Images prompt sharing of background context</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.4</level>
      <title>Images support reflective discussion</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.4.1</level>
      <title>Images ground conversation</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.4.2</level>
      <title>Illustrating and providing evidence</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.4.3</level>
      <title>Images allow participants to see more</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>5</level>
      <title>Discussion</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>5.1</level>
      <title>Supported features of reflective discussion</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>5.2</level>
      <title>Reflecting on the value of SenseCam features for reflection</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>5.3</level>
      <title>Teacher suggestions for future SenseCam use</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>5.4</level>
      <title>Implications and further Research</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>6</level>
      <title>Acknowledgements</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>7</level>
      <title>References</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
  </sections>
  <citationContexts/>
  <references>
    <Reference>
      <id>ref1</id>
      <referenceIdString>b0</referenceIdString>
      <title>Video, reflection and transformation: Action research in vocational education and training.&quot; Educational action research 5</title>
      <source>Enhancing multipoint desktop video conferencing (MDVC) with lesson video clips: recent developments in pre-service teaching practice in Singapore.&quot; Teaching and Teacher</source>
      <publisher>R</publisher>
      <authors>
        <ReferenceAuthor>
          <firstNames>
            <string>Carry</string>
          </firstNames>
          <lastName>06</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames/>
          <lastName>Le</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>France</string>
          </firstNames>
          <lastName>Rouet</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>D</string>
          </firstNames>
          <lastName>Frohlich</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>Audiophotography</string>
          </firstNames>
          <lastName>2004</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames/>
          <lastName>Sounds</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames/>
          <lastName>Dordrecht</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames/>
          <lastName>Publishers</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>R</string>
          </firstNames>
          <lastName>Harper</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>D</string>
          </firstNames>
          <lastName>Randall</lastName>
        </ReferenceAuthor>
      </authors>
      <volume>11</volume>
      <note>Reflection in teacher education: Towards definition and implementation.&quot; Teaching and Teacher Education</note>
      <publicationDateString>1983</publicationDateString>
      <publicationYear>1983</publicationYear>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref2</id>
      <referenceIdString>b1</referenceIdString>
      <title>Using Video Interaction Guidance to assist student teachers&apos; and teacher educators&apos; reflections on their interactions with learners and bring about change in practice, Report for the Scottish Executive Education Department</title>
      <source>Zuber-Skerritt, O., Ed. 1984. Video in Higher Education. Worcester, Billing &amp; Sons Limited</source>
      <authors>
        <ReferenceAuthor>
          <firstNames>
            <string>M</string>
            <string>G</string>
          </firstNames>
          <lastName>Sherin</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>E</string>
            <string>A</string>
          </firstNames>
          <lastName>Es</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>Aace</string>
          </firstNames>
          <lastName>Usa</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>C</string>
          </firstNames>
          <lastName>Thomson</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>L</string>
          </firstNames>
          <lastName>Macdougall</lastName>
        </ReferenceAuthor>
      </authors>
      <note>Society for Information Technology and Teacher Education International Conference</note>
      <publicationDateString>2002</publicationDateString>
      <publicationYear>2002</publicationYear>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
  </references>
</Publication>