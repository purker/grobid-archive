<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Users\Angela\git\grobid\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-12-29T00:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">QualityTrails: Data Quality Provenance as a Basis for Sensemaking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">QualityTrails: Data Quality Provenance as a Basis for Sensemaking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Christian Bors 1 , Theresia Gschwandtner 1 , Silvia Miksch 1 , and Johannes G Â¨ artner 2 1 Institute of Software Technology &amp; Interactive Systems (ISIS), Vienna University of Technology, Austria, {surname}@ifs.tuwien.ac.at 2 XIMES GmbH, Vienna, Austria, gaertner@ximes.com</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>1) generating Provenance from Data Quality Control and (2) sensemaking based on Data Quality Provenance Keywords: data provenance</term>
					<term>analytic provenance</term>
					<term>sensemaking</term>
					<term>data quality</term>
					<term>quality metrics</term>
					<term>visual data analysis Index Terms: Human-centered Computing [Visualization]: Vi-sualization application domains-Visual Analytics Mathematics of computing [Probability and statistics]: Statistical paradigms-Exploratory data analysis 1 INTRODUCTION</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Visual Analytics prototypes increasingly support human sensemak-ing through providing Provenance information. For data analysts the challenge of knowledge generation starts with assessing the quality of a data set, but Provenance is not yet utilized to aid this task. This position paper aims at characterizing the complexity of Visual Analytics methods introducing Provenance in Data Quality by highlighting the challenges of (In Data Quality (DQ) assessment one of the central questions is, &apos;Is the Data Quality good enough for analysis to produce meaningful results?&apos; The quality of data analysis is highly dependent on the quality of the underlying data. Thus, a prerequisite of any data analysis, such as creating visualizations and performing analytical reasoning, is assessing and improving DQ. Data cleansing is an iterative task that requires user expertise and domain knowledge of the data provided [7]. DQ control can be understood as a combination of data quality assessment, the data cleansing process, as well as applying transformations to change a data set&apos;s structure. Kandel et al. [7] argue that integrating interactive and visual systems could facilitate these tasks as well as data verification. Yet, the analyst is left with the decision about when quality is sufficient to start analysis, or if the data is worth further manipulating at all. Sensemaking is an integral part of Visual Analytics (VA). During DQ assessment the analyst needs to take into account not only the actual data, but also implicit information, like how the data was created or its transformation history. A data set already might have been analyzed by someone else, generating a transformation</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CHALLENGES</head><p>We reviewed the state-of-the-art of Provenance generation <ref type="bibr">[11]</ref>, Provenance in VA <ref type="bibr">[10]</ref>, as well as sensemaking in VA <ref type="bibr">[1,</ref><ref type="bibr">13]</ref>, and lastly Provenance in DQ assessment <ref type="bibr">[5,</ref><ref type="bibr">2]</ref>. In the following sec- tions we illustrate our results, i.e., the current VA approaches that combine DQ with Provenance to aid analysts in their task of making sense of data. Furthermore we derive open problems and challenges for Provenance in DQ analysis and contemplate possible solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Provenance from Data Quality Control</head><p>Data Provenance information is primarily utilized for resolving conflicting data sets and estimating data reliability based on lin- eage <ref type="bibr">[3,</ref><ref type="bibr">14]</ref>. Hartig <ref type="bibr">[5]</ref> suggests to use a Provenance model in DQ to assess metrics like accuracy, reliability, or timeliness of data, which partly conforms with the above mentioned use of conflict resolution.</p><p>However, there are just a few approaches that denote how Prove- nance information could be used for DQ improvement and assess- ment. In the following sections we propose approaches to outline which Provenance information is suited to aid these tasks and how it should be gathered.</p><p>Generating Provenance from Data Cleansing Opera- tions. Some data analysis tools incorporate the concept of log- ging the actions of data manipulation <ref type="bibr">[8]</ref>. Generating Provenance from cleansing operations is a promising approach. By now, this information is merely presented in textual form and used for track- ing purposes rather than DQ assessment. Provenance information from data exploration and transformation can be obtained by trac- ing transformation steps, cleansing operations, etc. in a log for later inspection.</p><p>The Open Provenance Model <ref type="bibr">[11]</ref> (OPM) has been developed to depict Provenance information through an Artifact, Process, and Agent model. DQ assessment and cleansing operations can be ap- plied to this model as means of tracking the action history of qual- ity assessment, employing data sources, similar to artifacts, trans- formation functions, comparable to processes, and analysts, inter- pretable as agents. The model's design is generic enough to support this task. It provides a good overview of which actions have been taken by other analysts. However, this approach does not consider implicit information about data generation sources or information based on the analyst's experiences while cleansing operations are omitted. Thus, it is necessary to either investigate the extensibility of this model or to find other solutions that are suited to convey this information.</p><p>Generating Provenance from Annotated Data. As a common way of propagating insightful information to collaborators or analysts annotations are employed to further analyze the data <ref type="bibr">[9]</ref>. They can be seen as a type of Provenance information and allow for manually adding information about the conditions under which the data have been created or manipulated. This information is impor- tant to analysts in order to correctly assess the DQ and to be aware of all kinds of background information.</p><p>Hullman et al. <ref type="bibr">[6]</ref> proposed automatically adding narrative an- notations to line-charts of stock visualizations. They stress the im- portance of using annotations as an additional information source to support sensemaking. In existing data analysis approaches anno- tation is not directly incorporated, but analysts rely on informal in- formation and consider it in their sensemaking process. We propose administrating annotations about data sources and quality cleansing operations as Provenance information.</p><p>Generating Provenance from Quality Metrics. In Data Quality Management one approach to measuring Data Quality is computing Data Quality Metrics <ref type="bibr">[12]</ref> (QM). The aim is to find structural or measurement errors by means of computation. This is a task that requires comprehensive knowledge about the error sources and causes, as well as how they manifest in the data. Met- rics can be used to both give overview on a data set and simulta- neously give detailed information on specific values, by being cal- culated on multiple granularity levels. Errors in the data set are propagated to high level overviews and can still be easily tracked by browsing lower aggregation layers.</p><p>With quality problems being resolved over time, also the qual- ity measures improve and indicate a trend during DQ assessment. We propose utilizing development of the data quality -as indicated by QM computed at different points in time -as Provenance. We contemplate that an analyst can determine if the quality is sufficient for analysis from assessing gradual quality improvement over time, comparing the current status to the data's original condition.</p><p>We contemplate combining visualizations of different Prove- nance information types into interactive views that employ linking and brushing. Within these multiple views annotations could be used to accentuate significant events and draw conclusions. Pro- viding such visualizations in addition to Provenance graphs would provide enriched means for DQ aware data analysis, i.e., different kinds of visualization for different analysis tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OUTLOOK</head><p>We have described approaches to generate Provenance from data cleansing operations, from annotations, as well as from meta in- formation based on QM. Logging this information allows their in- tegration into computation processes and it can be used to deduce patterns and learn about domain specific traits. Another challenge is to design means that foster the integration of DQ Provenance into sensemaking.</p><p>In our upcoming research we aim at tackling the challenges charac- terized above by developing a DQ control prototype that incorpo- rates data cleansing and transformation operations as well as em- ploying Provenance information to support analysts in their sense- making tasks.</p><p>ACKNOWLEDGMENTS This work is part of the the Laura Bassi Cen-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sensemaking based on Data Quality Provenance</head><p>tre of Expertise CVAST is funded by the Austrian Federal Ministry of Econ It is not enough to capture Provenance information about DQ, it also needs to be integrated into sensemaking. Making sense of data is a highly complex task, which requires the analyst to be aware of the circumstances under which the data have been generated and by which contingencies they were influenced. The diversity of Prove- nance information can be significant. It is necessary to determine ways of efficiently presenting various types of Provenance informa- tion to the analyst without obstructing data cleansing operations.</p><p>In general, DQ improvement is used to prepare a data set for sub- sequent analysis. Attfield et al. <ref type="bibr">[1]</ref> suggest that analysts aim at gen- erating a model of sensemaking based on their semantic knowledge in combination with available information. We identify three itera- tive phases in the course of DQ assessment and sensemaking where the analyst combines his/her semantic knowledge with information about the data set and its respective Provenance information: <ref type="bibr">(1)</ref> The analyst decides if the data is usable, based on the Prove- nance information that has been provided. <ref type="bibr">(2)</ref> The analyst has a certain goal in mind what to do with the data in the subsequent analysis and thus he/she transforms and refines the data to achieve an output that supports sensemaking in this spe- cific context. <ref type="bibr">(3</ref>) Based on the Provenance information the analyst determines his/her confidence in the data, and thus, in the analysis results and interprets the outcome accordingly.</p><p>One way of further supporting the sensemkaing process is the use of efficient visualizations, providing the necessary information in a suitable format.</p><p>Visualizing Provenance from Data Quality Assess- ment. Provenance for sensemaking in DQ has the potential to provide substantial additional information to the analyst. It is nec- essary to develop means of visually propagating this information to him/her. Analytic Provenance approaches resort to graph-or tree- like visualization techniques to develop visual representations of Provenance graphs <ref type="bibr">[5,</ref><ref type="bibr">13,</ref><ref type="bibr">10]</ref>. Attfield et al. <ref type="bibr">[1]</ref> suggest to em- ploy visualization prototypes to provide indicators that let analysts hypothesize on the data.</p><p>Carata et al. <ref type="bibr">[4]</ref> claim that little research has been put into al- ternative visualization techniques, aside from node-link represen- tations. We propose novel ideas on how to utilize Provenance information to generate visual aids in a DQ assessment environ- ment. Which types of visual aids are suited for this task depends, of course, on the type of information. QM measure data properties over time, and are usually normalized. This implies that a contin- uous multivariate line-chart could properly visualize such informa- tion and support the decision-making process of the data analyst. Manual annotations could serve as guiding-points in either data ta- ble views or in the suggested line-chart visualizations of QM devel- opment over time, similar to Hullman et al. <ref type="bibr">[6]</ref>. <ref type="bibr">[1]</ref> S. J. Attfield, S. K. Hara, and B. L. W. Wong. Sensemaking in visual analytics: Processes and challenges. In J. Kohlhammer and D. Keim, editors, EuroVAST 2010: Intern. Symp. on VAST, pages 1-6, Bor- deaux, France, 2010. Eurographics Association. <ref type="bibr">[2]</ref> C. Batini and M. Scannapieco. Data Quality: Concepts, Method- ologies and Techniques (Data-Centric Systems and Applications). Springer Verlag New York, Inc., Secaucus, NJ, USA, 2006. <ref type="bibr">[3]</ref> P. Buneman, S. Khanna, and W. C. Tan. Why and where: A character- ization of data provenance. In J. V. d. Bussche and V. Vianu, editors, Intern. Conf. DB Theory, pages 316-330. Springer, LNCS 1973, 2001. <ref type="bibr">[4]</ref> L. Carata, S. Akoush, N. Balakrishnan, T. Bytheway, R. Sohan, M. Seltzer, and A. Hopper. A primer on provenance.  <ref type="bibr">[5]</ref> O. Hartig and J. Zhao. Using web data provenance for quality assess- ment. In J. Freire, P. Missier, and S. S. Sahoo, editors, SWPM, volume 526 of CEUR Workshop Proceedings. CEUR-WS.org, Oct. 2009. <ref type="bibr">[6]</ref> J. Hullman, N. Diakopoulos, and E. Adar. Contextifier: Automatic generation of annotated stock visualizations. In Proc. SIGCHI Conf.  <ref type="bibr">[7]</ref> S. Kandel, J. Heer, C. Plaisant, J. Kennedy, F. van Ham, N. H. Riche, C. Weaver, B. Lee, D. Brodbeck, and P. Buono. Research directions in data wrangling: Visualizations and transformations for usable and credible data. Inf. Vis.  <ref type="bibr">[9]</ref> Q. Li, A. Labrinidis, and P. Chrysanthis. User-centric annotation man- agement for biological data. In J. Freire, D. Koop, and L. Moreau, editors, Provenance and Annotation of Data and Processes, volume 5272 of Lecture Notes in Computer Science, pages 54-61. Springer Berlin Heidelberg, 2008. <ref type="bibr">[10]</ref> J. Lu, Z. Wen, S. Pan, and J. Lai.  <ref type="bibr">[11]</ref> L. Moreau, B. Clifford, J. Freire, J. Futrelle, Y. Gil, P. Groth, N. Kwas- nikowska, S. Miles, P. Missier, J. Myers, B. Plale, Y. Simmhan, E. Stephan, and J. V. d. Bussche. The open provenance model core spec. (v1.1). Future Gen. Computer Systems, 27 <ref type="bibr">(6):743 -756, 2011. [12]</ref> S. Sadiq, editor. Handbook of Data Quality. Springer Verlag, Berlin, Heidelberg, 2013. <ref type="bibr">[13]</ref> Y. B. Shrinivasan and J. J. van Wijk. Supporting the analytical reason- ing process in information visualization. In Proc. SIGCHI Conference on Human Factors in Computing Systems, CHI '08, pages 1237-1246, New York, NY, USA, 2008. ACM. <ref type="bibr">[14]</ref> Y. L. Simmhan, B. Plale, and D. Gannon. A survey of data provenance in e-science. SIGMOD Rec. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REFERENCES</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Human Factors in Computing Systems, CHI '13, pages 2707-2716, New York, NY, USA, 2013. ACM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>- omy, Family and Youth (project number: 822746).</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
