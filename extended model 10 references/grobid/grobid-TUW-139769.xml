<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Users\Angela\git\grobid\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-12-29T00:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Extended Local Branching Framework and its Application to the Multidimensional Knapsack Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anleitung</forename><surname>Von</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Computergrafik und Algorithmen</orgName>
								<orgName type="laboratory">a.o. Univ.-Prof. Dipl.-Ing. Dr. Günther Raidl Univ.-Ass. Dipl.-Ing. Jakob Puchinger durch Daniel Lichtenberger Matr. Nr</orgName>
								<orgName type="institution">Technischen Universität Wien</orgName>
								<address>
									<addrLine>9825754 Märzstrasse 80/12</addrLine>
									<postCode>1150</postCode>
									<settlement>Wien Datum Unterschrift</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Extended Local Branching Framework and its Application to the Multidimensional Knapsack Problem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>DIPLOMARBEIT</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This thesis deals with local branching, a local search algorithm applied on top of a Branch and Cut algorithm for mixed integer programming problems. Local branching defines custom sized neighborhoods around given feasible solutions and solves them partially or completely before exploring the rest of the search space. Its goal is to improve the heuristic behavior of a given exact integer programming solver, i.e. to focus on finding good solutions early in the computation. Local branching is implemented as an extension to the open source Branch and Cut solver COIN/BCP. The framework&apos;s main goal is to provide a generic implementation of local branching for integer programming problems. IP problems are optimization problems where some or all variables are integer values and must satisfy one or more (linear) constraints. Several extensions to the standard local branching algorithm were added to the framework. Pseudo-concurrent exploration of multiple local trees, aborting local trees and a variable fixing heuristic allow the user to implement sophisticated search metaheuristics that adjust the local branching parameters adaptively during the computation. A major design goal was to provide a clean encapsulation of the local branching algorithm to facilitate embedding of the framework in other, higher-level search algorithms, for example in evolutionary algorithms. As an example application, a solver for the multidimensional knapsack problem is implemented. A custom local branching metaheuristic imposes node limits on local subtrees and adaptively tightens the search space by fixing variables and reducing the size of the neighborhood. Test results show that local branching can offer significant advantages to standard Branch and Cut algorithms and eventually proves optimality in shorter time. Especially for large, complex test instances exploring the local neighborhood of a good feasible solution often yields better short-term results than the unguided standard Branch and Cut algorithm. Improving the solutions found early in the computation also helps to remove additional parts of the search tree, potentially leading to better solutions in longer runs. Zusammenfassung Diese Diplomarbeit beschäftigt sich mit Local Branching, einem lokalen Suchalgorithmus, der auf einem Branch and Cut Algorithmus für ganzzahlige Optimierungsprobleme aufsetzt. Local Branching definiert beliebig große Nachbarschaften um gegebene gültige Lösungen und löst diese teilweise oder komplett, bevor der Rest des Lösungsraums durchsucht wird. Das Ziel ist eine Verbesserung des heuristischen Verhaltens des gegebenen Solvers für ganzzahlige Optimierungsprobleme, d.h. sich auf das möglichst frühe Finden guter Lösungen zu konzentrieren. Local Branching ist als Erweiterung des Open Source Branch and Cut Solvers COIN/BCP implementiert. Das Hauptziel des Frameworks ist eine generische Implementierung von Local Branching für ganzzahlige Optimierungsprobleme, also Probleme, bei denen alle oder einige Variablen ganzzahlig sein müssen, und zusätzlich eine oder mehrere (lineare) Bedingungen in Form von Ungleichungen erfüllen müssen. Es wurden mehrere Erweiterungen zum Framework hinzugefügt: die pseudo-parallele Abarbeitung mehrerer lokaler Suchbäume, das vorzeitige Terminieren lokaler Suchbäume sowie eine unabhängige Variablen-Fixing-Heuristik. Durch diese Erweiterungen können die Parameter für Local Branching im Laufe der Berechnung beliebig verändert werden. Ein wesentliches Ziel beim Entwurf des Frameworks war eine klare Kapselung des Local Branching Algorithmus, um die Einbettung in andere, höhere Suchalgorithmen zu ermöglichen, etwa in evolutionäre Algorithmen. Als Beispielapplikation wurde ein Solver für das mehrdimensionale Rucksackproblem implementiert. Eine eigene Local Branching Metaheuristik beschränkt die Größe lokaler Bäume durch Knotenlimits und kann den Suchraum durch Anwendung der Variablen-Fixing-Heuristik weiter einschränken. Die Testergebnisse zeigen signifikante Vorteile für Local Branching im Vergleich zum normalen Branch and Cut Algorithmus. Vor allem für große, komplexe Testinstanzen liefert die Suche in lokalen Bäumen oft bessere Resultate am Anfang der Berechnung. Dadurch wird auch die Zeit zum Finden (und Beweisen) der optimalen Lösung potentiell verringert, da dadurch früher zusätzliche Teile des Suchbaums weggeschnitten werden können.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Integer programming problems (IPs) are optimization problems that restrict some or all vari- ables to integer values. In contrast to linear programming problems (LPs) without integrality constraints, IPs are NP-hard. Much research has gone into effective search algorithms for integer programs, leading to exact algorithms like Branch and Bound <ref type="bibr" target="#b22">[25]</ref>, cutting plane al- gorithms <ref type="bibr" target="#b27">[30]</ref>, and a large variety of heuristical algorithms that trade optimality for quickly getting "good enough" solutions.</p><p>This thesis considers the modification of standard Branch and Cut to follow ideas from lo- cal search based heuristics, the so-called local branching <ref type="bibr">[13]</ref>. Branch and Bound is a generic algorithm for solving integer programming problems by partitioning the search space into smaller subproblems (branching), calculating bounds on the best solution that can be found in a subproblem (bounding), and removing those subproblems that are proven to contain only solutions inferior to the best known solution (pruning). The bounding operation is commonly executed by solving the LP relaxation (i.e. the IP problem without the integral constraints). Branch and Cut tries to delay the branching operation by adding constraints (cuts) that are violated by the current LP result, leading to a reduction of the search tree size.</p><p>Local branching defines subproblems through additional local branching cuts that isolate a neighborhood of a certain size around a given feasible solution. By exploring this smaller subproblem before the rest of the search tree, the intention is to improve good feasible solutions before continuing Branch and Cut in a standard way. Several extensions have been added to local branching: pseudo-concurrent tree exploration, the possibility to abort local trees, and a variable fixing heuristic have been added. Due to its general design, local branching can be used with any IP solver.</p><p>A large part of integer programming is concerned with combinatorial problems. These include for example the subset sum equality problem, various graph theory problems, and the well-known family of knapsack problems. In this thesis, the multidimensional knapsack prob- lem is used to demonstrate the use and the benefits of local branching. Although all types of knapsack problems are NP-hard, some problems can be efficiently solved by enumerative tech- niques like dynamic programming. For others, like the multidimensional knapsack problem, no such methods are known. These problems supply well suited testcases for fully fledged Branch and Cut solvers, and are often too complex to be solved to optimality in reasonable time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Thesis Overview</head><p>In chapter 2, an overview of integer programming problems, cutting plane techniques and Branch and Bound algorithms is given to summarize the building blocks of Branch and Cut. Chapter 3 provides an introduction to local branching as proposed by Fischetti and Lodi <ref type="bibr">[13]</ref>. Chapter 4 introduces the framework implemented for this thesis, including extensions to the local branching algorithm, and describes the overall design of the interface to the framework. In chapter 5, an overview of the open source COIN/BCP framework used for implementing local branching is given. Chapter 6 contains the implementation details of the local branching framework. An overview of knapsack problems in general and multidimensional knapsack problems in particular is given in chapter 7. The implementation of a sample local branching application for the multidimensional knapsack problem is described in chapter 8. Test results exploring the benefits and drawbacks of local branching based on the sample application are given in chapter 9. Chapter 10 summarizes the results and provides a brief outlook on possible future work. In appendix A, the patches necessary for the COIN/BCP source code are de- scribed. Appendix B provides a brief overview of the test scripts used for analyzing the local branching test runs.</p><p>Branch and Cut is an exact algorithm for solving integer programming problems. It combines cutting plane methods with Branch and Bound. The following introduction is based on Lee and Mitchell's Branch and Bound tutorial <ref type="bibr" target="#b23">[26]</ref>, Mitchell's introduction to Branch and Cut <ref type="bibr" target="#b26">[29]</ref>, the COIN/BCP User's Manual by Ralphs and Ladanyi <ref type="bibr">[36]</ref>, and the book on integer programming by Laurence Wolsey <ref type="bibr" target="#b36">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Integer Programming Problems</head><p>An integer programming problem (IP) is an optimization problem in which some or all vari- ables are restricted to integer values. A given objective function has to be maximized or mini- mized in a solution space constrained by inequalities. A mixed integer programming problem (MIP) contains both integer and continuous variables, a pure integer programming problem restricts all variables to be integer. Mixed or pure 0-1 integer programming problems restrict all integer variables to be 0 or 1, thus they are also called binary integer programming prob- lems. In this thesis we will concentrate on linear 0-1 integer programming problems where all variables are binary and all terms of the objective function and constraints are linear. The objective function should be maximized. A linear 0-1 IP can then be stated as: maximize c T x subject to Ax ≤ b (2.1) x ∈ {0, 1} n with A ∈ R m×n , b ∈ R m and c ∈ R n . We can define the solution space S of a problem as S = {x ∈ {0, 1} n : Ax ≤ b}.</p><p>(2.2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Convex Hull of an Integer Program</head><p>In algebraic topology, Ax ≤ b defines a convex polyhedron which contains all feasible solu- tions of the integer program. H. Weyl proved in 1935 that a convex polyhedron can be defined as the intersection of a finite number of half-spaces or as the convex hull combined with the conical hull of a finite number of vectors or points. If the problem is formulated in rational numbers, Weyl's theorem implies the existence of a finite system of linear inequalities whose solution set coincides with the convex hull of our solution space S, also written as conv(S). This directly leads to cutting plane algorithms for solving integer programming problems that will be described in section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Relaxations</head><p>A key concept of integer programming is that of problem relaxation. A relaxation of an opti- mization problem as stated in equation (2.1) is an optimization problem</p><formula xml:id="formula_0">max{c T R x : x ∈ S R }, (2.3)</formula><p>where S ⊆ S R and c T x ≤ c T R x for all x ∈ S. The relaxed solution space is a superset of the problem solution space, and the relaxed objective function is equal to or greater than the original function for all feasible solutions of the given problem.</p><p>A common relaxation for linear integer programming problems is the linear programming relaxation (LP relaxation). The integer constraints on all variables are removed and the prob- lem can then be solved with linear programming methods. The most common algorithm for solving linear programs is the simplex method invented by George Bernard Dantzig in 1947. There are instances where the simplex method requires an exponential number of steps, but those problems seem to be highly unlikely in practical applications where the simplex method achieves very good performance.</p><p>Khachian's ellipsoid algorithm <ref type="bibr" target="#b19">[22]</ref> proved that linear programming was polynomial in 1979. Karmarkar's interior-point method <ref type="bibr">[20]</ref> was both a practical and theoretical improve- ment over the ellipsoid algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Branch and Bound</head><p>Branch and Bound is a class of exact algorithms for various optimization problems, especially integer programming problems and combinatorial optimization problems (COP). It partitions the solution space into smaller subproblems that can be solved independently (branching). Bounding discards subproblems that cannot contain the optimal solution, thus decreasing the size of the solution space. Branch and Bound was first proposed by <ref type="bibr">Land and Doig in 1960 [25]</ref> for solving integer programs.</p><p>Given a maximization problem as described in equations (2.1) and (2.2), a Branch and Bound algorithm iteratively partitions the solution space S, for example by branching on bi- nary variables -fixing one of them to 0 in one branch and to 1 in the other branch. For each subproblem an upper bound on the objective value is calculated. The upper bound is guaran- teed to be equal to or greater than the optimal solution for this subproblem. When a feasible solution (i.e., no fractional variables remaining) is found, all subproblems whose upper bounds are lower than this solution's objective value can be discarded. The best known feasible so- lution represents a lower bound for all subproblems, and only subproblems with an upper bound greater than the global lower bound have to be considered. Discarding a subproblem is called fathoming or pruning. Upper bounds for a subproblem can be obtained by relaxing the subproblem, thus they are often obtained by optimizing the subproblem's LP relaxation. <ref type="figure" target="#fig_0">Figure 2</ref>.1 summarizes the above steps using a pseudo-code notation. The sequence of subproblems created by branching can be organized as a rooted directed graph. The original 1. Initialize list of all subproblems C = {S} 2. Generate a feasible solution and store it inˆsinˆ inˆs. It is not necessary to generate a feasible solution (e.g. by heuristics), but it can help to reduce the search tree size. When no initial solution is provided, the objective value forˆsforˆ forˆs is set to −∞.</p><p>3. Repeat while C = ∅:</p><p>(a) Take a subproblem S from C (b) Relax S and solve the relaxed problem (c) Decide to branch or prune as explained in figure 2.2. problem is the root node with edges going to each of its children. This graph is called the search tree and its nodes represent all generated subproblems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ReturnˆsReturnˆ Returnˆs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cutting Plane Algorithms</head><p>As in section 2.1, we will consider a binary integer programming problem, its mathematical formulation is stated in equations (2.1) and (2.2). The fundamental concept used for cutting plane algorithms is that of a valid inequality. An inequality</p><formula xml:id="formula_1">πx ≤ π 0 (2.4)</formula><p>is valid if πx ≤ π 0 for all x ∈ S, where S contains all feasible solutions of the IP. The basic idea of cutting planes is to describe the convex hull conv(S) of the original prob- lem by adding valid inequalities to the LP relaxation until the LP solution becomes feasible for the original problem.</p><p>Mitchell <ref type="bibr" target="#b27">[30]</ref> outlines the following structure of a cutting plane algorithm:</p><p>1. Solve the LP relaxation using linear programming methods such as the simplex algo- rithm.</p><p>2. If the LP solution is feasible for the integral problem, return the optimal solution.</p><p>3. Otherwise add cutting planes to the relaxation that separate the LP solution from the convex hull of feasible integral points.</p><p>4. Go to first step.</p><p>Cutting planes can be generated with or without problem specific knowledge. One method of obtaining cutting planes is by combining inequalities from the current LP relaxation. This is known as integer rounding, and the resulting cutting planes are called Chvátal-Gomory cutting planes <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b6">7]</ref>. The following example is taken from <ref type="bibr" target="#b27">[30]</ref>. Consider the integer programming problem</p><p>Depending on the solution of the relaxed problem, do one of the following:</p><p>1. No solution was found, the relaxed problem is infeasible. Then there is also no feasible solution in S , thus the subproblem is pruned.</p><p>2. The optimal solution is not better thanˆsthanˆ thanˆs. The subproblem can be pruned because its upper bound is lower than the global lower bound.</p><p>3. The optimal solution is better thanˆsthanˆ thanˆs and it is in S (the integer constraints are satisfied). Replacê s with the new optimal solution. The subtree can be pruned because no better solution can be found.</p><p>4. The optimal solution is better thanˆsthanˆ thanˆs but it is not in S (at least one integer constraint is violated). In this case S is partitioned into n smaller subproblems such that: n i=1 S i = S . Each of these children of S is added to C. This is the common case and is usually called branching. (2.5)</p><formula xml:id="formula_2">x 1 + 2x 2 ≤ 7 2x 1 − x 2 ≤ 3 x 1 , x 2 ∈ N 0 .</formula><p>A cutting plane is obtained by a weighted combination of inequalities, e.g. gives the valid inequality</p><formula xml:id="formula_3">x 1 ≤ 2.6. (2.7)</formula><p>This inequality is valid for all LP relaxations, but in a feasible solution, the left hand side must be an integer value. This leads to the inequality</p><formula xml:id="formula_4">x 1 ≤ 2.</formula><p>(2.8)</p><p>Gomory's cutting plane algorithm will find the optimal solution by iterating the steps as described above. However, the number of steps to describe the convex hull (called the Chvátal rank) is typically very high, leading to very slow convergence <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>It can be enhanced using techniques like adding many Chvátal-Gomory cuts at once, as shown in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b4">[5]</ref>. Another approach is to combine cutting plane methods with Branch and Bound, which leads to a method called Branch and Cut.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Initialize candidate list C = {S}</head><p>2. Generate a feasible solution and store it inˆsinˆ inˆs 3. Repeat while C = ∅:</p><p>(a) Take a subproblem S from C (b) Relax S and solve the relaxed problem, store LP result iñ s (c) Repeat:</p><p>(1) Try to add cuts to the relaxed problem that are violated by˜sby˜ by˜s (2) Exit loop when no new cuts were generated in step 1 (3) Solve relaxed problem again, store LP result iñ s. Note that the objective value of˜sof˜ of˜s is monotonically decreasing since the added cuts render infeasible the previous LP results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(d) Depending oñ</head><p>s, decide to branch or prune the node as shown in figure 2.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ReturnˆsReturnˆ Returnˆs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Branch and Cut</head><p>Branch and Cut methods use Branch and Bound to partition the solution space into smaller subproblems, but also utilize cutting plane methods to tighten the relaxation and thus to reduce the size of the search tree. Branch and Cut was first proposed by Padberg and Rinaldi <ref type="bibr" target="#b28">[31]</ref> as a framework for solving traveling salesman problems. The purpose of cutting planes or cuts is to reduce the upper bound derived from the optimal solution of the LP relaxation. A smaller upper bound makes pruning the subproblem more likely, thus reducing the search tree size. When the algorithm failed to generate new cuts that are violated by the current LP solution, the subproblem is branched as in Branch and Bound.</p><p>As cut generation can be very expensive, it is common to generate cuts only for some nodes in the search tree. For example, it might be reasonable to generate cuts for every eighth node or for all nodes at a depth of a multiple of eight. The cut-and-branch variant adds cutting planes only at the root node. A pseudo-code formulation of Branch and Cut is given in figure 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 3 Local Branching</head><p>While there exist sophisticated solvers for integer programming problems, for many hard prob- lems the optimal solution is often hard to find within a reasonable time. Therefore, it becomes increasingly important to find reasonably good solutions early in the computation process.</p><p>Local Branching is a local search meta-heuristic for integer programs proposed by <ref type="bibr">Fischetti and Lodi in 2002 [13]</ref> that is entirely embedded in a Branch and Cut framework. Its goal is to improve the heuristic behavior of a given MIP solver without losing optimality, that is, to find good feasible solutions as soon as possible while still being able to find the global optimum and prove its optimality.</p><p>Local Branching works by partitioning the search tree through so-called local branching cuts. Since those local cuts are just specific constraints for integer programming problems, they can be expressed like normal IP constraints using any generic MIP solver.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Soft vs. Hard Variable Fixing</head><p>A common technique for IP heuristics is hard variable fixing. For example, a heuristic might use a LP solver to compute a continuous optimal solution, heuristically fix some variables to integer values (e.g. by rounding the variable with the least fractional value), and then repeating these steps for the resulting subproblem without the fixed variables. This way, relatively good (but probably not optimal) solutions may be found in reasonable time even for hard problems.</p><p>The major downside of this approach is that it may be nearly impossible during the early stages to decide which variable should be fixed. This inevitably leads to bad fixings which may not be detected until much later, requiring some kind of backtracking to undo bad choices.</p><p>To overcome this limitation of variable fixing, Fischetti and Lodi proposed soft variable fixing. It does not select a single variable for fixing, but only specifies that a certain percentage of all variables of a given feasible solution should be fixed. This approach is best illustrated using the binary integer programming problem described in section 2.1. Supposing there is a feasible solution and 90% of its nonzero variables should be fixed to 1, Fischetti and Lodi add a soft fixing constraint</p><formula xml:id="formula_5">n n ¯ x j x j ≥ ¯ x j (3.1) j=1 j=1</formula><p>to the current formulation. ¯ x j represents the feasible solution around which a local neigh-borhood is isolated, i.e. in any feasible solution x j only 10% of those variables set to 1 in ¯ x j may be flipped to 0. The idea is that fixing 90% of the variables helps the solver to find good solutions as effectively as when fixing a large number of variables, but with a much larger degree of freedom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A Basic Local Branching Framework</head><p>Given a binary integer programming problem as stated in section 2.1 and a feasible solution ¯ x, the binary support ¯ S is defined as ¯ S := {j ∈ <ref type="bibr">[1, n]</ref> : ¯ x j = 1}, i.e. the indices of those variables that are set to 1. A soft fixing constraint in terms of the previous section can then be formulated as</p><formula xml:id="formula_6">∆(x, ¯ x) := (1 − x j ) + x j ≤ k. (3.2) j∈ ¯ S j / ∈ ¯ S</formula><p>Fischetti and Lodi call this a local branching constraint that counts all binary variables that flipped their value from zero to one or from one to zero compared to ¯ x. ∆(x, ¯ x) actually represents the Hamming distance between x and ¯ x, thus the constraint is also called Hamming distance constraint. When the cardinality of ¯ S is fixed, this constraint is equivalent to</p><formula xml:id="formula_7">∆(x, ¯ x) := (1 − x j ) ≤ k (= k 2 ), (3.3) j∈ ¯ S</formula><p>because for every variable x j with j ∈ ¯ S that flips from one to zero another variable must flip from zero to one. This definition is consistent with the classical k'-opt neighborhood for the Traveling Salesman Problem, where at most k edges may be replaced.</p><p>A local branching constraint partitions the search tree in two disjunct branches</p><formula xml:id="formula_8">∆(x, ¯ x) ≤ k (local branch) and ∆(x, ¯ x) &gt; k (normal branch). (3.4)</formula><p>The local branch is completely solved before continuing with the normal branch. When a new global optimum ¯ x 2 was found in the local branch, local branching can continue with the new solution by adding a new constraint to the remaining "normal" branch, again partitioning the search tree in two disjunct branches</p><formula xml:id="formula_9">∆(x, ¯ x) &gt; k, ∆(x, ¯ x 2 ) ≤ k (local branch), (3.5) ∆(x, ¯ x) &gt; k, ∆(x, ¯ x 2 ) &gt; k (normal branch).</formula><p>This scheme works as long as the local branching trees yield new global optima and is illustrated in <ref type="figure" target="#fig_20">figure 3</ref>.2. The numbers indicate the sequence in which the subproblems are generated and processed. The actual optimization problems are solved by a generic MIP solver.</p><p>The size of the local subtrees at positions 2, 4 and 6 depend on the choice of the k param- eter. Small values of k define a relatively small neighborhood that is easier to solve, but may not contain solutions that are significantly better than the current one. Larger values of k offer higher degrees of freedom during the tree search, but drastically increase the size of the local branching trees. </p><formula xml:id="formula_10">1 ∆(x, ¯ x 1 ) ≤ k d d d d d d d ∆(x, ¯ x 1 ) &gt; k 2 3 MIP solver ∆(x, ¯ x 2 ) ≤ k ∆(x, ¯ x 2 ) &gt; k improved solution ¯ x 2 d d d d d d d 4 5 MIP solver ∆(x, ¯ x 3 ) ≤ k ∆(x, ¯ x 3 ) &gt; k improved solution ¯ x 3 d d d d d d d</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Local Branching Extensions</head><p>Fischetti and Lodi <ref type="bibr">[13]</ref> proposed several extensions to the standard local branching algorithm described in the previous section.</p><p>• Imposing a time limit on local branching trees allows to use large values of k without having to explore a local tree completely. When time runs out and a better solution was found in the local tree, the algorithm creates a new local tree at the original root node using the new solution. However, since the previous local tree was not explored completely, this may lead to a duplication of effort as the optimal solution might still be in the first local tree, and its search space can therefore not be excluded. If the time limit is reached without finding a new better solution, k is decreased to speed up the exploration of the local tree.</p><p>• Diversification may be used when a local tree did not improve the best known solution. Fischetti and Lodi suggest to start with a soft diversification by enlarging the neighbor- hood, e.g. by When no better solution is found in this larger local tree, they apply a strong diversification by taking another (worse) solution and restarting local branching with this solution.</p><p>• Embedding local branching in heuristic frameworks like Tabu Search, Variable Neigh- borhood Search, Simulated Annealing or Evolutionary Algorithms can be easily done, since local branching naturally defines a custom sized neighborhood around a given so- lution. Additional constraints imposed by the heuristic framework can be described as linear cuts which makes them easy to join with local branching constraints.</p><p>• Working with infeasible solutions is necessary for problems where finding an initial fea- sible solution is hard, e.g. for hard set partitioning models. In order to use an infeasible solution as initial solution for local branching, one may define additional slack variables for some of the constraints while penalizing them in the objective function.</p><p>• General integer variables require a new definition of the local branching constraint. Some general integer problems still have a relevant subset of 0-1 variables that can be used for local branching. In case there are no relevant binary variables, introducing weights leads to a viable local branching constraint. In a MIP model that involves the bounds l j ≤ x j ≤ u j for j = 1 . . . n, a local branching constraint can be defined as</p><formula xml:id="formula_11">∆(x, ¯ x) := µ j (x j − l j ) + µ j (u j − x j ) + µ j (x + j + x − j ) ≤ k. j:¯ x j =l j j:¯ x j =u j j:l j &lt;¯ x j &lt;u j (3.6)</formula><p>The weights are defined as µ j = 1/(u j − l j ), while x + j and x − j define additional slack variables that satisfy the equation</p><formula xml:id="formula_12">x j = ¯ x j + x + j − x − j , x + j ≥ 0, x − j ≥ 0.</formula><p>Of course, there are other possibilities to improve the standard local branching algorithm not proposed by Fischetti and Lodi. The following enhancements have been integrated in our local branching framework as described in chapter 4.</p><p>• Fixing variables allows to tighten the neighborhood when the original local tree was too large to be explored completely. Variables that share the same value in the incumbent solution and in the solution of the LP relaxation are less likely to change in the global optimum. By fixing some of those variables in the local tree and adding a corresponding cut to the remaining tree local branching can avoid calculating parts of the tree that will probably yield no better results. This approach was proposed by Danna et al. <ref type="bibr" target="#b7">[8]</ref> and is known as RINS (Relaxation Induced Neighborhood Search).</p><p>• Concurrent exploration of different local trees provides diversification by creating sev- eral local trees from different feasible solutions and exploring them simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>An Advanced Local Branching Framework</head><p>In this chapter a generic framework for local branching is described. Standard local branching is implemented as described in chapter 3, and several extensions are introduced to improve its performance. The main goal of this framework is to provide a local search algorithm for higher-level metaheuristics, for example evolutionary algorithms. These metaheuristics can use local branching for exploring the neighborhood of certain solutions, and use the generated feasible solutions as input for their own improvement algorithms. The actual implementation of the framework will be described in chapter 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Basic Functionality</head><p>A sequential version of the standard local branching algorithm provides the basis for the frame- work. It is capable of using local branching to completely solve a problem without further user intervention. The main phases of the local branching algorithm are:</p><p>1. Generate an initial solution for the first tree.</p><p>2. Initialize the first local tree using the previously generated solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Repeat:</head><p>(a) Completely solve the local tree.</p><p>(b) When the local search terminates:</p><p>• A better feasible solution was found in this local tree: create a new local tree using the improved solution from this local tree as initial solution.</p><p>• No better feasible solution was found: abort local branching.</p><p>4. Solve the rest of the search tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Return optimal solution.</head><p>The initial solution can be created by a custom heuristic, or it is derived from the optimum of the root node's LP relaxation (e.g. by rounding or truncating the LP solution). The de- fault implementation uses local branching constraints as described in section 3, i.e. Hamming distance constraints defining a neighborhood around the solution according to the distance parameter k. Other constraints for branching might be implemented by the user as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Limitations</head><p>The standard local branching algorithm works well for some instances, but has several limita- tions:</p><p>1. Depending on the number of variables and the value of k, the Hamming distance con- straint possibly defines a very large neighborhood. Given a binary IP with n variables, a feasible solution has n n! k = (n−k)!k! neighbors with a Hamming distance of k (the local tree includes all neighbors with a Hamming distance not larger than k, so the actual search tree is even larger).</p><p>2. Depending on the specific problem, there might be more than one reasonable initial solution for local branching. When a given heuristic returns several promising solutions that would create (partially) disjunct local trees (i.e. their Hamming distance is greater than k), only one neighborhood can be explored.</p><p>3. While a local branching constraint defines a neighborhood around a feasible solution, it provides no further guidance for exploring this neighborhood besides the standard branch and cut strategies (e.g. best bound first search). Other local search heuristics might help to tighten the search tree.</p><p>Preliminary testing with multidimensional knapsack problems confirmed these shortcom- ings. The test instances contain integer programming problems with 100 to 500 variables and 5 to 30 constraints. Detailed results will be discussed in chapter 9.</p><p>The larger test instances (n ≥ 250, d ≥ 10) contain too many variables for using k values larger than approximately 5. This allows at most five variables to flip their values, and likely prohibits significant improvements to the initial solution of a local tree. For any value k &gt; 5 even the local tree defines a subproblem that is often too complex to be solved completely within the given time limit. Additionally, the first initial solution is either derived by a first fit heuristic or by rounding the first LP solution, and both are unlikely to be in a small neighborhood of the optimal solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Extending the Basic Algorithm</head><p>In order to address the shortcomings described in the previous section, three extensions have been added to the standard local branching algorithm. The first one eliminates the restric- tion of sequential execution by allowing to create new local trees before the previous one(s) are finished. On a related issue, the second extension allows to abort local trees before they are completely solved. The last extension tries to reduce subproblem complexity by fixing variables that are less likely to change in the optimal result than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Using Multiple Local Trees</head><p>The first major extension to standard local branching is the support for pseudo-concurrent exploration of several local trees. It removes the burden of relying on one local tree at a time,</p><formula xml:id="formula_13">1 ∆(x, ¯ x 1 ) ≤ k d d d d d d d 2 2 ∆(x, ¯ x 2 ) ≤ k d d d d d d d c 2 3 MIP solver '</formula><p>. . . The framework provides a method to spawn any number of local branching trees simply by providing an initial solution. However, these trees are not parallelized in the sense of a separate process dedicated to a single local tree. Instead, there is still a single pool for subproblems where all local tree nodes are stored. Depending on the chosen tree search strategy, some trees will probably get more time than others with less promising nodes. For example, when a best bound first tree search is performed, a local tree whose nodes have relatively poor upper bounds will get less time than a tree with more promising nodes.</p><p>Unfortunately this kind of pseudo-concurrent exploration likely leads to a duplication of effort in some cases since it is not known a priori which trees will actually be completely solved, and thus, inverse local branching constraints cannot be considered. When a local tree is prematurely terminated, no information about this local tree (except feasible solutions found so far) can be further utilized: the neighborhood defined by this tree cannot be excluded from future local trees because it still may contain the optimal solution.</p><p>The framework achieves parallel exploration by a simple modification to the standard local branching algorithm: before a local tree is not completely solved, the inverse local branching constraint for the rest of the search tree remains inactive. When a local tree is prematurely terminated, the inverse constraint is removed from all future local trees. <ref type="figure" target="#fig_5">Figure 4</ref>.2.1 shows the modified version of the original algorithm previously shown in figure 3.2. All parts of the search tree labeled with the same number are parallelized, thus the inverse constraints on the right hand side are missing. The initial solutions ¯ x 1 and ¯ x 2 are not necessarily related; they are supplied by the higher-level metaheuristic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Aborting Local Trees</head><p>Aborting local trees greatly enhances control over local branching. It becomes possible to impose time or node limits on local trees, abort stagnating local trees in favor of more promis- ing ones, or simply restart local branching with new solutions (possibly generated outside the framework.)</p><p>When a local tree is aborted, the inverse local branching constraint (defining the search tree outside the local tree) must be removed. This also applies to the variable fixing constraint introduced in the next section. Besides that, the only issue is to find some criteria for premature local tree termination. Specifying a time limit is rather complex due to the distributed design of COIN/BCP. Different machines may have different performance ratings, and it would require non-trivial extensions to COIN to track the time spent for each subproblem, potentially across several LP processes, cut generators, and variable generators.</p><p>The local branching framework offers extensive information about the number of nodes processed per local tree instead. Using these facilities, it is easy to impose a node limit on a local tree, or to specify a maximum number of nodes that can be processed in a single local tree before an improvement is found. The downside of this approach is that the number of nodes that can be processed in a given CPU timeslice depends on the complexity of the IP problem. Thus node limits may have to be set heuristically, for example by some constant value multiplied with a weighted sum of the number of variables and the number of constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Tightening the Search Tree by Variable Fixing</head><p>The variable fixing extension to local branching is based on Relaxation Induced Neighborhood Search (RINS) proposed by Danna et al. <ref type="bibr" target="#b7">[8]</ref>. The underlying assumption is that variables having the same integer value in the incumbent solution and in the LP relaxation are likely to be set to their optimal value. By fixing some of those variables to their current value, the local search focuses attention on the fractional variables.</p><p>Compared with reducing search tree size by reducing the value of k, variable fixing gives more freedom to the exploration of the more promising fractional variables while ignoring the allegedly less promising integral variables of the current LP optimum.</p><p>Choosing the best variables to be fixed is a problem by itself. The framework picks a random selection from the set of all variables having the same integer values in the integral and the LP solution. The number of fixed variables is given relative to the total number of variables in the (sub-)problem. In the following, let F 1 denote the indices of variables fixed to one, and F 0 the indices of variables fixed to zero.</p><p>While fixing variables in the local tree can be done directly in the MIP solver, the inverse constraint is a bit more complicated: a node becomes feasible when at least one of the fixed variables changed its value. Ignoring the local branching constraint, this can be achieved through a new row cut of the form</p><formula xml:id="formula_14">(1 − x j ) + x j &gt; 0. (4.1) j∈F 1 j∈F 0</formula><p>When using Hamming distance cuts for local branching both constraints can be combined to a single cut. A solution is feasible outside the local tree when either the Hamming distance is greater than k, or at least one variable flipped. In other words, when a variable flips (and the above inequality becomes valid), the Hamming distance constraint should be considered irrelevant. The following row cut achieves these goals:</p><formula xml:id="formula_15">  ∆(x, ¯ x) &gt; k − k (1 − x j ) +  x j  , (4.2) j∈F 1 j∈F 0</formula><p>where ∆(x, ¯ x) denotes the Hamming distance between the initial solution ¯ x and the current solution x as defined in equation <ref type="bibr">(3.2)</ref>. When one of those fixed variables flips, the right hand side will be less or equal to zero. Since the Hamming distance is always greater or equal to zero, the constraint is satisfied (even if the Hamming distance is smaller than k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Utilizing the Extensions</head><p>When developing a local branching metaheuristic, most often a combination of the extensions described above works best. For example, it is apparent that when aborting local trees, one may also change the local branching parameters for the value of k and the number of variables to be fixed. When using multiple trees, it may be reasonable to start different trees with different local branching parameters.</p><p>The combination of variable fixing and node limits on local trees is a straight-forward way of tightening the search tree as the global solution improves. For example, the search may be started with rather weak constraints, i.e. a relatively high value of k and no or little variable fixing. When the local tree fails to yield new solutions in a given node limit, it is aborted and the parameters are modified. For example, the value of k is decreased or the number of variables to be fixed is increased. Then a new local tree can be created, using the new parameters and the last improved solution from the previous tree (or even the initial solution of the previous tree, since the tightening might lead to a faster convergence towards an improved solution). See chapter 8 for a sample implementation of this tightening scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COIN/BCP</head><p>The implementation of the local branching framework is based on the Branch and Cut and Price framework (BCP) that is part of the Computational Infrastructure for Operations Re- search (COIN) project <ref type="bibr" target="#b25">[28]</ref>. By augmenting an existing Branch and Cut framework re- implementation of a MIP solver is avoided. Furthermore, developers familiar with COIN/BCP can easily use the framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">COIN Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">History</head><p>As research in combinatorial optimization advanced tremendously over the past decades, de- velopers faced increasing complexity when trying to implement efficient versions of their algo- rithms. While standard algorithms like Branch and Cut exist, problem-dependent algorithms often required custom implementations due to problem-dependent methods like variable or cut generation. In the early 1990s a research group was founded with the goal of providing de- velopers a generic software framework which could be adapted to specific problems. This led to the release of COMPSys (Combinatorial Optimization Multi-processing System) <ref type="bibr" target="#b11">[12]</ref>. Af- ter several revisions this project became SYMPHONY (Single-or Multi-Process Optimization over Networks). In 1998, a reimplementation in C++ was started at IBM research.</p><p>As a result, the COIN project was publicly announced in the first half of 2000, including a generic Branch, Cut and Price framework codenamed COIN/BCP. IBM guaranteed to sup- port the online infrastructure for the COIN project for three years, including the website at http://www.coin-or.org, several mailing lists and the source code repository. Much of the ini- tial development was done by IBM researchers, but in the past years the spirit of open source has picked up and has led to various contributions by external researchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Components</head><p>Our framework uses the following components of the COIN project:</p><p>• BCP: the Branch, Cut and Price framework used for solving MIPs.</p><p>• OSI: the Open Solver Interface, a standardized API for calling math programming solvers. It is used by BCP to call a simplex solver for solving the LP relaxations. A wide variety of solvers is supported, most notably the free COIN/CLP and the commer- cial CPLEX MIP solvers.</p><p>• CLP: COIN LP, the COIN project's LP solver. This is a free implementation of a simplex solver.</p><p>• CGL: A Cut Generator Library for generating standard cuts for IP problems like Gomory cuts or knapsack cover cuts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Design of COIN/BCP</head><p>The following introduction to the design of COIN/BCP is based on the user manual by Ralphs and Ladányi <ref type="bibr">[36]</ref>. The major design goals for COIN/BCP are portability, efficiency and ease of use. It provides a black-box design with a clean end-user interface that keeps most of the actual implementation hidden from the user. COIN/BCP was developed using an object-oriented approach. The central objects are cuts and variables that can be used as base classes for user-defined objects. Additionally, user ob- jects provide methods that can be re-implemented to alter specific aspects of the algorithm, like tightening variables or adding cuts. While this approach enables a straight-forward imple- mentation for many combinatorial optimization tasks, there is still enough flexibility left even for implementing complex meta-algorithms like local branching with little or no changes of the COIN/BCP code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Variables and Cuts</head><p>Since search trees can easily contain hundreds of thousands of nodes, a simple object-oriented approach storing the variables and cuts for each node in objects leads to excessive memory consumption. COIN/BCP tries to reduce memory usage by keeping the number of active vari- ables and cuts (the active set) as small as possible by using data structures that make it possible to move objects in and out of the active set efficiently. This is accomplished by maintaining an abstract representation of each global object that keeps information about adding or removing it from a particular problem instance (i.e. a particular LP relaxation).</p><p>In other words, a variable does not represent a specific column of a LP relaxation, but is an abstract object that can be realized as a specific column of a LP relaxation. Similarly, a cut does not describe a specific row of a LP relaxation, but it contains an abstract cut that can be realized as a row in a LP relaxation.</p><p>COIN/BCP distinguishes between two groups of cuts and variables: so-called core cuts and core variables that are active in all subproblems, and extra cuts and extra variables that can be added and removed dynamically. Extra cuts help to reduce the active set, but require additional bookkeeping when adding or removing them from the formulation. There are two different types of extra cuts:</p><p>• Indexed cuts are represented by a unique index value. The user must be able to generate the corresponding row cut when given the index number by using some kind of a virtual global list known only to the user. This is the most efficient way of representing extra cuts in a formulation and is particularly useful when the number of cuts is very high and most likely only few are violated by any feasible solution. Using indexed cuts, only constraints that are violated by a given LP solution have to be realized as rows in the LP relaxation. The downside is the extra bookkeeping involved for adding and removing those cuts, and the user must find an enumeration scheme when using indexed cuts.</p><p>• Algorithmic cuts give the user absolute freedom, especially in the case when the number of cuts is not known a priori and the cuts cannot be enumerated. The only requirement is that the user must be able to generate the corresponding row when given a set of active variables by some sort of algorithm. The downside, as with indexed cuts, is the fair amount of bookkeeping involved for creating and removing algorithmic cuts.</p><p>Indexed and algorithmic variables work in a similar way. Indexed variables are generated by the user when given an index number. They are useful when given a big number of variables while most likely only few of them would be different from zero. Adding all variables to the core matrix would increase the problem complexity enormously. Similar to algorithmic cuts, algorithmic variables can describe any user-defined constraint that is violated by a given LP solution. Indexed and algorithmic variables are also essential for column generation algorithms that generate variables during the computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">COIN/BCP modules</head><p>COIN/BCP is grouped into four independent modules. They communicate using a message- passing protocol which is defined in a separate API. Thus they are well equipped for parallel execution, even on separate machines connected by a network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">The Tree Manager Module</head><p>The tree manager (TM) module represents the master process of the computation algorithm. It is responsible for problem initialization and controls the other modules. There is only one tree manager for any computation. Its main functions are:</p><p>• Reading parameters and the problem instance from the command line or from a file.</p><p>• Constructing the root node of the search tree.</p><p>• Beginning the computation by creating LP processes (see below) to solve individual nodes of the search tree.</p><p>• Receiving new solutions from the child LP modules and storing the best one.</p><p>• Receiving new subproblems and storing them for later processing.</p><p>• Pruning subproblems based on the global upper bound.</p><p>• Sending stored subproblems to idle LP processes.</p><p>• Printing the final result when the computation has finished (i.e. all subprocesses are in an idle state and all subproblems have been solved.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">The Linear Programming Module</head><p>The linear programming (LP) module performs the actual computation, i.e. the bounding and branching operations. Its main functionality includes:</p><p>• Requesting new subproblems from the tree manager.</p><p>• Receiving and processing subproblems.</p><p>• Choosing branching objects and sending the resulting subproblems back to the tree man- ager.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">The Cut Generator Module</head><p>Since cut generation may be computationally expensive, it can be performed inside a separate cut generator module. It receives a LP solution by a LP process, tries to generate valid in- equalities violated by this solution, and sends the cuts back to the LP solver. Then it remains in an idle state until a new solution is sent to the cut generator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">The Variable Generator Module</head><p>Similar to the cut generator module, the variable generator module's only responsibility is to generate variables for a given LP solution. If any variables are generated, they are sent back to the requesting LP process and the variable generator module keeps waiting for new solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">The Linear Programming Module</head><p>For a better understanding of our local branching extensions, a deeper explanation of the linear programming module is required. The LP module uses a LP engine for finding upper bounds, generates cuts and variables when necessary and performs branching operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">The LP Engine</head><p>The LP module uses the Open Solver Interface (OSI) in order to communicate with third-party LP libraries or LP engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Managing the LP Relaxation</head><p>The LP module is responsible for managing extra variables and cuts. It does so by maintaining a local cut pool where any generated extra cuts are stored. In each iteration, up to a specified number of the strongest cuts are added to the problem. A cut's strongness corresponds to the degree of violation in the current LP solution. Cuts that proved ineffective over a specified number of iterations are purged from the cut pool. Variables can be tightened by user-defined methods before solving the LP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3">Branching</head><p>Branching is performed when no new cuts were generated or the user forces branching. A branching object describing all of the new cuts and variables and their corresponding bounds is generated and sent back to the tree manager. The branching operation can be based on cuts or on variables. Optionally strong branching can be performed. In strong branching, several branching objects are created and then pre-solved, i.e. quickly optimized in a probably non- optimal way. The most promising candidate, based on some internal rule (e.g. best objective value) or on the user's decision, is used for branching. By default, COIN/BCP uses branching on fractional variables. One (standard branching) or several (strong branching) fractional variables are selected and corresponding branching objects are generated. The selection of variables can be user-defined or based on some internal rule, COIN/BCP allows to specify the number of the most fractional variables (i.e. those nearest to 0.5 in a binary optimization problem) and the number of those variables close to one to be selected for (strong) branching. When the total number of variables is greater than one, strong branching has to be enabled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Parallelizing COIN/BCP</head><p>Since Branch and Cut methods can heavily benefit from parallelization one design goal of COIN/BCP was that of parallelization. There are two main sources of parallelism: Obviously, each subproblem of the candidate list can be solved independently from the others. This can be accomplished by spawning more than one instance of the LP module, either on one machine (reasonable for multi-processor systems) or on a cluster of computers connected by a network.</p><p>The second source lies within the processing of a single subproblem: the individual tasks can be parallelized with the LP solver, which means a node can be completely processed in roughly the time it takes the LP engine to solve the relaxation. This is the reason that the potentially expensive cut and variable generators are placed in separate modules outside the LP module.</p><p>In COIN/BCP, the architecture is based on a master/slave model. The tree manager as- sumes the role of the master process in control of slave processes that execute its orders. The tree manager is responsible for spawning at least one process of each type (LP, cut generation, variable generation) and keeping them busy until all subproblems are solved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Inter-Process Communication</head><p>COIN/BCP allows the user to choose between sequential and parallel execution. It is based on an abstract message passing protocol with parallel and sequential implementations. The former is an interface to the Parallel Virtual Machine (PVM) protocol, the latter emulates a parallel machine that effectively executes the algorithm sequentially inside a single process. Support for other communication frameworks can be added by implementing the abstract base class of COIN/BCP's messaging framework.</p><p>One instance of an object in memory can never be shared between different modules since these modules might be executed in different processes or on different machines. Instead, objects can be packed and unpacked into a COIN-specific buffer class (BCP buffer). The mes- saging framework uses these buffers for communication between modules, thus it is possible to transmit user-defined objects by implementing methods for packing and unpacking objects of these types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Fault Tolerance</head><p>Using distributed computation, fault tolerance becomes important because a single crashed machine should not cause the termination of the whole program. For this purpose, the tree manager tracks all processes and restarts them as necessary. When a process is lost, the subproblems assigned to this process are reassigned to other processes. Additionally, new machines can be added to the distributed network on the fly without having to restart the com- putation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Developing Applications with COIN/BCP</head><p>This section gives a brief overview of the basic steps for developing an application with COIN/BCP. It focuses on the parts that will be modified in our local branching framework, a more complete description can be found in the COIN/BCP user manual <ref type="bibr">[36]</ref>.</p><p>Developing an application for a specific problem basically means subclassing some of COIN/BCP's provided classes, implementing some abstract methods and overriding others to diverge from default behavior. The main classes designed for derivation by the user are:</p><p>• BCP lp user: The user-defined LP module extension. By subclassing it it is possible to modify the LP module's decisions (e.g. whether to branch or generate cuts) and to store problem-specific data. One object of this type is generated for each LP process.</p><p>• BCP tm user: The user-defined tree manager extension. It is embedded into the tree manager module and is responsible among other things for initializing the problem and deciding on the tree search strategy.</p><p>• BCP vg user is used for implementing user-defined variable generators.</p><p>• BCP cg user provides a possibility to generate cuts inside a separate process.</p><p>• USER initialize: This class is used for instantiating objects of the derived BCP xx user classes.</p><p>• BCP cut: This abstract base class is used for describing cuts, allowing the user to derive problem-specific cut classes. The subclasses for core, indexed and algorithmic cuts are derived from this class.</p><p>• BCP var: This class can be subclassed for describing user-defined variable types. Sub- classes for core, indexed and algorithmic variables are already defined.</p><p>• BCP solution: The abstract base class for describing feasible solutions. A generic implementation exists (BCP solution generic).</p><p>In the BCP tm user and BCP lp user classes there are some key methods that are of great importance for the implementation of our local branching framework. For a complete descrip- tion of these classes, refer to the autogenerated documentation and the user's manual <ref type="bibr">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.1">The BCP tm user Class</head><p>• pack module data(): This method is invoked to pack the data needed to start the com- putation in other modules. This can be used for sending problem-specific data (e.g. local branching parameters) to the LP module.</p><p>• unpack feasible solution(): This method is called when the tree manager received a new feasible solution. By overriding this method the user gets every feasible solution found by a LP module, which can be used for further enhancements (e.g. crossover between two or more solutions when using a genetic algorithm).</p><p>• initialize core() and create root() are used for initializing the problem (probably by reading it from a file) and setting up the root node of the search tree.</p><p>• compare tree nodes(): This method is essential for the tree search strategy. It is in- voked by the tree manager when a new tree node was received which will be inserted in the candidate queue. By overriding this method it is possible to use an arbitrary tree search strategy, we use this to calculate local tree nodes before any other tree nodes. The standard implementation can be configured by a parameter to perform either a depth first, breadth first, or best bound first tree search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The candidate queue</head><p>The tree manager keeps a list of all unprocessed subproblems in a single candidate queue. This is also known as a single-pool BCP algorithm. The candidate queue is implemented in the BCP node queue class as a heap-based priority queue. When the tree manager receives new subproblems from one of the LP processes, the priority of the item is determined indirectly by repeatedly calling the binary compare tree nodes() function until the final position of the subproblem has been found. The subproblems remain in the candidate queue until taken out by the tree manager for an idle LP process. Since the lower bound may have increased since the subproblem was inserted into the queue, the subproblem may be pruned before it is actually sent to an LP process. In this case, the next subproblem is taken from the queue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.2">The BCP lp user Class</head><p>• unpack module data(): This method is the counterpart to the pack module data() method of the BCP tm user class. It receives the information sent by the tree manager and can be used to initialize problem-specific data in a LP module.</p><p>• initialize solver interface() can be overridden to use a specific LP engine (like COIN's own CLP solver or the commercial CPLEX solver).</p><p>• initialize new search tree node(): This method is called before a new tree node is solved, providing an opportunity to tighten or fix variables.</p><p>• generate heuristic solution(): When the problem's structure allows to quickly gen- erate feasible solutions based on the current LP solution (e.g. by clever rounding of fractional values), this method can be overridden to generate feasible solutions. By finding good solutions the search tree size can be drastically reduced.</p><p>• select branching candidates(): This method decides whether to branch or not, and selects branching candidates. The default implementation uses branching on fractional variables, the local branching framework will override this method to implement local branching cuts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 6</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation of the Framework</head><p>The main intention for creating a local branching framework was to provide a clean, reliable and extendable framework for local branching metaheuristics. The main design goals of the local branching framework are:</p><p>• Problem-independent functionality: The local branching framework should be usable for any binary IP problem. Therefore, it should not make problem-dependent assumptions and separate local branching logic from problem-dependent functionality.</p><p>• Explicit local branching metaheuristics: It should be possible to literally write a meta- heuristic function without being forced to scatter the algorithm over many COIN/BCP classes.</p><p>• "Transparency": The implementation of an algorithm for COIN/BCP should not be much different from the implementation using our local branching framework. Further- more, existing COIN/BCP advantages such as parallelization should not be affected by local branching.</p><p>• Avoid changes to COIN/BCP sourcecode: It would have been possible to embed local branching directly into the COIN/BCP source repository. However, this would tie lo- cal branching very close to COIN/BCP's internals which are subject to change at will. Additionally, it would be much harder to integrate future bugfixes and enhancements of COIN/BCP.</p><p>• Hide COIN/BCP internals: The complexity of COIN/BCP should be hidden from the local branching metaheuristic. Instead, service methods for querying the current state of local branching should be provided.</p><p>These goals were met by subclassing the predefined user classes of COIN/BCP (mainly BCP lp user and BCP tm user) and embedding the local branching algorithm in those sub- classes. Additionally, a local tree manager class provides handlers and parameters for con- trolling the flow of the local branching algorithm. This way most of the complexity and the COIN/BCP-specific implementation is hidden from the user.</p><p>Ideally, enabling local branching for an existing COIN/BCP program would be done by replacing the COIN/BCP user classes with the framework's derived classes. Of course, some additional initialization has to be performed since some classes of the framework need to be subclassed by the user again.</p><p>The main classes of the framework are:</p><p>• LB tm: the local branching framework's tree manager implementation. It is responsible for managing local trees, creating and terminating local trees, and controlling the LP modules.</p><p>• LB lp: the local branching framework's LP module. It executes the tree manager's in- structions regarding local branching, i.e. creating local cuts in the branching operations according to the given parameters (e.g. value of k).</p><p>• LB MetaHeuristic: the user's control module. It provides methods for the user to create and terminate local trees, provides statistical data about all local trees, and handlers that are repeatedly called and are intended to be used to implement another high-level heuristic like an evolutionary algorithm. When using the framework, this is the main class the user has to care about. Unlike COIN/BCP modules, this module is not executed within its own process, but is attached to the tree manager module.</p><p>• LB init: the local branching framework's implementation of the USER initialize class. It is used to initialize instances of the tree manager (LB tm) and LP modules (LB lp).</p><p>Currently LB init does not implement any initialization logic on its own, it merely exists for extension purposes.</p><p>• LB cut: a simple row cut used for the Hamming distance constraint.</p><p>• LocalTreeManager: an internal data manager class that is responsible for tracking all local trees, managing the found solutions for local trees, and maintaining a list of all currently active local trees. The user probably does not need to override this class except when additional data about local trees should be stored.</p><p>• LocalTreeIndex: used to store information about all existing local trees. An instance of this class is shared by the LB MetaHeuristic and LocalTreeManager objects, the latter being mostly responsible for updating the information in the LocalTreeIndex, while the metaheuristic object can use the index to determine its actions (e.g. terminating a local tree that appears to be stagnating).</p><p>• LocalTree: keeps information about a single local tree. Everything the tree manager (and therefore the other local branching classes) knows about a local tree is kept in a LocalTree object. For example, it contains information about the number of active nodes, the number of created nodes since the last improvement of the objective value or the current best solution found in the tree. There are four classes that must always be subclassed for a working program. The methods to be implemented are defined by the COIN/BCP superclasses and have to be implemented anyway to get a working program (except for the LB MetaHeuristic subclass).</p><p>• LB tm: pack cut algo() and unpack cut algo() must be able to pack and unpack LB cut row cuts (although other custom cut types can be supported too). initialize core() must be implemented to initialize the core matrix, ending with a call to LB tm's version of this method to complete initialization. The user must also implement the create lbh() method to return a new instance of his implementation of the LB MetaHeuristic subclass. • LB lp: pack cut algo() and unpack cut algo() have to be implemented similarly to the user's LB tm implementation. initialize solver interface() has to create the LP engine for the LP process. generate heuristic solution() may be implemented to obtain feasible solutions from LP results (e.g. by clever rounding).</p><p>• LB init: lp init() and tm init() are implemented to return new instances of the user's LB lp and LB tm subclasses. The tm init() method is a good place to initialize the problem instance. LB tm's initialize() method has to be called immediately after the tree manager has been created.</p><p>• LB MetaHeuristic: at least initial solution() must be implemented to return the initial solution used for the very first local tree. The user probably wants to override some other methods (especially tree finished()) in order to create more local trees during the computation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Integrating Local Branching into COIN/BCP</head><p>The main effort of implementing local branching went into the interaction between the local branching metaheuristic and the COIN Branch and Cut framework. A major goal was to exploit the existing framework as much as possible. Rewriting parts of the COIN/BCP code to implement local branching would leave the user stuck to exactly one version of COIN/BCP, without having the benefit of upcoming enhancements and bugfixes. Our implementation requires only minimal patches of existing COIN/BCP code where the original user classes did not provide the necessary flexibility. These changes are described in appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Identifying Local Tree Nodes</head><p>COIN/BCP provides a mechanism to attach an user data object to nodes for storing individual information about each node. By creating a subclass of BCP user data and creating methods to pack and unpack objects of this subclass to a BCP buffer, the LP modules can attach any user-defined data to a single node of the search tree.</p><p>The local branching framework uses this method to assign each node a LB user data ob- ject. Its main components are the node type, the unique number of its local tree if it is in a local tree and some internal information. The node type distinguishes three types of nodes:</p><p>• UD LocalRoot: represents a local root node, i.e. the root node of a local tree.</p><p>• UD NormalRoot: represent a normal root node, i.e. the root node for the search tree outside the local tree.</p><p>• UD LocalNode: represents a node in a local tree.</p><p>Note that nodes outside a local tree do not have a type, in fact they have no assigned user data objects at all since there is no extended information that might be of interest. The terms local and normal root node emerged from the way COIN/BCP handles branching: when a subproblem is branched, appropriate branching objects are created (containing the variables or cuts to be branched on), and these are used to create two or more child nodes that represent the root nodes of the new subproblems. When local branching is initiated, branching occurs on a local branching constraint, i.e. on a cut. Two children are created: one with a Hamming distance of ∆(x, ¯ x) ≤ k, the other with a Hamming distance of ∆(x, ¯ x) &gt; k. These child nodes represent the root nodes of the new subproblems: the first being the local root node, the second being the normal root node.</p><p>The children of the local root node form a local tree and are assigned an unique identifi- cation number (ID), represented by the class LocalTreeId. In order to guarantee unique tree IDs even when the trees are created in different LP processes, a LocalTreeId consists of the internal COIN index number of its root node and the unique index number of the LP process where it was created (supplied by the tree manager). The other classes do not care about Lo- calTreeId's internals, all they need are the pre-defined operators (==, ! =, &lt;) and the packing and unpacking methods for transferring LocalTreeIds between modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">The LB tm Module</head><p>The LB tm module provides our own implementation of COIN/BCP's tree manager module. It is derived from BCP tm user and implements some of its methods to integrate local branching into the tree manager. It provides the LP modules with commands concerning local branching, is able to create local trees by transmitting the appropriate root nodes and keeps track of the number of created and pruned nodes for all local trees.</p><p>LB tm implements several methods of the BCP tm user class:</p><p>• pack module data(): sends miscellaneous initialization information to the LP process. This includes the initial solution for local branching, if local branching is enabled at all, and the value of k to be used for the first local tree.</p><p>• pack user data(): this method is called by COIN/BCP when a node with an user data object is sent to a LP module. Additionally to packing the node's LB user data object, the tree manager updates its tree statistics about pruned nodes and sends additional in- formation when a new local tree is started (i.e. the initial solution, value of k, and some other necessary information).</p><p>• unpack user data(): used to unpack an LB user data object sent from a LP process.</p><p>• unpack feasible solution(): this method is invoked by COIN/BCP when a new feasible solution was sent by a LP process. This method unpacks the feasible solution (of type BCP solution generic) and updates the LocalTreeIndex's statistics when it was found in a local tree. When a new global optimum is found, the solution is broadcasted to all active LP processes using COIN/BCP's messaging framework.</p><p>• compare tree nodes(): this binary comparison function is crucial for the local branch- ing metaheuristic. It is called by COIN/BCP to insert a new tree node in the internal can- didate queue. The nodes are ordered by priority, and the first node is the next to be sent to an idle LP process. COIN/BCP implements this method in a way that it represents a certain tree search strategy (i.e. ordering nodes by level for breadth-first or by upper bound for best bound first search). The local branching framework extends this method by always preferring local tree nodes to "normal" nodes. When both nodes are local tree nodes (or both are normal nodes), the COIN/BCP comparison function is called.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">The LB lp Module</head><p>The LB lp module implements local branching for the LP module. It executes the commands sent from the tree manager (LB tm) module, and is able to create local trees when a normal root node is sent.</p><p>The following methods of the BCP lp user superclass have been implemented:</p><p>• unpack module data(): the counterpart to LB tm::pack module data(). Initialization of this LP process is performed, and common parameters like the value of k are set, and the initial feasible solution used for local branching is unpacked.</p><p>• pack user data(): packs an LB user data object to a buffer.</p><p>• unpack user data(): unpacks an user data object. This method is called by COIN/BCP when a new node with an attached user data object arrived from the tree manager. The additional information sent by LB tm::pack user data() when a new local tree should be created is also stored in the LB lp object.</p><p>• unpack user message(): this function was patched into COIN/BCP to allow trans- mitting user-defined messages between the tree manager and LP modules. By setting a certain message tag number this method gets called when the message arrives at the process.</p><p>• pack feasible solution(): packs a feasible solution to be sent to the tree manager. Ad- ditional to its predefined behavior, the local branching framework adds the current user data object if the feasible solution was generated in a local tree. This makes it possible for the tree manager to assign each received solution to the local tree where it was found.</p><p>• initialize new search tree node(): this function gets called before a node is processed (i.e. before the LP relaxation is computed). This allows the user to tighten variable and cut bounds. The local branching framework performs two major tasks in this method:</p><p>-When the local root node of a new tree is processed, variable fixing might occur. A given percentage of all free variables that is equal in the initial solution of the local tree and the current LP result is fixed to its value.</p><p>-As explained in section 4.2.3, the inverse constraint when fixing variables is ex- pressed as a row cut. Depending on whether the corresponding local tree was completely solved, this row cut has to be (de-)activated when the normal root node is processed.</p><p>• select branching candidates(): this method is invoked by COIN/BCP when the LP relaxation of a subproblem has been solved. This method can either decide to repro- cess the subproblem when cuts have been added, or to return one or more branching objects. When a local tree should be created, an appropriate local branching constraint (a Hamming distance cut by default) is created and a branching object is returned. The local branching cut is created by the virtual method create local constraint() that can be re-implemented by the user.</p><p>• set actions for children(): when a branching object was chosen, the LP process de- cides for each child whether to keep it for immediate processing or to return it to the tree manager. At most one child can be kept in a LP process. The local branching framework uses this method to force processing of the local root node when a new tree was created.</p><p>• set user data for children(): the user data information for the child nodes of a branch- ing object is generated after the branching object was chosen. When a new local tree is created, this method sets the local tree identification number and other internal data about the local tree. When an existing local tree is branched, it propagates the informa- tion stored in the current user data object to its children.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Creating the Hamming distance cut</head><p>LB lp::create hamming constraint() generates a Hamming distance constraint used for local branching. It resembles the local branching constraint as described by Fischetti and Lodi. In its current implementation it is restricted to binary IPs. It can be used as a template for custom local cut generators. Note that create hamming constraint() is not virtual, the framework calls the virtual func- tion create local constraint() when creating local cuts which in turn calls the Hamming dis- tance generator. When implementing new cuts, simply override the latter virtual function. Both functions return a local branching object and get information about the current node through their input parameters:</p><p>• lpres represents the current LP optimum.</p><p>• vars contains all available variables at the current node.</p><p>• cuts contains all current cuts. The generated local cut(s) can not be appended to this collection, they must be contained in the returned branching object.</p><p>• br sol is the feasible solution sent from the tree manager to be used for local branching (the initial solution).</p><p>The creation of the Hamming distance constraint is straight-forward: first, the feasible solution br sol is unpacked to a local array for easier access. Then the variable coefficients of the cut are generated. Each variable that flips its value in any feasible solution must be detected, and the sum of all changed variables must not be greater than k. Thus, the coefficients for the cut are:</p><formula xml:id="formula_16">c j := 1 if j ∈ S 0 = {j : ¯ x j = 0}, -1 if j ∈ S 1 = {j : ¯ x j = 1},<label>(6.1)</label></formula><p>where ¯ x is the initial solution for the local tree. The local cut is then described as</p><formula xml:id="formula_17">0 ≤ x j + (1 − x j ) ≤ k (6.2) j∈S 0 j∈S 1</formula><p>for any feasible solution x. Simple transformation leads to the row constraint as it will be passed to COIN/BCP:</p><formula xml:id="formula_18">− |S 1 | ≤ x j − x j ≤ k − |S 1 |. (6.3) j∈S 0 j∈S 1</formula><p>After creating a row cut with the bounds for the local tree and the rest of the search tree, some variables are selected for fixing if the tree manager requested variable fixing for this local tree. The indices of all free (non-fixed) variables equal in both the initial and the current LP solution are stored in an array, which in turn is used to randomly pick the requested number of variables. An additional constraint for the normal tree is added as described in section 4.2.3. The variables of the local tree will be fixed when initialize new search tree node() is called for the local root node. The list of picked variables can be kept inside the LB lp module since the local root node is processed immediately after branching by the same process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Managing Local Trees</head><p>In order to provide a clean separation between the low-level local branching implementation represented by the LB tm and LB lp classes and global local branching state information, the LocalTreeManager class was introduced.</p><p>It encapsulates all methods for tracking local trees, such as maintaining active node num- bers and assigning found solutions to local trees. A LocalTreeIndex object is used for storing the data, which is shared with the LB MetaHeuristic objects that is responsible for controlling the local branching algorithm.</p><p>To emphasize the different purposes of these classes, a quick overview of the control dis- tribution follows. All classes below (except LB lp) are effectively singletons inside the LB tm process.</p><p>• The LB lp module(s) process individual subproblems.</p><p>• The LB tm module assigns subproblems to LB lp modules and receives all new sub- problems and solutions. When it receives information about a local tree (e.g. a new solution was found), the appropriate LocalTreeManager method is called. It also polls the LB MetaHeuristic object for commands, e.g. creation or termination of local trees.</p><p>• The LocalTreeManager is mostly a passive module that provides data manage- ment routines concerning local trees. Its only active part lies in the activation of LB MetaHeuristic routines on certain events, e.g. calling a method to notify the meta heuristic of a new solution or a terminated tree.</p><p>• The LB MetaHeuristic object is mainly responsible for controlling local branching - that is, creating new local trees or terminating existing ones. Additionally, the initial solution for the first local tree is generated inside this class.</p><p>• The LocalTreeIndex serves as shared data pool for the LocalTreeManager and LB MetaHeuristic classes. The former is responsible for keeping the information up to date, the latter uses it mainly as decision source (e.g. to terminate all trees with more than 50.000 nodes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">The LocalTreeIndex</head><p>The LocalTreeIndex gathers information about all local trees and provides miscellaneous sta- tistical information, e.g. the number of active trees or the number of created nodes per tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The LocalTree class</head><p>A local tree is represented by a LocalTree object. This class provides several get and set methods. The latter are called by the LocalTreeManager, but the former can be also used in some LB MetaHeuristic methods to query miscellaneous information about the given local tree. The most significant properties of a local tree are:</p><p>• get nodes created() returns the total number of created nodes in this local tree.</p><p>• get nodes deleted() returns the total number of deleted nodes in this subtree. This in- cludes pruned nodes (because of their upper bound), infeasible nodes, and nodes deleted by the tree manager when a local tree was terminated.</p><p>• get active nodes() returns the number of active (i.e. not processed and not deleted) nodes, in other words the difference between created and deleted nodes. A local tree with no active nodes is terminated, all active local tree must have at least one node that has not been deleted.</p><p>• get nodes created since improvement() returns the number of created nodes since the last improvement of the best solution in this local tree.</p><p>• get nodes deleted since improvement() is the equivalent number for deleted nodes.</p><p>• get terminated() returns true when this local tree has been explicitly terminated. This is a helper function for the user to avoid terminating the same tree several times (since tree termination might not occur immediately, depending on the number of active nodes.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The LocalTreeIndex class</head><p>The LocalTreeIndex class stores all local trees in an associative container (using the previ- ously introduced LocalTreeIds as key and LocalTree as value type). The local tree manager is responsible for creating new entries when necessary, so the LocalTreeIndex actually provides a single service method: find() accepts a LocalTreeId as parameter and returns the corresponding LocalTree object, or throws an exception when the local tree does not exist.</p><p>Additionally, miscellaneous statistical information about all local trees (e.g. the best global solution found so far, or the number of nodes created since the last tree was terminated) is provided through getter methods similar to those in the LocalTree class. For a complete de- scription, refer to the autogenerated class documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">The LocalTreeManager</head><p>The LocalTreeManager is instantiated by the LB tm object and assumes control over the Lo- calTreeIndex data storage. It provides a clean interface for all tasks concerning local tree in- formation, such as assigning solutions to local trees, adding created nodes or removing deleted nodes. Additionally, it maintains the lists for active, terminated and aborted trees in the Lo- calTreeIndex. The user probably does not want to interfere with the LocalTreeManager's methods, they are automatically called from LB tm when needed. Instead, the LocalTreeMan- ager delegates control to the LB MetaHeuristic object, which will be implemented by the user and is responsible for local tree control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Controlling Local Branching</head><p>The LB MetaHeuristic class provides a clean and simple encapsulation of the local branching algorithm. Its main goal is to provide an interface to the local branching framework without requiring the user to deal with the internals of COIN and the framework. LB MetaHeuristic is an abstract class that does not implement any local branching functionality. However, it takes little to implement the standard local branching algorithm.</p><p>LB MetaHeuristic operates asynchronously in the sense that its actions, for example local tree creation, are not immediately executed. Instead, internal flags indicate the action to be taken by the tree manager when it is possible. This limitation is caused by the internal structure of COIN which imposes certain limits on direct control of the computation in exchange for performance, efficiency and parallelism. This should be taken into account when advanced tasks, such as creating multiple local trees at once, do not work as expected.</p><p>Local branching control is basically performed by two operations: creating local trees and terminating local trees. Additional parameters influence local branching, such as the value of k, or the amount of variables to be fixed. LB MetaHeuristic offers the following methods and data fields for local branching control:</p><p>• create tree() sets internal variables to tell the tree manager that a new tree should be created. The initial solution can be passed as a parameter, or the current incumbent solution will be used. Note that subsequent calls to this function have no effect since the actual tree creation is executed asynchronously by the tree manager. For creating multiple trees at once, the calls to create tree() have to be synchronized, for example using the tree created() handler described below.</p><p>• terminate tree() tells the tree manager to terminate the local tree with the given Local- TreeId.</p><p>• terminate active trees() terminates all active trees. This may be especially useful for terminating local branching.</p><p>• lb k contains the value of k to be used for new local trees.</p><p>• lb fixvars contains the amount of variables to be fixed relative to the total number of variables.</p><p>The local branching algorithm is determined by LB MetaHeuristic's reaction to certain events. These event handlers are called by the LocalTreeManager and offer great degrees of freedom for creating own local branching metaheuristics. The event handlers are:</p><p>• initial solution() is called to obtain the initial solution for the very first local tree. The parameters lb k and lb fixvars might also be set in this procedure.</p><p>• tree created() is called when a new tree was generated. The corresponding tree iden- tification and the tree object are passed as references. After creating a tree with cre- ate tree(), this is the first occasion to create another local tree.</p><p>• tree finished() is called when a tree is finished, i.e. it has no active nodes remaining.</p><p>• new node generated() is called whenever a new node was generated in a local tree. Since this method gets called regularly, time-related tasks (such as terminating local trees above a certain node limit) can be implemented in this method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Implementing a Basic Local Branching Algorithm</head><p>In order to emphasize how the LB MetaHeuristic object can be used for implementing local branching, consider the following task. Standard local branching should be implemented, i.e. one active tree at any given time, with a node limit of 10.000 nodes per local tree. This is accomplished by implementing LB MetaHeuristic's event handlers in the following way:</p><p>• initial solution() returns a heuristically generated solution and sets lb k and lb fixvars to the desired values.</p><p>• tree terminated() creates a new local tree by calling create tree(). This single function call implements the standard sequential local branching algorithm and ensures that there is always only one active local tree.</p><p>• new node generated() uses the LocalTreeIndex object (index) to fetch the number of created nodes for the active tree and calls terminate tree() when the node limit was exceeded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 7</head><p>Multidimensional Knapsack Problems</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Introduction</head><p>Given a knapsack of fixed capacity c and n items with profits p j and weights w j for j = 1 . . . n, the task is to find the most valuable subset of items that fits into the knapsack. We assume that p 1 . . . p n and w 1 . . . w n are positive integers. The unbounded knapsack problem does not limit the number of times each item type can be used. In the binary or 0-1 knapsack problem, the number of items is constrained to be 0 or 1. The multiple-choice knapsack problem requires the items to be chosen from disjoint classes. In the multiple knapsack problem, several knapsacks are to be filled simultaneously. The rest of this chapter will be based on binary knapsack problems. Formally, a binary knapsack problem can be stated as:</p><formula xml:id="formula_19">maximize n j=1 p j x j (objective function) (7.1) subject to n j=1 w j x j ≤ c (constraint) x j ∈ {0, 1} j = 1 . . . n</formula><p>In this formulation, x j is 1 when item j is included in the knapsack and 0 otherwise. p 1 . . . p n contains the profit (or value) for each item, and w 1 . . . w n the weight or resource usage. Note that it is trivial to obtain a (poor) feasible solution x j = 0 for all j.</p><p>This section is based on the book on knapsack problems by Pisinger et al. <ref type="bibr" target="#b18">[21]</ref> which provides a thorough reference for the family of knapsack problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1">Algorithms for Knapsack Problems</head><p>All knapsack problems are NP-hard, therefore it is highly unlikely to find an optimal algorithm with a polynomial worst-case time complexity. Despite this, there are algorithms that achieve reasonable solution times also for large instances. The following overview of exact and ap- proximate algorithms is based on <ref type="bibr" target="#b29">[32]</ref>. Note that the multidimensional knapsack problem is more complex and thus usually not covered by highly effective approaches like the dynamic programming approach.</p><p>• Branch and Bound: A Branch and Bound implementation for knapsack problems was first proposed by P. J. Kolesar in 1967 <ref type="bibr" target="#b20">[23]</ref>.</p><p>• Dynamic programming: Basically an enumeration algorithm which can achieve excel- lent performance on some families of knapsack problems, especially those bounded by relatively low integer capacity. For these it is possible to obtain an optimal solution in Θ(nc) with n being the number of items and c the knapsack capacity.</p><p>• State space relaxation: A dynamic programming relaxation where the coefficients are scaled by a fixed value. The complexity of an algorithm may be decreased, but the optimal solution may no longer be found. This is an interesting approach for efficient approximate algorithms.</p><p>• Preprocessing: Some variables may be fixed at their optimal values by using bounding tests.</p><p>• Fully polynomial time approximation schemes (FPTAS): These are heuristics that can find a solution z with a relative error bounded by any constant value ε, i.e.</p><formula xml:id="formula_20">z−z * z * ≤ ε,<label>where</label></formula><p>z * is the optimal solution value, in polynomial time bounded by the length of the input and 1 ε . A fully polynomial approximation scheme for the binary knapsack problem was presented by <ref type="bibr">Ibarra and Kim in 1975 [19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Multidimensional Knapsack Problems</head><p>The generalization of the knapsack problem to more than a single constraint is the multidimen- sional knapsack problem, also known as d-dimensional knapsack problem (d-KP) or multicon- straint knapsack problem. It is defined as an integer program with the following structure:</p><formula xml:id="formula_21">maximize n j=1 p j x j subject to n j=1 w ij x j ≤ c i i = 1 . . . d (7.2) x j ∈ {0, 1} j = 1 . . . n</formula><p>An equivalent formulation using vectors is:</p><formula xml:id="formula_22">maximize c T x subject to W x ≤ c (7.3) x ∈ {0, 1} n , c ∈ N d 0 , W ∈ N 0 d×n</formula><p>There are two main characteristics of integer programs that describe multidimensional knapsack problems: First, they are particular difficult instances of integer programming be- cause the constraint matrix W is unusually dense, while most other relevant classes are defined by sparse constraint matrices. But analogously to other knapsack problems it is also particu- larly easy to find a feasible solution: x j = 0 for all j, whereas in general integer programming finding feasible solutions might be as hard as finding an optimal solution.</p><p>Typically the number of items n exceeds the number of constraints d. A rough bound for computing optimal solutions of multidimensional knapsacks with todays algorithms and computers is n = 500 and d = 10.</p><p>It has been shown by <ref type="bibr">Korte and Schrader in 1979 [24]</ref> that the existence of a fully polyno- mial time approximation scheme for a multidimensional knapsack problem even with only two constraints (d = 2) would imply P = NP , i.e. that every NP-hard problem could be solved in polynomial time. However, there exists a polynomial time approximation scheme (PTAS) with a running time of Θ(n ) <ref type="bibr" target="#b3">[4]</ref>. Compared to a FPTAS, a PTAS has the drawback of an exponential increase in running time with respect to the accuracy, i.e. its running time is polynomial only with respect to the input length, but not to the required ε value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Heuristic Algorithms</head><p>The enormous complexity of multidimensional knapsack problems motivated extensive re- search in heuristic algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Greedy Heuristics</head><p>Greedy heuristics work by inserting all items that do not violate any resource constraints (pri- mal greedy heuristics) or by first putting all items into the knapsack and then removing items until the solution becomes feasible (dual greedy heuristics). Since the order in which the items are inserted or removed matters and some items are more valuable than others (i.e. offer a relatively high profit for relatively low resource usage), items are sorted by an arbitrary effi- ciency e j before inserting them into the knapsack. The most obvious efficiency measure for a one-dimensional binary knapsack problem is the relative profit</p><formula xml:id="formula_23">e j = p j w j .</formula><p>Since there is more than one resource constraint in multidimensional knapsack problems, there is no such trivial method of determining the efficiency of an item. The nearest counterpart would be the aggregation of all d constraints, i.e.</p><formula xml:id="formula_24">e j = p j d i=1 w ij , (7.4)</formula><p>where e j would be the efficiency for item j. The main drawback is that it does not work well when the resource constraints are of different orders of magnitude. In this case, one constraint may completely dominate all others. This can be avoided by taking the relative weight for each constraint and define</p><formula xml:id="formula_25">e j = p j d . (7.5) i=1 w ij c i</formula><p>Senju and Toyoda <ref type="bibr">[38]</ref> proposed a different way to incorporate the relative distribution of weights by including the difference between the capacity and the total resource usage of all items for a given constraint.</p><formula xml:id="formula_26">e j = p j d i=1 w ij ( n j=1 w ij − c i ) . (7.6)</formula><p>A generalized formulation of these efficiency measures was proposed by Fox and Scud- der <ref type="bibr" target="#b32">[37]</ref> by introducing a relevance value r i for every constraint.</p><formula xml:id="formula_27">e j = p j d i=1 r i w ij (7.7)</formula><p>Equation (7.4) can be derived by setting r i = 1 for all i, (7.5) by setting r i = 1 c i</p><p>, and (7.6) by setting r i = n j=1 w ij − c i .</p><p>Advanced adaptive algorithms adjust the relevance values when an item was inserted, an early version of such an algorithm can be found in <ref type="bibr">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Relaxation-Based Heuristics</head><p>Heuristics based on the LP relaxations of integer programs can also be used for multidimen- sional knapsack problems with little or no adaptation. A simple and fast approach was given by Bertsimas and Demir in 2002 <ref type="bibr" target="#b2">[3]</ref>. It starts by fixing variables in the LP solution depending on a parameter γ ∈ [0, 1]:</p><formula xml:id="formula_28">x H 1 if x LP j := j = 1, 0 if x LP &lt; γ. (7.8) j</formula><p>In the second phase the subproblem defined by the undecided variables γ ≤ x LP j &lt; 1 is solved again, and further variables are fixed:</p><formula xml:id="formula_29">1 if x LP j x H j := = 1, 0 if x LP j = 0, 0 for j = argmin{x LP (7.9) j | 0 &lt; x LP j &lt; 1}.</formula><p>The last assignment fixes the variable with the least fractional value to zero. This second phase is repeated until all variables are fixed to zero or one. Small values for γ lead to better solution values but longer running times, while bigger values offer better performance. Setting γ = 1 is equivalent to rounding down the first LP solution. The authors proposed setting γ = 0.25 when performance is more important than solution quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3">Hybrid Algorithms</head><p>More advanced algorithms combine different approaches to the multidimensional knapsack problem. They are often more complex and require more running time, but can yield near- optimal solutions in many cases where simpler heuristics fail.</p><p>One such approach was proposed by Lee and Guignard in 1988 <ref type="bibr" target="#b24">[27]</ref>. Their algorithm starts with a modified version of Toyoda's primal greedy heuristic <ref type="bibr" target="#b34">[40]</ref>. Instead of deciding on each item separately, they decide on several items at once before recomputing the relevance values, leading to better performance. Based on this feasible solution, the LP relaxation is solved. A comparison between the feasible solution and the LP solution in combination with the reduced costs of the LP solution is used to fix some variables and reduce the problem size. These steps are iterated, the number of iterations is controlled by a parameter.</p><p>A more recent heuristic was given by <ref type="bibr">Vasquez and Hao in 2001 [41]</ref>. They combine linear programming and tabu search to search binary areas around continuous solutions. This is facilitated by additional constraints that limit the search space around a solution, like a sphere constraint that geometrically isolates the search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.4">Evolutionary Algorithms</head><p>Evolutionary algorithms (EAs) were inspired by biological evolution and try to mimic the evolutionary process. An evolutionary algorithm keeps one or more populations of solutions for a given problem, and tries to improve these solutions by imitating evolutionary procedures like selection, recombination and mutation.</p><p>Several evolutionary algorithms exist for the multidimensional knapsack problem. Major differences between algorithms concern varying operators for recombination and mutation, and also different representations of the solutions themselves. Raidl <ref type="bibr">[33,</ref><ref type="bibr" target="#b30">34,</ref><ref type="bibr" target="#b31">35]</ref> proposed different approaches for the multidimensional knapsack problem, also combining evolutionary algorithms with local improvement heuristics.</p><p>A particularly effective approach is based on an EA by Chu and Beasley <ref type="bibr" target="#b5">[6]</ref>. It uses a direct representation using bit vectors ∈ {0, 1} n for representing solutions. Recombination is done by uniform crossover, i.e. a child solution is created by randomly picking bits from one of its parents. Bit-wise mutation can be used to increase the diversity of solutions. Both crossover and mutation can produce infeasible solutions, so a repair algorithm is required. A two-phase heuristic is used for repairing and local improvement: the items are ordered by an utility ratio similar to the efficiency measures described in section 7.2.1. For repairing solutions, the least promising items are removed until the solution becomes feasible. The local improvement algorithm processes items not present in the current solution by decreasing utility ratio and inserts them if no constraints are violated.</p><p>Decoder-based EAs replace the direct representation of a solution with an encoding scheme. Recombination and mutation operate on the encoded solutions, implicitly explor- ing the original search space. The choice of the encoding scheme can greatly influence the effectivity of recombination and mutation and the convergence of the overall search algorithm.</p><p>A possible encoding scheme for knapsack problems uses permutations. Instead of storing the value for each variable, a permutation π : J → J with J = {1, . . . , n} is used to repre- sent a solution. In order to get a direct representation for a solution, decoding starts with the feasible solution x = (0, . . . , 0). Then the variables are visited in the sequence described by the permutation, and variables that do not violate constraints are set to 1. Mutation randomly exchanges two different positions in a permutation, recombination is done using uniform or- der based crossover <ref type="bibr" target="#b8">[9]</ref> which keeps the ordering (but not necessarily the positions) of the parent solutions. A permutation based EA for the knapsack problem has been proposed by <ref type="bibr">Hinterding [18]</ref> and it has also been applied to the multidimensional knapsack problem by Gottlieb <ref type="bibr" target="#b15">[17]</ref>, Raidl <ref type="bibr">[33]</ref>, Thiel and Voss <ref type="bibr" target="#b33">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 8 A Sample Application: MD-KP</head><p>This chapter guides through a sample application for the local branching framework, a Branch and Cut solver for the multidimensional knapsack problem as described in chapter 7. The goal is to optimize the following integer program:</p><formula xml:id="formula_30">maximize n j=1 p j x j subject to n j=1 w ij x j ≤ c i i = 1 . . . d (8.1) x j ∈ {0, 1} j = 1 . . . n</formula><p>Since the application actually will be embedded into the COIN/BCP main program, it makes sense to adhere to COIN/BCP's directory structure. COIN/BCP provides makefiles for building custom applications where only the added user files have to be defined.</p><p>The application source is grouped into the following directories:</p><p>• include/ contains all header files for the application's classes.</p><p>• LP/ contains the implementation of this program's LP module.</p><p>• TM/ contains the tree manager module.</p><p>• Member/ contains the other classes, in our case the initialization class (descendant of LB init) and the metaheuristic.</p><p>First of all, defining a class to hold a problem instance simplifies the further operations. In case of the multidimensional knapsack problem, we basically need some arrays to hold the coefficients of the constraints and the objective function, and the corresponding bounds. This class is based on the BranchAndCut example from the COIN source and can be easily adopted to other integer programming problems. It is defined as follows: Next, the tree manager class will be implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">KS tm implementation</head><p>The tree manager implementation is responsible for reading the problem data from a file, initializing the core matrix of COIN/BCP, and providing methods to pack and unpack cuts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.1">Test File Format</head><p>Our program will read test instances taken from Chu and Beasley's paper on a genetic algo- rithm for the multidimensional knapsack problem <ref type="bibr" target="#b5">[6]</ref>. These test files contain 270 different instances, ranging from very easy to very complex problems. The problems are described in plain text, each file contains 30 instances of the same dimension (i.e. the same number of variables and constraints). The format of the text file is:</p><p>• The number of instances (should be 30).</p><p>• For each problem: KS tm::read input() reads the data from the given file name using the given instance num- ber into a KS prob object which is stored in KS tm. Since it is just a very simple line parser the implementation is omitted here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.2">Setting up the Core Matrix</head><p>The raw core matrix was set up by KS tm::read input() and stored into KS prob::core, but until now COIN/BCP is not aware of the problem data. To do this, we must override LB tm::initialize core() to create all core variables and core cuts (i.e. all IP constraints). The core matrix is put together using the coefficients and upper and lower bounds loaded by read input(). In the end, we call the implementation of the superclass because the local branching framework might have to do some setup actions on its own. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.3">Packing and Unpacking of Cuts</head><p>We do not create own cuts in our sample application, but we still have to provide means to pack and unpack LB cut objects. These cuts will be used for local branching cuts and inverse variable fixing constraints. Since LB cut already provides methods for packing and unpacking those cuts, the corresponding implementations in LB tm are very compact: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.4">Sending the Problem Description to the LP Module</head><p>The LP module will need the problem description stored in the KS prob object for heuristically finding feasible solutions. KS tm::pack module data() allows to send any information to an LP process when it is created, thus we simply append our problem description to the given buffer. The local branching framework appends data on its own, so the implementation of the superclass is called too.</p><p>void KS tm::pack module data(BCP buffer&amp; buf, BCP process t ptype) { if (BCP ProcessType LP == ptype) buf.pack(&amp;prob); LB tm::pack module data(buf, ptype); } Actually only a pointer to the problem description is passed. This is possible since the focus of the sample application does not lie on parallel execution, but on simplicity. How- ever, it is a rather trivial task to write packing and unpacking routines for the KS prob class (especially since the core matrix does not need to be transmitted).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.5">Creating a KS MetaHeuristic Object</head><p>The KS MetaHeuristic implements the abstract LB MetaHeuristic class and contains the user- defined local branching control methods. Since the tree manager does not know the meta heuristic's type a priori, we instantiate a KS MetaHeuristic object by overriding LB tm's ab- stract method create lbh():</p><p>virtual LB MetaHeuristic* create lbh() { return new KS MetaHeuristic(ltm−&gt;index, &amp;prob); } ltm is the tree manager's LocalTreeManager object, ltm→index is the shared LocalTreeIn- dex, and prob contains the problem definition initialized by KS tm::read input().</p><p>The implementation of the tree manager is now complete, the next task is to implement the LP module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">KS lp Implementation</head><p>In the LP module implementation, the main effort goes into cut generation and heuristically finding feasible solutions. First, we need the counterpart to pack module data, or the local branching framework will use the wrong buffer values. Additionally, methods for packing and unpacking cuts are also required. We also need to setup the LP solver. Here we will instantiate COIN's own CLP solver, the complete version of the sample application also supports CPLEX. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.1">Generating Feasible Solutions</head><p>COIN/BCP provides a method where the user can generate feasible solutions from solved LP relaxations. By generating good feasible solutions early in the computation, the search tree size can be reduced. However, the heuristic should not be too complex since this method is called for every solved LP relaxation.</p><p>For the multidimensional knapsack problem, we chose a simple greedy heuristic as de- scribed in section 7.2.1. The efficiency measure is not based on the resource usage of each variable, but on its value in the LP result. Thus, after sorting the variables by descending LP value, all variables that do not violate the resource constraints are added to the solution, which is then returned to the LP module. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.2">Generating Cuts</head><p>The second main task for the LP module is cut generation. When a LP relaxation was solved, one can either try to generate cuts violated by the LP result, or the subproblem is branched. COIN/CGL offers several generic cut generators. If one chooses to generate cuts, it can be either done for every node, or for nodes meeting a certain condition. In this example, we choose to generate cuts for nodes at every eighth level of the search tree. We try to create generic knapsack cover cuts and Gomory cuts. The cut generators are first instantiated and stored in a list. We also set the maximal number of items for the knapsack cut generator. Higher numbers lead to higher computational complexity, but also higher chances of finding cuts. Then every cut generator is invoked to generate cuts and store them in cutlist. These cuts are then appended to the new cuts output parameter. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">KS init Implementation</head><p>COIN/BCP provides the USER initialize class to instantiate custom tree manager and LP module implementations. KS init implements LB init, which in turn was derived from USER initialize. KS init::lp init() creates a new KS lp object, and KS init::tm init() instanti- ates a new KS tm object. While the former is called once for every created LP process, the latter is only called on program startup. Thus it is used to process command line parameters and initialize the tree manager by calling KS tm::read input() for the given file name. Addi- tionally, the global function BCP user init() has to be implemented to return a new KS init() object.</p><p>With these three classes, the basic COIN/BCP implementation is finished. For the standard COIN/BCP classes, the implemented methods are sufficient for an executable Branch and Cut algorithm for the multidimensional knapsack problem. The local branching framework requires the implementation of a fourth class, the local branching metaheuristic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">KS MetaHeuristic Implementation</head><p>All local branching related logic is contained in KS MetaHeuristic, our implementation of the LB MetaHeuristic class. Our local branching controller accomplishes three main tasks:</p><p>• initial solution() creates a heuristic solution used for the first local branching tree.</p><p>• new node generated() is called regularly by the framework and monitors local branching progress. When the given node limits are exceeded, it restarts local branching.</p><p>• tree finished() starts a new local tree when the last active tree finished, effectively im- plementing the sequential local branching algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.1">Configuring Local Branching</head><p>Before the actual local branching implementation is described, we need a way to adjust cer- tain parameters of our heuristic without recompiling the whole program. COIN/BCP offers a convenient, generic parameter parser that can be used to load user-defined parameters from the command line or from a file, perform type checking and sanity checks, and define de- fault values. In order to utilize COIN/BCP's parser, we start by defining a parameter class, KS parameters. It is not derived from any other class, instead for each parameter type (integer, double, string, ...) it defines enumerations containing the parameters' names. This class is used as a generic type parameter for COIN/BCP's BCP parameter set::create keyword list() and set default entries. The first method assigns actual string labels to the user-defined param- eters, the second methods initializes all parameters with default values. For example, the following code defines a couple of double parameters and then imple- ments COIN/BCP's methods for using them:</p><formula xml:id="formula_31">class KS parameters { public:</formula><p>enum dbl params { LB FixVarsInitial, LB FixVarsIncrement, LB FixVarsMax, LB MultiK, end of dbl params }; }; template&lt;&gt; void BCP parameter set&lt;KS parameters&gt;::create keyword list() { keys.push back(make pair(BCP string("LB FixVarsInitial"), BCP parameter(BCP DoublePar, LB FixVarsInitial))); keys.push back(make pair(BCP string("LB FixVarsIncrement"), BCP parameter(BCP DoublePar, LB FixVarsIncrement))); keys.push back(make pair(BCP string("LB FixVarsMax"), BCP parameter(BCP DoublePar, LB FixVarsMax))); keys.push back(make pair(BCP string("LB MultiK"), BCP parameter(BCP DoublePar, LB MultiK))); } template&lt;&gt; void BCP parameter set&lt;KS parameters&gt;::set default entries() { set entry(LB FixVarsInitial, 0.0); set entry(LB FixVarsIncrement, 0.0); set entry(LB FixVarsMax, 0.0); set entry(LB MultiK, 1.0); } BCP parameter set also provides methods for reading parameter from the command line, from files, or from input streams. It also offers methods for accessing parameter values (get entry() and set entry()) and packing or unpacking of parameter sets. Since the param- eters are only important for the local tree metaheuristic, we do not need to pass the parameters to other modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.2">Setting up Local Branching</head><p>Before the local branching heuristic takes over control, we have to tell the framework if lo- cal branching should be enabled at all -and which parameters to use. The event handlers depend on an already running local branching algorithm (e.g. a new node was generated, or a tree was terminated). The decision whether to create a local tree or to use standard branching takes place when the first LP process is initialized in LB tm::pack module data(). LB MetaHeuristic::lb maxpasses sets the maximum number of local trees. If it is zero, no lo- cal trees will be generated at all and standard branching will be used. This information is also used in tree creation methods, which will fail when the number of created local trees exceeds lb maxpasses.</p><p>The KS MetaHeuristic class sets lb maxpasses in its read parameters() method, where the command line is parsed using the parameter methods described in the previous section, effectively disabling local branching when either the maximum number of local trees or the value of k has been set to 0. The value of k for the very first local tree is also set in this method, which is called by KS init::tm init() after the tree manager and the KS MetaHeuristic objects were created.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.3">Creating the Initial Solution</head><p>The initial solution is retrieved by the local tree manager when the first LP process is initial- ized. To demonstrate the use of pseudo-concurrent tree exploration, we use three different heuristics to start local branching with three (partially) disjunct local trees. The solution de- rived from the first LP result is used for the first local tree, and two greedy heuristics with different efficiency measures provide the other two solutions.</p><p>Since the metaheuristic class does not know the first LP result (it is local to the LP pro- cess), a small workaround forces the local branching framework to actually use the first LP result: initial solution() returns an empty solution (i.e. with all variables set to 0) and tells the framework to use the feasible solution derived from the first LP result (if it is better). The first LP-derived solution is certainly better than the empty solution for any feasible problem instance, thus it will always be used. The other initial solutions are stored in the metaheuristic object and are sent to the tree manager as soon as the first local tree is created.</p><p>To summarize the steps above, the initial local trees are created in the following way:</p><p>1. initial solution() calls greedy() to generate two initial solutions using two different ef- ficiency measures. These solutions are stored in the KS MetaHeuristic object for later use.</p><p>2. initial solution() returns an empty solution to force the framework to use the solution derived from the first LP result as initial solution for the first tree.</p><p>3. tree created() issues create tree() to create the next two local branching trees.</p><p>The implementation of greedy() is similar to the feasible solution generator described in section 8.2.1. A greedy heuristic inserts the items ordered by an efficiency value determined by one of the following formulas as described in section 7.2.1:</p><formula xml:id="formula_32">e j = p j d . (8.2) i=1 w ij c i</formula><p>The profit p j for item j is divided by the relative resource usage, i.e. the sum of all relative weights. The relative weight concerning a given resource i and an item j is the absolute weight w ij divided by the resource limit c i . This way, weights are scaled to [0 . . . 1] regardless of their absolute value, leading to a fair consideration of all weights.</p><formula xml:id="formula_33">e j = p j d i=1 w ij ( n j=1 w ij − c i ) .<label>(8.</label></formula><p>3)</p><p>The second efficiency measure takes the weight distribution into account, i.e. it emphasizes scarce resources.</p><p>The code for sorting the items follows below, the greedy heuristic for inserting the items is the same as in section 8.2.1. The parameter fun determines which efficiency measure should be used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.4">Imposing Node Limits on Local Trees</head><p>While the framework provides all necessary information for terminating trees above a certain node count, the criteria for aborting local trees have to be checked in the meta heuristic. In this metaheuristic, we will implement a rather simple node-based tree termination scheme that has the following characteristics:</p><p>• Trees will be aborted when their total number of created nodes exceeds a given limit.</p><p>• Trees will be aborted when the number of created nodes since the last improvement of the best feasible solution found inside the local tree exceeds a given limit.</p><p>• When a tree is aborted and the maximum number of local trees is not reached, a new local tree is created with the current best global solution. Based on the result of the last local tree, the new tree will be eventually modified:</p><p>-When a better solution was found since the last tree was created, local branching is restarted with this new solution and the initial local branching parameters.</p><p>-When no new solutions were found, the new local tree is tightened (if the cor- responding parameters are set): the number of variables to be fixed is increased, and/or the value of k gets modified.</p><p>Written as a handler using LB MetaHeuristic::new node generated(), the following code implements node limits for all local trees. Some additional safety checks occurs, such as checking if local branching is enabled (lb enabled). Due to COIN/BCP's asynchronous de- sign, nodes may be added to a tree event after the tree was terminated. Thus it is also checked if the current tree has not already been terminated (ltree.get terminated()). The last expres- sions of the outer if clause formulate the node limits described above using the statistical data of the LocalTreeIndex. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.5">Handling Terminated Local Trees</head><p>LB MetaHeuristic::tree finished is called when a formerly active tree has no more active nodes remaining. It may be called when the tree was solved completely, or when it was aborted, e.g. by our new node generated() implementation. When the tree was aborted, the tree's get terminated() function returns true. In both cases, a new tree has to be created. LB MetaHeuristic::create tree() takes care of the limit on the total number of local trees by setting lb enabled to false if necessary. Our implementation additionally tracks the number of retries for the current incumbent solution (i.e. the number of local trees spawned with the last incumbent solution), disabling local branching when a given number of retries has been exceeded. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Finishing Touches</head><p>The Branch and Cut solver for multidimensional knapsack problems is now complete. For compiling the application, a properly patched installation of COIN/BCP is needed (see ap- pendix A), and an adapted makefile. A makefile template can be taken from one of the COIN/BCP examples, found under Examples/BAC or Examples/BranchAndCut in the COIN directory. Note that all of the framework's sources have to be added to the makefile. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test Results</head><p>The multidimensional knapsack solver described in the previous chapter was used to under- take extensive testing of local branching performance. The test instances were taken from J.E. Beasley's OR Library <ref type="bibr" target="#b1">[2]</ref> which provides 270 instances for the multidimensional knap- sack problem. They are grouped by problem dimension into nine files, each containing 30 instances. The smallest problem size contains 100 variables and 5 constraints, the largest 500 variables subject to 30 constraints. Each file contains three groups of instances with tightness ratios of α = 0.25 , 0.5 , and 0.75. The tightness ratio defines how "tight" the resource limits are set, lower ratios define tighter resource limits.</p><p>Additional problems were taken from the Hearin Center for Enterprise Science <ref type="bibr" target="#b12">[14]</ref>. This dataset contains eleven test instances originally used for the multiple knapsack problem, rang- ing from two instances with 100 variables and 15 constraints to an extremely large test instance with 2500 variables and 100 constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Test Environment</head><p>All tests were executed on an Intel Pentium 4 with 2.8 GHz and 2 GB of RAM, running Linux with a 2.4.21 kernel. The LP engine used for testing was CPLEX 8.1.</p><p>The test application was configured to output status information at regular intervals, allow- ing a reporting tool described in appendix B to generate tables and plots comparing different configurations.</p><p>The running time is always given in CPU time for the COIN/BCP process as recorded by COIN/BCP's own timing statistics. This also includes time spent solving the LPs using the CPLEX solver.</p><p>When analyzing the results with respect to time (i.e. determining when a solution was found during the computation), the number of processed nodes is taken instead of the CPU time. As described in chapter 6, it is much easier for COIN/BCP to track the number of nodes during a computation than the CPU time spent so far. This simplification relies on the fact that the number of processed nodes does not vary significantly for a given test instance, even when using different parameters for local branching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Test Results Overview</head><p>Summarizing the detailed results that will be presented in this chapter, three major observations were made:</p><p>• Local branching can find better solutions than standard branching early in the computa- tion especially for large, complex test instances.</p><p>• For smaller, easier test instances local branching did not show such advantages or was inferior to standard branching.</p><p>• The settings for local branching, especially the value of k, the number of variables to be fixed, and the maximum number of nodes depend on the problem size. It was not possible to find a parameter configuration that delivers good results for all problem sizes (or even a rule of thumb to account for problem complexity).</p><p>Since local branching showed its benefits primarily with larger test instances, most of the detailed results will concentrate on larger knapsack problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.1">Final Objective Comparison</head><p>The first method for comparing two configurations is by comparing the best feasible solution found in a given timespan. When both configurations found the same feasible solution (or at least two solutions with the same objective value), the configuration which processed less nodes to find this solution is considered better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.2">Online Performance</head><p>As an artificial measure for determining the efficiency of the algorithm an online performance rating was introduced. The basic idea is to plot the best objective value over time, and then calculate the sum of the area below:</p><formula xml:id="formula_34">nodesmax w(x)objval (x) (9.1) x=0</formula><p>with objval (x) being the interpolated final objective value for the number of processed nodes x and nodes max the total number of processed nodes. By adding a monotonically decreasing weight function, the online performance favors algorithms that find good solutions early in the computation, even if the final result is the same.</p><p>We chose a simple inverse exponential weight function,</p><formula xml:id="formula_35">w(x) = e −x nodesmax . (9.2)</formula><p>The online performance rating is calculated by summing up objval (x)w(x) for x = 1 . . . nodes max and scaling the result by 1 nodesmax . When comparing different configurations, all results have to be processed over the same range. We set nodes max to the maximum num- ber of processed nodes for the last improvement in the considered configurations. <ref type="figure" target="#fig_19">Figure 9</ref>.1 shows a plot of the objective value for two different configurations on the left, and the corresponding online performance weight function on the right. While both config- urations ultimately find almost equally good solutions, configuration 6 yields better solutions earlier in the computation, so its online performance score is greater than that of configuration 1 (the former configuration is actually using local branching, while the latter is not.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Local Branching Configurations</head><p>As explained in the previous chapters, there are several key parameters that influence the per- formance of local branching. In short, the user has to decide on the following parameters:</p><p>• The value of k for the Hamming distance constraint determines how many binary vari- ables can flip inside a single local tree.</p><p>• Fixing some variables helps to reduce the problem complexity inside the tree defined by the chosen k value.</p><p>• Defining node limits on local trees avoids stagnation.</p><p>• By adapting the values of k and the numbers of variables to be fixed at run-time, the search can be narrowed or broadened at will.</p><p>The variables used for controlling these parameters are described in chapter 8. In the test results, the following abbreviated notation will be used:</p><p>• k = k initial , k scaling , k {min|max } defines the initial k value, the factor k is multiplied with when a tree is aborted, and the minimum (when the factor is less than 1) or maximum (when the factor is greater than 1) value for k. When only one value is given, k remains constant throughout the computation.</p><p>• Variable fixing: f initial , f increment , f max contains the number of variables fixed when a local tree using a new incumbent solution is started, and the increment and maximum values to be used when a tree is aborted and restarted with the same initial solution.</p><p>• Maximum nodes is the maximum number of nodes for a local tree, no node limit is used when this parameter is omitted.</p><p>• Maximum nodes without improvement declares the maximum number of nodes to be created in a local tree without finding an improved feasible solution. When this value is omitted, no such node limit is imposed on local trees.</p><p>All parameters depend on the size of the test instance, so no reasonable default values can be provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4">Short-Time Tests</head><p>The objective of the following tests is to accelerate the process of finding good solutions early in the computation, while the final objective is not of paramount importance. For these test runs, a time limit of 10 minutes per instance was used. Since there was no single configura- tion that succeeded in all presented problem instances, the results are separated by problem size. For the initial solution a greedy heuristic generated two solutions, the first using relative weights as in equation <ref type="formula">(7.5)</ref> as efficiency measure and the second using the first LP optimum. The better solution (regarding the objective value) was used as initial solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4.1">Local Branching and Node Limits</head><p>The first set of test runs uses standard local branching and for some instances node limits, but no cut generation. We start with examining the moderately sized mknapcb7 test instance collection from the OR Library <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mknapcb7: 100 variables, 30 constraints</head><p>The following configurations have been tested for all 30 test instances of mknapcb7:</p><p>(1) Standard Branch and Cut.</p><p>(2) k = 13, variable fixing: 0.1, no node limit. For these test instances, the local tree search without a node limit was superior to a local tree search with the same parameters, but with a limit on the total number of nodes per local tree. When comparing final objectives with the conditions described earlier in this chapter, configuration (2) wins against (1) with a clear advantage of 27 : 10 (the numbers do not add up to 30 because of some ties.) For configuration (3), the direct comparison yields only a slight advantage of 19 : 17 for local branching.</p><p>Introducing the online performance rating, (2) loses some of its advantage, but still show- ing a distinct advantage of 22 : 14 when compared to (1). Configuration (3) stays at 19 : 17, not showing a significant benefit from local branching.</p><p>Comparing the number of local trees, (2) mostly used only a single local tree with an average of 1.2 local trees, (3) created an average of 27.1 trees per test instance. <ref type="figure" target="#fig_19">Figure 9</ref>.2 shows two sample graphs from this test series.   <ref type="figure" target="#fig_19">Figure 9</ref>.3: Two sample graphs for mknapcb8 showing the benefit of node limits for configu- ration (3) against the same configuration without node limit (2) and standard Branch and Cut (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mknapcb8: 250 variables, 30 constraints</head><p>For the larger test instances of mknapcb8, imposing node limits proved to be more beneficial. A local branching setup similar to the previous configurations proved to be superior to standard Branch and Cut, especially when considering the online performance rating. The following configurations delivered the best results compared to standard Branch and Cut:</p><p>(1) Standard Branch and Cut.</p><p>(2) k = 13, variable fixing: 0.1, no node limit (3) k = 13, variable fixing: 0.1, 0.1, 0.5, maximum nodes per tree: 5000</p><p>Comparing the final objective values, both (2) and (3) showed an advantage of 18 : 14 against (1). When comparing the online performance rating, (2) exhibited a slight disadvantage of 15 : 17, while (3) apparently benefited from the node limit and won clearly by 21 : 11. 18 : 14 21 : 11 15.4% mknapcb9 500 30 (3) 19 : 11 17 : 13 2.1% <ref type="table" target="#tab_2">Table 9</ref>.1: Summary table for the tested mknapcb problems. Each row represents 30 different instances with the given dimensions. The ratios given for final objective value and online performance compare the best local branching configuration to standard Branch and Cut.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mknapcb9: 500 variables, 30 constraints</head><p>The largest class of test instances from the OR Library, mknapcb9, exhibited similar behavior regarding local branching. Compared to standard branch and cut, two configurations exhibited similar performance.</p><p>(1) Standard Branch and Cut. Regarding the final objective values, configuration (2) achieves a ratio of 18 : 12 against standard Branch and Cut, reducing the node limit leads to a further minor improvement of 19 : 11. The online performance ratings are a bit less favorable, showing a 17 : 13 advantage for both local branching configurations. Configuration (2) created an average of 12.2 local trees per computation, while (3) used an average of 67.8 local trees. <ref type="table" target="#tab_2">Table 9</ref>.1 summarizes the results and also contains the result of a Wilcoxon rank sum test. It represents the error probability for the assumption that the first method performs on average better than the second. It is generated by creating two columns, one for each configuration, and setting a 1 where a configuration achieved the best result for a given test instance, and 0 otherwise. We do not compare the final objective values, because even when two configura- tions achieved the same value, we prefer the configuration that reached it with fewer processed nodes.</p><p>A Wilcoxon score close to 0 means that the the local branching configuration is very likely to be better than the standard Branch and Cut algorithm, a value close to 0.5 means that no significant difference exists. For mknapcb7 and mknapcb9 the Wilcoxon test clearly indicates that the local branching results are better than the standard Branch and Cut results, while the result for mknapcb8 (0.15) is less clear.</p><p>The detailed test results for all test instances are given in tables 9.2, 9.3, and 9.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MK-gk11: 2500 variables, 100 constraints</head><p>The huge eleventh test instance from the problems taken from the Hearin Center for Enter- prise Science <ref type="bibr" target="#b12">[14]</ref> shows clear advantages for most local branching configurations. The tested configurations are:</p><p>(1) Standard Branch and Cut. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4.2">Cut Generation</head><p>The idea of cut generation is to find valid inequalities that are violated by the current LP opti- mum as described in section 2.3, thus decreasing the LP optimum and increasing the chances to prune a subproblem. The size of the search tree can be reduced significantly at the expense of computationally expensive cut generation.</p><p>In our test results, cut generation did not lead to a significant advantage for local branching in comparison to the standard Branch and Cut algorithm, instead it compensated the advantage of local branching. We used COIN/CGL's generic cut generators, the most efficient proved to be the knapsack cover cut generator. Others, like the Gomory cut generator, did not improve the results but slowed down the computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mknapcb7: 100 variables, 30 constraints</head><p>The following parameter configurations have been tested:</p><p>(1) Standard Branch and Cut.</p><p>(2) k = 13, variable fixing: 0.1, no node limit. Without cut generation, configuration (2) beat standard Branch and Cut by 27 : 10. With cut generation, the standard algorithm reaches a tie result of 18 : 18 both against (2) and (3). Regarding the online performance rating, local branching gains a slight advantage of 18 : 16 for configuration (2) and 19 : 15 for (3   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4.3">Multiple Initial Solutions</head><p>Creating multiple local trees in the beginning of the computation can help to improve the initial performance of the local branching algorithm. The processor time is distributed over several local trees, preferring those with better nodes (according to the tree search strategy, i.e. those with better bounds.) As described in chapter 8, three different initial solutions were used:</p><p>• The feasible solution generated heuristically from the first LP result.</p><p>• A solution returned by a greedy heuristic using the relative weight as an efficiency mea- sure.</p><p>• A solution returned by the same heuristic including the weight distribution as an effi- ciency measure.</p><p>Compared to local branching with a single initial solution the results improved consider- ably. For the mknapcb7 test instances, the three initial local trees contributed equally to the best found solution, that is, the initial trees were of roughly the same size. For the mknapcb8 and mknapcb9 instances, the tree based on the first LP result was most often superior to the trees based on efficiency measures, meaning that the latter two trees were often completed af- ter a few nodes. Apparently the greedy heuristics with efficiency values worked better for the smaller mknapcb7 instances than for the more complex mknapcb8 and mknapcb9 instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mknapcb7: 100 variables, 30 constraints</head><p>The following configurations have been tested:</p><p>(1) Standard Branch and Cut.</p><p>(2) k = 13, variable fixing: 0.1, no node limit. Regarding the final objective values, both local branching configurations showed an 24 : 10 advantage to standard Branch and Cut. While this result is similar to what local branching with a single initial solution achieved, the pseudo-concurrent tree exploration shows more benefits when looking at the online performance rating. Both local branching configurations achieved a clear advantage of 25 : 9 compared to local branching, which is considerably better than the results using a single initial solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mknapcb8: 250 variables, 30 constraints</head><p>As in section 9.4.1, the following configurations have been tested for mknapcb8:</p><p>(1) Standard Branch and Cut.</p><p>(2) k = 13, variable fixing: 0.1, no node limit  <ref type="table" target="#tab_2">Table 9</ref>.5: Summary table for the tests using multiple initial solutions, including a Wilcoxon probability score for the assumption that the final objective values of standard Branch and Cut are better than the given local branching configuration.</p><p>Comparing the final objective values, configuration (2) showed an advantage of 22 : 8 against standard <ref type="bibr">Branch and Cut, (3)</ref> had an advantage of 21 : 9. Regarding online perfor- mance, (2) showed a clear advantage of 24 : 6 and (3) an advantage of 26 : 4 compared to standard Branch and Cut.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mknapcb9: 500 variables, 30 constraints</head><p>The following configurations were tested:</p><p>(1) Standard Branch and Cut.  Both (2) and (3) showed clearly superior results to (1), with (2) showing a slight advantage of 17 : 13 and (3) beating standard Branch and Cut by 22 : 8. The online performance ratings clearly favor the local branching configurations: (2) beats (1) by 24 : 6, (3) beats (1) by 25 : 5. Compared with the same configuration without multiple initial solutions, (2) exhibited an advantage of 19 : 11 for the final objective value and 27 : 3 for the online performance rating. <ref type="table" target="#tab_2">Table 9</ref>.5 summarizes the results for these test runs. The detailed results for all test in- stances of mknapcb7, mknapcb8 and mknapcb9 are given in tables 9.6, 9.7, and 9.8. Bold values indicate the best result for a single instance. Note that it is possible for more than one configuration to achieve the "best" result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.5">Long Runs</head><p>The test runs described in the last section are useful for testing the short-time heuristical behav- ior a large variety of local branching configurations. Testing the instances of the OR library <ref type="bibr" target="#b1">[2]</ref> with longer running times (up to one hour) did not reveal significantly different behavior. How- ever, the very large eleventh instance of the second set of test instances <ref type="bibr" target="#b12">[14]</ref> with 2500 variables and 100 constraints was an interesting target for examining long-run behavior. The huge core matrix dramatically slows down the LP solver, affecting the significance of the results of a 10 minute test run. Increasing the CPU time to 2 hours showed interesting results: local branching extended its lead (with unmodified parameters), standard branch and cut was clearly inferior to all tested configurations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary and Outlook</head><p>This thesis described the implementation of a generic local branching framework based on the open source COIN/BCP Branch, Cut and Price library. Local branching is a local search heuristic that is well suited for integration in existing integer programming solvers. The frame- work provides the possibility to augment COIN/BCP programs with local branching search capabilities. Several extensions to the standard local branching algorithm were implemented: pseudo-concurrent exploration of multiple local trees, aborting local trees, and search space tightening through variable fixing.</p><p>An encapsulated metaheuristic class offers means for a clean implementation of local branching metaheuristics without touching COIN/BCP's internals. Rich statistical data about the current state of the local branching algorithm is provided by the framework. Methods for creating new trees, terminating existing trees or modifying the local branching search param- eters are also provided.</p><p>As a sample application, a Branch and Cut solver for the multidimensional knapsack prob- lem was used to demonstrate the application of the local branching framework and to research the effects of local branching.</p><p>The results for the multidimensional knapsack problem were promising: local branching showed better convergence, especially in the early stages of the computation, and showed significant benefits for large, complex test instances. By guiding the Branch and Cut solver through neighborhood search and fixing of variables, local branching allows to find better results earlier in the computation, which also leads to a reduction of the search tree complexity in the later stages. However, the benefit for relatively small test instances was less clear.</p><p>The local branching framework was designed in a way that facilitates embedding local branching as a local search metaheuristic in another, higher-level search algorithm. This is the main area where future work could be expected, to use the heuristical characteristics of local branching to improve other search algorithms not based on Branch and Cut. In general, any algorithm that involves some kind of local neighborhood search lends itself to the integration of local branching. For example, an evolutionary algorithm could use the framework to generate new, better solutions based on especially promising candidates.</p><p>Then we add virtual method declarations of unpack user message() to BCP tm user and BCP lp user by adding the following lines to the corresponding class definitions in in- clude/BCP lp user.hpp and include/BCP tm user.hpp: virtual void unpack user message(BCP lp prob&amp; prob, BCP buffer&amp; buf);</p><p>We also provide a default implementation that throws an exception when called in LP/BCP lp user.cpp and TM/BCP tm user.cpp: void BCP tm user::unpack user message(BCP tm prob&amp; prob, BCP buffer&amp; buf) { throw BCP fatal error( "BCP tm user::unpack user message() invoked but not overridden!\n"); }</p><p>The implementation for BCP lp user is identical except for the class name. The last step to be taken is to call these handlers from the tree manager and LP module message process- ing functions. For the tree manager, we add the following block to the switch statement of BCP tm prob::process message() in TM/BCP tm msgproc.cpp: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Extending the Candidate List</head><p>When local trees can be spawned before the previous tree terminated, the normal root node (the sibling of the local tree root) has to be extracted from the candidate list. The easiest and fastest way to achieve this goal is to store the normal root node in an extra variable and modify the methods to insert and retrieve items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 include/BCP tm node.hpp</head><p>We start with modifying include/BCP tm node.hpp. We have to add two member variables to BCP node queue which is used to store the candidate list.</p><p>/** root node of the "normal" tree, to be used when all local trees are processed or a new tree should be opened */ BCP tm node* normal root node; /** use normal root node instead of a candidate from the queue the next time top() is called */ bool use normal root node;</p><p>Then we add a new parameter to BCP node queue::insert that permits to insert a normal root node without using the extra slot. This is used when the normal root node is the last remaining node and should be returned to the candidate list. By setting a default value, existing calls to this function do not need to be modified.</p><p>/** Insert a new node into the queue. */ void insert(BCP tm node* node, bool replace normal root node = true);</p><p>We also slightly modify the inline functions empty() and top() to account for the normal root variable.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 include/BCP tm node.cpp</head><p>We also have to change the implementations of the insert and and pop methods of the BCP node queue class. Since we have to access user data objects, we have to include the framework's user data header. By using a compile-time flag for applications that use the local branching framework, the COIN source remains usable for other applications.</p><p>#ifdef COIN LB #include "LB user data.hpp" #endif</p><p>The pop() method removes a node from the head of the priority queue. When the queue is has only one element left, the normal root node is re-inserted to the list. If the normal root node has been used (by setting use normal root node to true), it is deleted when pop() is called. In the insert() method, we have to detect normal root nodes and store them in the extra vari- able instead of the normal candidate list. By using the COIN LB flag again, the LB user data cast does not conflict with other COIN/BCP applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.3 TM/BCP tm functions.cpp</head><p>Another small modification is necessary in the static helper function BCP tm start one node(). When the normal root node should be returned, it is returned without further checking (e.g. if it should be pruned). This way the tree manager can recognize when the normal root node is pruned without further modifications (in this case, the node would be pruned by a LP pro- cess). Also, when a node was pruned because of the global upper bound, it is added to the pruned nodes list that is described in the next section. The script has to be executed from the main knapsack application directory and stores the results in the file specified by outfile. The instance numbers are stored in instances (in this case {0 . . . 29}), the configurations are stored in testcases. The test files are supplied on the command line, possibly using wildcards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Analyzing Log Files</head><p>The printstats.py script parses the log file given on the command line and offers a simple line-based interactive interface to query the results. The most important commands are:</p><p>• help returns a list of all commands.</p><p>• help <ref type="bibr">[command]</ref> returns a short description and possible parameters of the given com- mand.</p><p>• table [configuration]* prints a table containing all tested instances as rows and the given configurations (or all, if none are supplied) as columns. The index numbers of the configurations correspond with the log file and are also displayed below the table.</p><p>• columns <ref type="bibr">[parameter]</ref> sets the displayed values. Possible parameters are:</p><p>-finalobjective: the final objective value.</p><p>-finalobjective delta: the final objective value, and the number of processed nodes relative to the best configuration in a row (when two configurations found the same result.)</p><p>-onlineperformance: the online performance rating.</p><p>-localtrees: the number of (created) local trees.</p><p>-localtime: time spent in local branching relative to the total computation time.</p><p>-finalbinary: a binary comparison function for the final objective value, useful for executing Wilcoxon rank sum tests.</p><p>• showfilename [true/false] enables or disables the file name column in the table view.</p><p>• plot <ref type="bibr">[filename]</ref> [configurations]* executes gnuplot to plot the final objective values of the given configurations (or all if none are given).</p><p>• outputformat [screen/postscript] sets the output format of the plots generated by the plot commands. screen uses gnuplot to display the diagram on the screen, postscript writes the output to a postscript file.</p><p>• outputdir <ref type="bibr">[directory]</ref> sets the directory where the postscript files are stored (default: current working directory.)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2.1: Branch and Bound pseudo-code</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2.2: Deciding to branch or prune</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2.3: Branch and Cut pseudo-code</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 3.1: Local Branching</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4.1: Pseudo-concurrent local tree exploration using a single MIP solver instance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6.1 shows an UML diagram for the classes attached to the LB tm class. There are four classes that must always be subclassed for a working program. The methods to be implemented are defined by the COIN/BCP superclasses and have to be implemented anyway to get a working program (except for the LB MetaHeuristic subclass).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6.1: UML class diagram for the tree manager extension</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Total number of items (= columns) int nConstraints; ///&lt; Total number of constraints (= rows) double optimalknown; ///&lt; Known optimal solution, −DBL MAX if unknown double* clb; ///&lt; Lower bound for each core variable (usually 0.0) double* cub; ///&lt; Upper bound for each core variable (usually 1.0) double* val; ///&lt; Objective value (profit) for each core variable double** res; ///&lt; Resource demands double* rescons; ///&lt; Resource constraints CoinPackedMatrix* core; ///&lt; Core matrix double* rlb core; ///&lt; Lower bounds in the core matrix (usually 0.0) double* rub core; ///&lt; Upper bounds in the core matrix (usually rescons[rownum]) };</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>-</head><label></label><figDesc>Number of variables n, number of constraints d, optimal solution (if known). -The coefficients of the objective function p j for j = 1 . . . n. -For each constraint i: the coefficients of the constraint w ij . -The upper bounds of the constraints c i for i = 1 . . . d.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>void</head><label></label><figDesc>KS tm::initialize core(BCP vec&lt;BCP var core*&gt;&amp; vars, BCP vec&lt;BCP cut core*&gt;&amp; cuts, BCP lp relax*&amp; matrix) { // initialize core variables for (int i = 0; i &lt; prob.nItems; ++i) if (0.0 == prob.clb[i] &amp;&amp; 1.0 == prob.cub[i]) vars.push back(new BCP var core(BCP BinaryVar, prob.val[i], 0, 1)); // initialize core cuts for (int i = 0; i &lt; prob.core−&gt;getNumRows(); ++i) cuts.push back(new BCP cut core(prob.rlb core[i], prob.rub core[i])); // create LP relaxation matrix = new BCP lp relax; matrix−&gt;copyOf(*prob.core, prob.val, prob.clb, prob.cub, prob.rlb core, prob.rub core); LB tm::initialize core(vars, cuts, matrix); // execute LB's initializiation }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>void</head><label></label><figDesc>KS tm::pack cut algo(const BCP cut algo* cut, BCP buffer&amp; buf) { const LB cut* lb cut = dynamic cast&lt;const LB cut*&gt;(cut); if (!lb cut) throw BCP fatal error("pack cut algo(): unknown cut type!\n"); lb cut−&gt;pack(buf); } BCP cut algo* KS tm::unpack cut algo(BCP buffer&amp; buf) { return new LB cut(buf); }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>void</head><label></label><figDesc>KS lp::unpack module data(BCP buffer&amp; buf) { buf.unpack(pprob); LB lp::unpack module data(buf); } void KS lp::pack cut algo(const BCP cut algo* cut, BCP buffer&amp; buf) { const LB cut* lb cut = dynamic cast&lt;const LB cut*&gt;(cut); if (!lb cut) throw BCP fatal error("LB lp::pack cut algo: unknown cut type!\n"); lb cut−&gt;pack(buf); } BCP cut algo* KS lp::unpack cut algo(BCP buffer&amp; buf) { return new LB cut(buf); }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>OsiSolverInterface* KS lp::initialize solver interface() { OsiClpSolverInterface *clp = new OsiClpSolverInterface; clp−&gt;messageHandler()−&gt;setLogLevel(0); return clp; }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>BCP solution* KS lp::generate heuristic solution(const BCP lp result&amp; lpres, const BCP vec&lt;BCP var*&gt;&amp; vars, const BCP vec&lt;BCP cut*&gt;&amp; cuts) { const double* x = lpres.x(); BCP solution generic* sol = new BCP solution generic(false); // sort variables by LP result value, then insert them in reversed order (best first) multimap&lt;double, int&gt; sorted; for (unsigned int i = 0; i &lt; vars.size(); ++i) sorted.insert(pair&lt;double, int&gt;(x[i], i)); // track current resource usage double* myres = new double[pprob−&gt;nConstraints]; for (int j = 0; j &lt; pprob−&gt;nConstraints; ++j) myres[j] = 0.0; multimap&lt;double, int&gt;::reverse iterator it; for (it = sorted.rbegin(); it != sorted.rend(); ++it) { int i = (*it).second; // number of the variable to be inserted bool ok = true; for (int j = 0; j &lt; pprob−&gt;nConstraints; ++j) { // check if any resource constraint is violated if (myres[j] + pprob−&gt;res[j][i] &gt; pprob−&gt;rescons[j]) ok = false; } if (ok) { // insert item into knapsack for (int j = 0; j &lt; pprob−&gt;nConstraints; ++j) myres[j] += pprob−&gt;res[j][i]; sol−&gt;add entry(vars[i], 1); } } delete[ ] myres; return sol; }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>void</head><label></label><figDesc>KS lp::generate cuts in lp(const BCP lp result&amp; lpres, const BCP vec&lt;BCP var*&gt;&amp; vars, const BCP vec&lt;BCP cut*&gt;&amp; cuts, BCP vec&lt;BCP cut*&gt;&amp; new cuts, BCP vec&lt;BCP row*&gt;&amp; new rows) { vector&lt;CglCutGenerator*&gt; cgs; // generate nodes at every 8th level if (current level() % 8 == 0) { CglKnapsackCover* kc = new CglKnapsackCover; kc−&gt;setMaxInKnapsack(pprob−&gt;nItems); cgs.push back(kc); cgs.push back(new CglGomory); } if (cgs.size() &gt; 0) { OsiSolverInterface* si = getLpProblemPointer()−&gt;lp solver; for (int i = vars.size() − 1; i &gt;= 0; −−i) si−&gt;setInteger(i); OsiCuts cutlist; for (int i = cgs.size() − 1; i &gt;= 0; −−i) { cgs[i]−&gt;setAggressiveness(100); cgs[i]−&gt;generateCuts(*si, cutlist); delete cgs[i]; cgs[i] = 0; } for (int i = cutlist.sizeRowCuts() − 1; i &gt;= 0; −−i) { LocalTreeId id = in localbranching() ? get ks user data()−&gt;id : LocalTreeId(); new cuts.push back(new LB cut(cutlist.rowCut(i), id)); } } } When using cut generation, we have to implement COIN/BCP's cuts to rows method. It is used to realize the abstract cut representations to actual rows of the LP relaxation. void KS lp::cuts to rows(const BCP vec&lt;BCP var*&gt;&amp; vars, BCP vec&lt;BCP cut*&gt;&amp; cuts, BCP vec&lt;BCP row*&gt;&amp; rows, const BCP lp result&amp; lpres, BCP object origin origin, bool allow multiple) { const int cutnum = cuts.size(); for (int i = 0; i &lt; cutnum; ++i) { const OsiRowCut* bcut = dynamic cast&lt;const LB cut*&gt;(cuts[i]); if (bcut) rows.push back(new BCP row(bcut−&gt;row(), bcut−&gt;lb(), bcut−&gt;ub())); else throw BCP fatal error("Unknown cut type in cuts to rows.\n"); } }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>vector&lt;double&gt; resource usages(pprob−&gt;nConstraints, 0.0); if (weight distribution == fun) { // calculate total resource usages for all resources for (int j = 0; j &lt; pprob−&gt;nConstraints; ++j) { for (int i = 0; i &lt; pprob−&gt;nItems; ++i) resource usages[j] += pprob−&gt;res[j][i]; } } multimap&lt;double, int&gt; relval; for (int i = 0; i &lt; pprob−&gt;nItems; ++i) { double allres = 0.0; if (relative weight == fun) { // relative weight of each item for (int j = 0; j &lt; pprob−&gt;nConstraints; ++j) allres += pprob−&gt;res[j][i] / pprob−&gt;rescons[j]; } else if (weight distribution == fun) { // weight distribution according to Senju and Toyoda for (int j = 0; j &lt; pprob−&gt;nConstraints; ++j) allres += pprob−&gt;res[j][i] * (resource usages[j] − pprob−&gt;rescons[j]); } relval.insert(pair&lt;double, int&gt;(pprob−&gt;val[i] / allres, i)); } The implementation of initial solution() is simple. Two solutions are generated, and an empty solution is returned to force the LP process to use the feasible solution derived from the first LP result. BCP solution generic* KS MetaHeuristic::initial solution( BCP vec&lt;BCP var core*&gt;&amp; corevars, std::map&lt;BCP IndexType, BCP var*&gt;&amp; vars, bool&amp; allow lp result) { solution relative weight = greedy(corevars, vars, relative weight); solution weight distribution = greedy(corevars, vars, weight distribution); allow lp result = true; return new BCP solution generic(false); } The tree created() handler is called when a new tree was created by the tree manager. Here we can create the two other local trees from the initial solutions created in initial solution(). void KS MetaHeuristic::tree created(const LocalTreeId&amp; id, LocalTree&amp; tree) { if (1 == index.trees.size()) create tree(solution relative weight); else if (2 == index.trees.size()) { create tree(solution weight distribution); }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>void</head><label></label><figDesc>KS MetaHeuristic::new node generated(const LocalTreeId&amp; id, LocalTree&amp; tree) { int maxnodes without improvement = params.entry(KS parameters::LB MaxNodesWithoutImprovement); int maxnodes = params.entry(KS parameters::LB MaxNodes); if (lb k &gt; 1 &amp;&amp; lb enabled &amp;&amp; !tree.get terminated() &amp;&amp; ((maxnodes without improvement &gt; 0 &amp;&amp; tree.get nodes created since improvement() &gt; maxnodes without improvement) | | (maxnodes &gt; 0 &amp;&amp; tree.get nodes created() &gt; maxnodes))) { terminate active trees(); if (index.nodes created since improvement &lt; index.nodes created since newtree) { // an improved solution was found, restart with this solution lb fixvars = params.entry(KS parameters::LB FixVarsInitial); lb k = params.entry(KS parameters::LB K); } else if (params.entry(KS parameters::LB FixVarsInitial) &gt; 0.0 | | params.entry(KS parameters::LB MultiK) != 1.0) { // the old tree did not yield a better solution, // so fix some variables and/or modify k value. lb fixvars += params.entry(KS parameters::LB FixVarsIncrement); lb fixvars = min(lb fixvars, params.entry(KS parameters::LB FixVarsMax)); lb k = (int) round(params.entry(KS parameters::LB MultiK) * lb k); lb k = max(lb k, params.entry(KS parameters::LB MinK)); lb k = min(lb k, params.entry(KS parameters::LB MaxK)); lb tightening = true; // do it only once } } }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>void</head><label></label><figDesc>KS MetaHeuristic::tree finished(const LocalTreeId&amp; id, LocalTree&amp; tree) { LB MetaHeuristic::tree finished(id, tree); if (0 == index.active trees.size() &amp;&amp; lb enabled) { if (index.nodes created since improvement &lt; index.nodes created since newtree) { create tree(); lb tightening = false; lb retries = 0; } else if (lb tightening &amp;&amp; lb retries &lt; params.entry(KS parameters::LB MaxRetries)) { create tree(); ++lb retries; } else lb enabled = false; } }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9.1: Final objective value and the corresponding online performance weights for a test instance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>( 3 )</head><label>3</label><figDesc>k = 13, variable fixing: 0.1, 0.1, 0.8, maximum nodes per tree: 10000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9.2: Two sample graphs for mknapcb7 showing a benefit for local branching on the left, and an advantage for normal Branch and Cut on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 9 .</head><label>9</label><figDesc>3 again shows two sample plots comparing the three parameter settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>( 2 )</head><label>2</label><figDesc>k = 10, variable fixing: 0.1, 0.1, 0.8, maximum nodes per tree: 5000 (3) k = 13, variable fixing: 0.1, 0.1, 0.8, maximum nodes per tree: 1000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9.4: Clear advantages for local branching in test instance MK-gk11.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>( 3 )</head><label>3</label><figDesc>k = 13, variable fixing: 0.1, 0.1, 0.8, maximum nodes per tree: 1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>( 3 )</head><label>3</label><figDesc>k = 13, variable fixing: 0.1, 0.1, 0.8, maximum nodes per tree: 10000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>( 3 )</head><label>3</label><figDesc>k = 13, variable fixing: 0.1, 0.1, 0.5, maximum nodes per tree: 5000 n d best final objective online performance Wilcoxon mknapcb7 100 30 (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>( 2 )</head><label>2</label><figDesc>k = 10, variable fixing: 0.1, 0.1, 0.8, maximum nodes per tree: 5000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>( 3 )</head><label>3</label><figDesc>k = 13, variable fixing: 0.1, 0.1, 0.8, maximum nodes per tree: 1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 9 .Figure 9 .</head><label>99</label><figDesc>Figure 9.5: The final objective value for MK-gk11, using a time limit of 2 hours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>( 2 )</head><label>2</label><figDesc>k = 5, variable fixing: 0.05, 0.2, 0.5, maximum nodes per tree: 250 (3) k = 5, variable fixing: 0.05, 0.2, 0.5, maximum nodes per tree: 500 (4) k = 10, variable fixing: 0.05, 0.2, 0.5, maximum nodes per tree: 500 (5) k = 20, variable fixing: 0.05, 0.2, 0.5, maximum nodes per tree: 1000 Chapter 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>/</head><label></label><figDesc>** Return whether the queue is empty or not */ inline bool empty() const { return !normal root node &amp;&amp; pq.size() == 1; } /** Return the top member of the queue */ BCP tm node* top() const { return ((normal root node &amp;&amp; use normal root node) | | (normal root node &amp;&amp; pq.size() == 1)) ? normal root node : pq[1]; } The last modification correctly initializes the new variables in the constructor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head></head><label></label><figDesc>BCP node queue(BCP tm prob&amp; p): p(q), pq(), normal root node(0), use normal root node(false) { pq.push back(NULL); }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>void</head><label></label><figDesc>BCP node queue::pop() { if (use normal root node &amp;&amp; normal root node) { normal root node = 0; return; } if (normal root node &amp;&amp; pq.size() &lt;= 2) { // reinsert normal root node when the last element is popped insert(normal root node, false); normal root node = 0; use normal root node = false; } (. . .)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>void</head><label></label><figDesc>BCP node queue::insert(BCP tm node* node, bool replace normal root node) { #ifdef COIN LB if (node−&gt;user data() &amp;&amp; replace normal root node) { const LB user data* ud = dynamic cast&lt;const LB user data*&gt; (node−&gt;user data()); if (ud &amp;&amp; LB user data::UD NormalRoot == ud−&gt;type) { normal root node = node; return; } } #endif (. . .)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head></head><label></label><figDesc>− p.param(BCP tm par::TerminationGap Relative))) process this = false; if (p.candidates.use normal root node) { process this = true; p.candidates.use normal root node = 0; } if (process this) break; if (desc−&gt;indexed pricing.get status() == BCP PriceNothing | | p.current phase colgen == BCP DoNotGenerateColumns Fathom) { next node−&gt;status = BCP PrunedNode OverUB; p.pruned nodes.push back(next node);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>The related part of the Makefile.bc file should look like the following: USER SRC = USER SRC += KS init.cpp USER SRC += KS lp.cpp USER SRC += KS tm.cpp USER SRC += KS metaheuristic.cpp</head><label>related</label><figDesc></figDesc><table># LB sources 

USER SRC += LB tm.cpp 

USER SRC += LB lp.cpp 

USER SRC += LB cut.cpp 

USER SRC += LB user data.cpp 

USER SRC += LB init.cpp 

USER SRC += localtree.cpp 

USER SRC += localtreeid.cpp 

USER SRC += localtreemanager.cpp 

USER SRC += LB metaheuristic.cpp </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>final objective value 

online performance 
number of local trees 
instance 
(1) 
(2) 
(3) 
(1) 
(2) 
(3) 
(1) (2) 
(3) 
0 
21946 21946 21946 13719.11 13719.11 13719.11 
0 
2 
29 
1 
21716 21716 21716 13700.76 13710.87 13699.94 
0 
1 
25 
2 
20754 20754 20754 13096.68 13102.44 13102.44 
0 
1 
27 
3 
21464 21464 21464 13532.09 13511.85 13524.59 
0 
1 
26 
4 
21844 21844 21844 13797.81 13809.01 13809.01 
0 
1 
24 
5 
22176 22176 22176 14005.53 14005.90 14006.11 
0 
1 
26 
6 
21799 21799 21799 13718.36 13723.17 13723.17 
0 
1 
26 
7 
21397 21327 21327 13493.88 13472.05 13473.10 
0 
1 
25 
8 
22471 22475 22482 14187.96 14201.18 14210.38 
0 
1 
24 
9 
20983 20983 20983 13230.11 13230.08 13223.38 
0 
1 
27 
10 
40691 40691 40767 25722.46 25723.66 25742.90 
0 
1 
25 
11 
41308 41308 41304 26108.12 26108.20 26106.94 
0 
1 
25 
12 
41630 41630 41630 26304.63 26304.63 26304.63 
0 
1 
25 
13 
41041 41041 41041 25937.69 25937.69 25937.69 
0 
1 
27 
14 
40889 40889 40889 25842.11 25842.93 25838.43 
0 
1 
24 
15 
41028 41058 41022 25934.05 25921.21 25915.76 
0 
1 
25 
16 
41062 41038 41038 25957.11 25936.80 25935.54 
0 
1 
25 
17 
42719 42719 42719 26976.12 26979.48 26979.01 
0 
1 
25 
18 
42230 42230 42230 42230.00 42230.00 42230.00 
0 
2 
49 
19 
41700 41700 41700 41700.00 41700.00 41700.00 
0 
1 
26 
20 
57494 57494 57494 36319.24 36320.82 36322.32 
0 
1 
28 
21 
60027 60027 60026 37944.30 37943.28 37943.50 
0 
1 
26 
22 
58052 58015 58052 36677.22 36670.90 36688.60 
0 
1 
26 
23 
60776 60776 60776 38415.55 38415.96 38415.96 
0 
2 
34 
24 
58884 58884 58884 37214.71 37214.71 37214.71 
0 
2 
26 
25 
60011 60011 60011 37919.29 37910.45 37910.45 
0 
2 
30 
26 
58132 58132 58132 36737.55 36737.63 36741.17 
0 
1 
27 
27 
59064 59064 59064 37325.45 37333.21 37333.21 
0 
2 
29 
28 
58975 58975 58975 37277.47 37278.91 37276.15 
0 
1 
25 
29 
60603 60603 60603 38295.77 38299.39 38299.39 
0 
1 
27 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 9 .</head><label>9</label><figDesc></figDesc><table>2: All results for mknapcb7 using a single initial solution (n = 100, d = 30.) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 9 .</head><label>9</label><figDesc></figDesc><table>3: All results for mknapcb8 using a initial solution (n = 250, d = 30.) </table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COIN/BCP patches</head><p>The local branching framework requires some small patches to the COIN/BCP source. The patches add the following functionality to COIN/BCP:</p><p>• Support for user-defined messages between LP and TM modules has been added.</p><p>• A special slot for the normal tree root node is provided in the candidate queue. This is necessary because the normal root node must be used whenever a new local tree is started.</p><p>• There is no way for the COIN/BCP user classes to catch all pruned nodes. Pruned nodes are now added to a list that is available to the framework's tree manager.</p><p>• When a local tree is aborted, all nodes must be removed from the candidate list. Since the nodes are potentially scattered over the candidate list, and the candidate list can contain millions of nodes, explicitly deleting all nodes may be ineffective. Instead, a list of local tree identification numbers is kept and nodes from these trees are pruned immediately instead of being returned to the tree manager.</p><p>All filenames in this section are relative to the COIN/BCP root directory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Adding User-Defined Messages</head><p>In order to support user-defined messages between LP and TM modules, we have to add an unique message tag for user messages and stubs for packing and unpacking routines. We start by adding two new message tags to the BCP message tag enumeration in in- clude/BCP message tag.hpp (written in bold face): </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Counting Pruned Nodes</head><p>We start by adding a new public member to the BCP tm prob class. It is used to store nodes that have been pruned. Since even pruned nodes are never deleted from memory, the tree manager can access this list without further restrictions. The tree manager can also empty the list when the nodes have been processed. /** Pruned nodes are stored in this list -may be cleared when no longer needed */ BCP vec&lt;BCP tm node*&gt; pruned nodes;</p><p>There are two more places where nodes may be pruned inside the tree manager.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.1 TM/BCP tm msg node rec.cpp</head><p>Among other things, the method BCP tm unpack branching info() prunes child nodes gen- erated from a branching object when necessary. We add those nodes to our pruned nodes() list. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.2 TM/BCP tm msgproc.cpp</head><p>The tree manager also receives pruned nodes from LP processes. These nodes are also added to pruned nodes. With these modifications, the tree manager is able to track the number of active nodes for all local trees. It uses the local tree identification number stored in the user data of the pruned nodes to update the node numbers of the corresponding local tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Aborting Local Trees</head><p>For aborting local trees, we store a set of local tree identification numbers in the candidate list. In the tree manager method responsible for finding a new subproblem for a LP process, we simply discard nodes that are in this set of terminated trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.1 include/BCP tm node.hpp</head><p>We have to include two additional headers, again wrapped in a precompiler conditional. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.2 TM/BCP tm functions</head><p>In BCP tm start one, we modify the head of the main loop, the updates marked with bold face. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test Scripts</head><p>The results of chapter 9 were retrieved using test scripts written in Bash and Python code. The printstats.py script expects a file containing the output of a set of test runs, usually covering more than one instance and testing several configurations. The results are grouped by filename and configuration, and miscellaneous statistical data can be extracted. For example, tables containing the final objective values or the online performance rating. Additionally, plots of the final objective value can be created. The gnuplot program is used to generate these cuts which can be viewed on screen or written to a postscript file. Since the test logs are usually rather large and take some seconds for processing, a simple interactive command line interface was implemented to shorten user response times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Generating Log Files</head><p>To simplify testing different configurations on many different files, a short Bash script is avail- able. The configurations to be tested are entered as an array, which is then applied to every file supplied. Since the instances of the OR Library <ref type="bibr" target="#b1">[2]</ref> contain 30 test instances per file, the instance numbers to be tested can be specified in an array.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>#!/bin/bash</head><p>outfile=testall.log rm $outfile instances="'seq 0 29'" testcases=("LB K 0" "LB K 10 LB MaxNodes 5000" "LB K 20") for file in $* do echo −e "Processing" $file ". . .\n" for inst in $instances do for opts in "${testcases <ref type="bibr">[@]</ref>}" do date &gt;&gt; $outfile echo −e "Processing" $file ", instance" $inst ", params =" $opts ". . .\n" &gt;&gt; $outfile nice Linux−O/bcps $opts ${file}:${inst} &gt;&gt; $outfile echo &gt;&gt; $outfile done done done</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gomory cuts revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Balas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ceria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cornuéjols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Natraj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research Letters</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Operation research library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Beasley</surname></persName>
		</author>
		<ptr target="http://www.brunel.ac.uk/depts/ma/research/jeb/info.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An approximate dynamic programming approach to multidimensional knapsack problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bertsimas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Demir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="550" to="565" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Approximation algorithms for knapsack problems with cardinality constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caprara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kellerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pferschy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pisinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="333" to="345" />
		</imprint>
	</monogr>
	<note>European Journal of Operational Research</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Combining and strengthening gomory cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ceria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cornuejols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dawande</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>In E. Balas and J. Clausen, editors, Integer Programming and Combinatorial Optimization: Proc. of the 4th International IPCO Conference, pages 438-451</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A genetic algorithm for the multidimensional knapsack problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Beasley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Heuristics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Edmonds polytopes and a hierarchy of combinatorial problems</title>
		<editor>V. Chvátal</editor>
		<imprint>
			<date type="published" when="1973" />
			<biblScope unit="page" from="305" to="337" />
		</imprint>
	</monogr>
	<note>Discrete Mathematics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Exploring relaxation induced neighborhoods to improve mip solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Danna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rothberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Pape</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Mathematical Programming</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">In Handbook of Genetic Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<pubPlace>101, New York</pubPlace>
		</imprint>
	</monogr>
	<note>A genetic algorithm tutorial</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On the chvátal rank of polytopes in the 0/1 cube</title>
		<editor>F. Eisenbrand</editor>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="21" to="27" />
		</imprint>
	</monogr>
	<note>Discrete Applied Mathematics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Gomory-Chvátal cutting planes and the elementary closure of polyhedra</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fully parallel generic branch-andcut</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Esö</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ladányi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Ralphs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Trotter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth SIAM Conference on Parallel Processing for Scientific Computing</title>
		<meeting>the Eighth SIAM Conference on Parallel Processing for Scientific Computing</meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">for Enterprise Science. Benchmarks for the multiple knapsack problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename></persName>
		</author>
		<ptr target="http://hces.bus.olemiss.edu/tools.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Outline of an algorithm for integer solutions to linear programs</title>
		<imprint>
			<date type="published" when="1958" />
			<publisher>R. E. Gomory</publisher>
			<biblScope unit="page" from="275" to="278" />
		</imprint>
	</monogr>
	<note>Bulleting of the American Mathematical Society</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Recent Advances in Mathematical Programming, pages 269-302</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Gomory</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963" />
		</imprint>
	</monogr>
	<note>An algorithm for integer solutions to linear programs</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Permutation-based evolutionary algorithms for multidimensional knapsack problems</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Proceedings of 2000 ACM Symposium on Applied Computing</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Mapping, order-independent genes and the knapsack problem. Proceedings of the 1st IEEE International Conference on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="1994" />
			<publisher>R. Hinterding</publisher>
			<biblScope unit="page" from="13" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Fast approximation algorithms for the knapsack and sum of subset problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">H</forename><surname>Ibarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>ACM</publisher>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="463" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Knapsack Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kellerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pferschy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pisinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A polynomial algorithm for linear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Khachian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1093" />
			<pubPlace>Nauk USSR, 224</pubPlace>
		</imprint>
	</monogr>
	<note>Doklady Akad</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A branch and bound algorithm for the knapsack problem</title>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="page" from="723" to="735" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">On the existence of fast approximation schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schrader</surname></persName>
		</author>
		<idno>O. L. Mangasarian, R. R. Meyer, and S. Robinson, editors, Nonlinear Programming 4, pages 415-437. Academic Press</idno>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An automatic method for solving discrete programming problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Land</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Doig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="page" from="497" to="520" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Branch-and-bound methods for integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Optimization, volume 2, pages 509-519</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>Kluwer Academic Publishers</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An approximate algorithm for multidimensional zero-one knapsack problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guignard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="402" to="410" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The common optimization interface for operations research</title>
	</analytic>
	<monogr>
		<title level="m">IBM Journal of Research and Development</title>
		<imprint>
			<publisher>R. Lougee-Heimer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">In Encyclopedia of Optimization, volume 2, pages 519-525</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>Kluwer Academic Publishers</orgName>
		</respStmt>
	</monogr>
	<note>Branch-and-cut algorithms for integer programming</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Cutting plane algorithms for integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>In Encyclopedia of Optimization. volume 2, pages 525-533. Kluwer Academic Publishers</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A branch-and-cut algorithm for the resolution of large-scale symmetric traveling salesman problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Padberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rinaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="100" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<title level="m">D. Pisinger. Algorithms for Knapsack Problems</title>
		<imprint>
			<date type="published" when="1995-02" />
		</imprint>
		<respStmt>
			<orgName>PhD thesis, University of Copenhagen, Dept. of Computer Science</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Weight-codings in a genetic algorithm for the multiconstraint knapsack problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 IEEE Congress on Evolutionary Computation, pages 596-603</title>
		<meeting>the 1999 IEEE Congress on Evolutionary Computation, pages 596-603</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Empirical analysis of locality, heritability and heuristic bias in evolutionary algorithms: A case study for the multidimensional knapsack problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Raidl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gottlieb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Accepted for publication in the Evolutionary Computation Journal</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A heuristic with tie breaking for certain 0-1 integer programming models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Scudder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="page" from="613" to="623" />
		</imprint>
	</monogr>
	<note>Naval Research Logistics Quarterly</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Some experiences on solving multiconstraint zero-one knapsack problems with genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Voss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>INFOR 32</publisher>
			<biblScope unit="page" from="226" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A simplified algorithm for obtaining approximate solution to zero-one programming problems</title>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<date type="published" when="1417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A hybrid approach for the 0-1 multidimensional knapsack problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vasquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of IJCAI 01</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Integer Programming. John Wiley and Sons</title>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>L. A. Wolsey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
