<Publication>
  <id>TUW-140047</id>
  <title>MIREX 2006 Computing Statistical Spectrum Descriptors for Audio Music Similarity and Retrieval</title>
  <abstractText>This paper describes our submission to the MIREX 2006 Audio Music Similarity and Retrieval task. The task was to submit an audio feature extraction algorithm, to compute music similarity measures and to return a distance matrix from an audio collection consisting of 5000 pieces, which was subsequently evaluated through human listening tests as well as objective statistics. We submitted a new implementation of the Statistical Spectrum Descriptor (SSD) audio feature extractor and computed the distance matrix directly from feature space. Results from the human evaluation show that our approach is among the top 5 algorithms which furthermore show no statistically significant performance differences. The evaluation of a number of objective statistics ranked our algorithm 3rd in most of the cases. Our submission was one of the two fastest in terms of total run-time, having the shortest distance computation time. The approach has also been evaluated on Audio Cover Song Identification, where it was the best-performing &quot;Au-dio Music Similarity and Retrieval&quot; submission, outper-formed, however, by 4 submissions which were specifically designed for the cover identification task.</abstractText>
  <keywords/>
  <authors>
    <Author>
      <firstNames>
        <string>Thomas</string>
      </firstNames>
      <lastName>Lidy</lastName>
      <affiliations>
        <Affiliation>
          <id>aff0</id>
          <institution>Vienna University of Technology</institution>
          <department>Department of Software Technology and Interactive Systems Favoritenstrasse</department>
          <country>Austria</country>
          <countryCode>AT</countryCode>
        </Affiliation>
      </affiliations>
    </Author>
    <Author>
      <firstNames>
        <string>Andreas</string>
      </firstNames>
      <lastName>Rauber</lastName>
      <affiliations>
        <Affiliation reference="/Publication[1]/authors[1]/Author[1]/affiliations[1]/Affiliation[1]"/>
      </affiliations>
    </Author>
  </authors>
  <affiliations>
    <Affiliation reference="/Publication[1]/authors[1]/Author[1]/affiliations[1]/Affiliation[1]"/>
  </affiliations>
  <sections>
    <Section>
      <level>1.</level>
      <title>Introduction</title>
      <referenceIds>
        <string>ref2</string>
        <string>ref3</string>
      </referenceIds>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.</level>
      <title>MIREX 2006 Tasks</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.1.</level>
      <title>Audio Music Similarity and Retrieval</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>1</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.1.1.</level>
      <title>Human Evaluation</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.</level>
      <title>Implementation</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.1.</level>
      <title>Audio Feature Extraction</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.1.2.</level>
      <title>Statistics</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>2.2.</level>
      <title>Audio Cover Song Identification</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>3</title>
      <referenceIds>
        <string>ref4</string>
        <string>ref5</string>
        <string>ref3</string>
        <string>ref6</string>
      </referenceIds>
      <referenceCitations/>
    </Section>
    <Section>
      <level>3.2.</level>
      <title>Distance Matrix Calculation</title>
      <referenceIds>
        <string>ref5</string>
      </referenceIds>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.</level>
      <title>MIREX 2006 Results</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.1.</level>
      <title>Audio Music Similarity and Retrieval</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.1.1.</level>
      <title>Human Evaluation</title>
      <referenceIds>
        <string>ref6</string>
      </referenceIds>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.1.3.</level>
      <title>Runtimes</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <level>4.2.</level>
      <title>Audio Cover Song Identification</title>
      <referenceIds/>
      <referenceCitations/>
    </Section>
  </sections>
  <citationContexts/>
  <references>
    <Reference>
      <id>ref1</id>
      <referenceIdString>b0</referenceIdString>
      <title>It is also one of the two fastest algorithms, with by far the most efficient distance calculation. Different statistics have been derived from genre, artist and album assignments, which gave our algorithm the 3rd rank in most of the cases, and 2nd rank in one case</title>
      <source>The first large-scale human listening test for Music Similarity and Retrieval in MIREX showed, that our algorithms are competing with state-of-the-art algorithms-no significant difference in performance has been found between the top 5 algorithms</source>
      <authors/>
      <note>Furthermore, the database used is highly skewed towards 2 main genres (Rock and Rap/Hip-Hop). Our algorithm has also been evaluated on Audio Cover Song Identification together with 3 of the other Audio Mu</note>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref2</id>
      <referenceIdString>b1</referenceIdString>
      <title>Playsom and pocketsomplayer, alternative interfaces to large music collections</title>
      <source>Proceedings of the Sixth International Conference on Music Information Retrieval</source>
      <authors>
        <ReferenceAuthor>
          <firstNames>
            <string>R</string>
          </firstNames>
          <lastName>Neumayer</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>M</string>
          </firstNames>
          <lastName>Dittenbach</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>A</string>
          </firstNames>
          <lastName>Rauber</lastName>
        </ReferenceAuthor>
      </authors>
      <note>September 11-15</note>
      <pageFrom>618</pageFrom>
      <pageTo>623</pageTo>
      <publicationDateString>2005</publicationDateString>
      <publicationYear>2005</publicationYear>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref3</id>
      <referenceIdString>b2</referenceIdString>
      <title>Evaluation of feature extractors and psycho-acoustic transformations for music genre classification</title>
      <source>Proceedings of the Sixth International Conference on Music Information Retrieval</source>
      <authors>
        <ReferenceAuthor>
          <firstNames>
            <string>T</string>
          </firstNames>
          <lastName>Lidy</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>A</string>
          </firstNames>
          <lastName>Rauber</lastName>
        </ReferenceAuthor>
      </authors>
      <pageFrom>34</pageFrom>
      <pageTo>41</pageTo>
      <publicationDateString>2005</publicationDateString>
      <publicationYear>2005</publicationYear>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref4</id>
      <referenceIdString>b3</referenceIdString>
      <source>&quot;Music Information Retrieval Evaluation eXchange-audio genre classification</source>
      <authors/>
      <note>Website</note>
      <publicationDateString>2005</publicationDateString>
      <publicationYear>2005</publicationYear>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref5</id>
      <referenceIdString>b4</referenceIdString>
      <source>Combined fluctuation features for music genre classification</source>
      <authors>
        <ReferenceAuthor>
          <firstNames>
            <string>T</string>
          </firstNames>
          <lastName>Lidy</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>A</string>
          </firstNames>
          <lastName>Rauber</lastName>
        </ReferenceAuthor>
      </authors>
      <publicationDateString>2005-09</publicationDateString>
      <publicationYear>2005</publicationYear>
      <publicationMonth>09</publicationMonth>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref6</id>
      <referenceIdString>b5</referenceIdString>
      <source>Springer Series of Information Sciences</source>
      <publisher>Springer</publisher>
      <authors>
        <ReferenceAuthor>
          <firstNames>
            <string>E</string>
          </firstNames>
          <lastName>Zwicker</lastName>
        </ReferenceAuthor>
        <ReferenceAuthor>
          <firstNames>
            <string>H</string>
          </firstNames>
          <lastName>Fastl</lastName>
        </ReferenceAuthor>
      </authors>
      <note>Psychoacoustics-Facts and Models, ser</note>
      <publicationDateString>1999</publicationDateString>
      <publicationYear>1999</publicationYear>
      <type>m</type>
      <publication reference="/Publication[1]"/>
    </Reference>
  </references>
</Publication>