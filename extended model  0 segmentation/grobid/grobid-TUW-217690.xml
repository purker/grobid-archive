<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Users\Angela\git\grobid\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-12-29T00:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parallel Tracking and Mapping in Hofburg Festsaal</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Gerstweiler</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Interactive Media Systems Group</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannes</forename><surname>Kaufmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Interactive Media Systems Group</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Kosyreva</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Interactive Media Systems Group</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Schönauer</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Interactive Media Systems Group</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuel</forename><surname>Vonach</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Interactive Media Systems Group</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Parallel Tracking and Mapping in Hofburg Festsaal</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parallel Tracking and Mapping in Hofburg Festsaal</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Georg Gerstweiler* Hannes Kaufmann Olga Kosyreva Christian Schönauer Emanuel Vonach</head><p>Interactive Media Systems Group, Vienna University of Technology </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Precise localization for mobile Augmented Reality in large indoor environments without specific tracking infrastructure is challenging. This is especially true for rooms with changing properties, like lighting, seating and carpeting. With these constraints a map for a vision based tracking approach has to be continuously updated. The Parallel Tracking and Mapping (PTAM) algorithm is capable of generating and extending a map while tracking the camera pose in an unknown environment. However, it has originally been designed for small workspace environments and has therefore certain limitations. We have extended and modified the original implementation in order to ensure efficient and robust map generation and tracking in large rooms. Furthermore, we have tested a mobile setup with the system in Festsaal in Vienna's Hofburg, which is close to thousand square meters in size. The user's position and path was tracked while the environment was augmented with virtual objects and the system was successfully tested for robustness and occlusions.</p><p>Vienna's historic Hofburg accommodates many grandiose rooms, the largest of which is Festsaal. These premises are being used as venues for exhibitions, conferences and cultural events. In this context our project partner, the Wiener Kongresszentrum Hofburg, is interested in providing visitors with audio/video information about the current room or paintings on walls and ceilings (frescos) as well as different room configurations on a mobile device. Furthermore, a visualization of the current position on a map can aid navigation within Hofburg. This can be helpful to find a certain conference booth or another person during an event (e.g. a ball). The rooms of the Hofburg are rich of features on walls and ceilings, which makes them well-suited for a computer vision- based approach. However, changes in lighting, seating, carpeting and other changing elements like conference booths pose certain restrictions. Therefore, we favor PTAM <ref type="bibr">[1]</ref>, which doesn't require any fiducial markers or models for pose estimation, over model- based approaches. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[Scene Analysis]: Object Recognition-Tracking</head><p>Our test platform was a dual-core laptop with an off-the-shelf webcam. The software was based on Castle and Klein's PTAM implementation <ref type="bibr">[2]</ref> with several extensions and modifications to ensure efficient and robust map generation and tracking in large rooms.</p><p>In a first stage the system was used to create a detailed map in a semi-automatic procedure, while walking through the room. Our adaptations made this process more efficient by improving the selection of features and keyframes, resulting in a more precise map while using less keyframes. New interface methods allow manual intervention to avoid structures, which shouldn't be integrated in the map (e.g. falsework present in Festsaal during first tests, or chandeliers, which are problematic due to their complicated structure and reflective properties). In addition, we have modified the constraints of the original algorithm to allow tracking behind the user's original position. New constraints maintain efficiency in the larger environment for example by avoiding high feature density in certain areas and removal of features outside the basic cubical shape of the room.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS &amp; CONCLUSION</head><p>We have tested our mobile setup in Festsaal and created a detailed map. Once the camera pose was available, the environment was augmented with various virtual content. In a first test we added a virtual theater stage and walked around it. The position and scaling of the scene was robust, while the frame-rate remained close to the update-rate of the camera. In addition, we added a virtual furniture set, which showed similar results. Another important use case was tracking of a user within the map. Therefore, we reconstructed the path of the user frame-by-frame in real-time. Another test demonstrated the system's behavior despite rapid camera movement and occlusions. During first tests in Festsaal there was a falsework in the middle of the room. While massive occlusions pose problems on any vision-based tracking system, with limited occlusions the tracking remained robust in many cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REFERENCES</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A user with the mobile setup in Festsaal (left) and a virtual theater stage placed on the real stage (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Keywords:</head><label></label><figDesc>Tracking, and mapping, augmented, and virtual realities 2 SYSTEM &amp; WORKFLOW Index Terms: H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities-; I.4.8</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
