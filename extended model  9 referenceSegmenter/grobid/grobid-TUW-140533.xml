<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Users\Angela\git\grobid\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-12-29T00:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Formal Program Verification: a Comparison of Selected Tools and Their Theoretical Foundations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ausgeführt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Computersprachen</orgName>
								<orgName type="laboratory">Theory and Logic Group Institute of Computer Languages Vienna University of Technology</orgName>
								<orgName type="institution">Technischen Universität Wien</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Formal Program Verification: a Comparison of Selected Tools and Their Theoretical Foundations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>MAGISTERARBEIT</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MASTER THESIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zusammenfassung</head><p>Formale Spezifikation und Verifikation sind durch die durch kontinuierliche Weiterentwicklung in letzter Zeit an einem Punkt angelangt, wo Programme beinahe automatisch verifiziert werden können.</p><p>Das Ziel dieser Magisterarbeit ist es, sowohl kommerzielle als auch für wissenschaftliche Zwecke entwickelte Verifikationsprogramme zu testen. Der Hauptaugenmerk liegt auf dem Nutzen dieser Werkzeuge in der Software- Entwicklung und in der Lehre. Hierzu wird diese Magisterarbeit die theo- retischen Grundlagen vorstellen und auf die verschiedenen Fähigkeiten und Eigenheiten der ausgewählten Werkzeuge eingehen.</p><p>Die theoretischen Grundlagen behandeln einerseits Ansätze, die für die formale Verifikation gebraucht werden, andererseits wird die Funktionsweise der ausgewählten Werkzeuge erklärt.</p><p>Die begutachteten Programme sind der Frege Program Prover, KeY, Per- fect Developer und das Prototype Verification System. Die Beispiele, mit denen diese Werkzeuge getestet werden, sind typische Problemstellung der Informatik. Bei der Evaluation wird auf den ganzen Ablauf beim Einsatz dieser Werkzeuge eingegangen und nicht nur auf das Endergebnis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Formal specification and verification of software have made small but contin- uous advances throughout its long history, and have reached a point where commercial tools became available for verifying programs semi-automatically or automatically.</p><p>The aim of the master thesis is to evaluate commercial and academic verification tools with respect to their usability in developing software and in teaching formal methods. The thesis will explain the theoretical foundation and compare the capabilities and characteristics of selected commercial and academic tools on concrete examples.</p><p>The theoretical foundations deal on the one hand with the general ideas and principles of formal software verification, on the other hand present some internals of the selected tools to give a comprehensive understanding.</p><p>The discussed tools are the Frege Program Prover, KeY, Perfect De- veloper, and the Prototype Verification System. The examples encompass simple standard computer science problems. The evaluation of these tools concentrates on the whole development process of specification and verifica- tion, not just on the verification results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>I would like to thank my family, especially my mother Inge, for supporting me.</p><p>Gernot Salzer, my advisor, helped me whenever he could and invested a lot of time in discussing and investigating problems together with me. David Crocker gave excellent support on Perfect Developer, Andreas Roth and Steffen Schlager offered helpful instructions on KeY, Jürgen Winkler provided papers and references on FPP. Also the subscribers of the PVS mailing list came up with nice ideas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Formal software verification has become a more and more important issue in developing security related software during the last decades. As a reaction, ISO -the International Organisation for Standardisation -issued the ISO 15408 Standard, defining exactly various quality levels for tested and verified software. This standard is represented in the Common Criteria Project, with members of security organisations around the globe.</p><p>During the last years, formal specification and verification tools have been introduced, especially designed for standard development processes. The focus ranges from security related projects, over hardware circuit verification to software driver verification. In particular model checking has been very successful.</p><p>Based on this evolution this thesis deals with four specification and veri- fication tools that enable the user to build software complying with the most demanding restrictions of the ISO 15408 Standard. The aim is to construct software that meets the Evaluation Assurance Levels 6 and 7 (EAL 6, EAL 7) defined in the Common Criteria Project. In other words this means fully verified specification and code.</p><p>For a long time users of these tools have been assumed to be experts in formal methods. With new target groups requirements changed. Therefore this thesis evaluates the tools with respect to two groups: software engineers with a good knowledge of computer science but without specific training in formal methods, and students of computer science and software engineering in the middle of their studies, being confronted with formal verification tools for the first time.</p><p>The four tools that will be investigated are the Frege Program Prover, KeY, Perfect Developer, and the Prototype Verification System. In the first part of this work, the theoretical background -main calculi and ideas of formal verification -is presented. Then the internals of the tools are dis- cussed, showing the different approaches and techniques from the theoretical side. Finally, by going through a set of simple standard computer science examples, the different characteristics and capabilities are presented in a practical form. By examining the tools from both sides, theory and practice, their usability in developing software and in teaching formal methods for the above defined target group is discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Historical perspective</head><p>Formal verification has always been a well discussed problem by a lot of excellent computer scientists. Jones <ref type="bibr">[2003]</ref> mentions three phases of historical development:</p><p>Pre-Hoare Herman Goldstine, John von Neumann, Alan Turing, Robert</p><p>Floyd and John McCarthy are only some famous computer pioneers that can be mentioned here. They started thinking about errors in their programs from the start on and had already ideas to avoid them. The idea of assertions for programs was borne.</p><p>Hoare's axiomatic approach Tony Hoare presented his axioms in his fa- mous paper Hoare <ref type="bibr">[1969]</ref> -the calculus is also discussed in section 2.4 of this thesis. This formulation led to new approaches towards formal verification in the late 1970s.</p><p>Post-Hoare After Hoare's axiomatic approach formal verification became a broad scientific research problem with connections to the semantics of programming languages. Many scientists, like Edsger Dijkstra, Tony Hoare himself and many more, continued to work on these foundations and made continuous improvements.</p><p>Until today automatic verification is an intensively considered problem. E.g. Tony Hoare stated the problem of building a "verifying compiler" as one of the big challenges of computer science in his paper Hoare <ref type="bibr">[2003]</ref>. Also the idea of reusing verified software is appreciated by the scientific community -Meyer <ref type="bibr">[2003]</ref> deals in detail with that idea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Theoretical Foundations</head><p>This section deals with general ideas and principles underlying formal soft- ware verification and explains basic notions and calculus frameworks. The reader is assumed to have a minimal background on formal logic, es- pecially in classical propositional and first order logic. Detailed explanations of these basics are given in Gallier <ref type="bibr">[2003]</ref> or Huth and Ryan <ref type="bibr">[2004]</ref>.</p><p>The following sections discuss an introduction to propositional logic, nat- ural deduction, the sequent calculus, the Hoare calculus and weakest precon- ditions.</p><p>We present only rules for propositional logic to give the flavour of the various approaches. Real systems for proving statements about programs are more complex in at least two respects: first, propositional logic has to be extended to first-order or even higher-order logics, i.e., in general we need quantification over first-order or higher-order variables. Second, provers need built-in knowledge about the data types used in programs and formal specifi- cations, like reals and integers, lists and sets. Moreover, special mechanisms have to be provided to deal with equalities, inequalities and other basic the- ories, using e.g. decision procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Propositional Logic</head><p>This section deals with the basics of propositional classical logic. The fol- lowing notations will be used as the basic formalism in later chapters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntax</head><p>The alphabet for propositional formulas consists of:</p><p>A countable set of propositional symbols A i , logical connectives ∨, ∧, ¬, ⊃, ⊥ and auxiliary symbols (parentheses).</p><p>Definition 2.1 The set of well formed propositional formulas PROP is in- ductively defined as:</p><p>Every propositional symbol A i and ⊥ are ∈ PROP , Whenever A, B ∈ PROP , then ¬A, A ⊃ B, A ∨ B, A ∧ B ∈ PROP .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantics</head><p>Definition 2.2 A valuation v is a function that maps well formed proposi- tional formula to truth values, hence v : PROP → {true, false}.</p><p>Let A, B ∈ PROP . We write v |= A iff A evaluates to true under the valuation v. The satisfaction relation is defined as:</p><formula xml:id="formula_0">v |= A iff v(A) = true v |= A ∧ B iff v |= A and v |= B v |= A ∨ B iff v |= A or v |= B v |= A ⊃ B iff v A or v |= B v |= ¬A iff v A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Natural Deduction</head><p>Let φ 1 , φ 2 , φ 3 , . . . , φ n be formulas, which are called premises, and ψ be an- other formula called conclusion. Definition 2.3 The expression φ 1 , φ 2 , φ 3 , . . . , φ n ψ is called sequent.</p><p>But instead of φ 1 , φ 2 , φ 3 , . . . , φ n ψ we write</p><formula xml:id="formula_1">φ 1 φ 2 φ 3 . . . φ n ψ</formula><p>This means that if all premises φ 1 , φ 2 , φ 3 , . . . , φ n are true, we conclude that the conclusion ψ is true.</p><p>From now on let φ, ψ and χ denote propositional formulas. The nat- ural deduction rules for propositional logic distinguish between introduction (i-rules) and elimination (e-rules) rules for connectives and are defined as follows:</p><p>Disjunction Rules:</p><formula xml:id="formula_2">∨i 1 φ φ ∨ ψ ∨i 2 ψ φ ∨ ψ ∨e φ ∨ ψ φ χ ψ χ χ Conjunction Rules: ∧i φ ψ φ ∧ ψ ∧e 1 φ ∧ ψ φ ∧e 2 φ ∧ ψ ψ</formula><p>Implication Rules: </p><formula xml:id="formula_3">⊃ i φ ψ φ ⊃ ψ ⊃ e φ φ ⊃ ψ φ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¬φ ⊥ φ</head><p>Tertium non datur φ ∨ ¬φ Definition 2.4 A proof in natural deduction is the smallest set X such that the one element tree φ belongs to X for all well formed propositional formulas φ and if φ ∈ X, ψ ∈ X and χ ∈ X, then every application of the above defined natural deduction rules is ∈ X.</p><p>Definition 2.5 Logical formulas φ such that φ holds are called theorems.</p><p>Definition 2.6 Two formulas of propositional logic φ and ψ are called prov- ably equivalent iff φ ψ and ψ φ.</p><p>Proposition 2.7 The natural deduction calculus for propositional formulas is sound.</p><p>Proposition 2.8 The natural deduction calculus for propositional formulas is complete.</p><p>More information on natural deduction can be looked up in Huth and Ryan <ref type="bibr">[2004]</ref> and van Dalen <ref type="bibr">[2004]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sequent Calculus</head><p>The sequent calculus was originally developed by Gentzen, and published in one of his famous papers <ref type="bibr">[Gentzen, 1935]</ref>. Definition 2.9 A sequent is a pair (Γ, ∆) of finite multi-sets of propositional formulas.</p><p>It should be mentioned that some authors (like Fitting <ref type="bibr">[1990]</ref>) define a se- quent as a set of formulas, others as a sequence.</p><p>Instead of (Γ, ∆) the notation Γ → ∆ is common. Γ is called antecedent and ∆ succedent. For simplicity, propositional sequents {A 1 , . . . , A n } → {B 1 , . . . , B m } are denoted as A 1 , . . . , A n → B 1 , . . . , B m . Similarly, we write → ∆ and Γ → if Γ and ∆ is empty, respectively.</p><p>A valuation v makes a sequent A 1 , . . . , A n → B 1 , . . . , B m true iff</p><formula xml:id="formula_4">v |= (A 1 ∧ . . . ∧ A n ) ⊃ (B 1 ∨ . . . ∨ B m )</formula><p>Let Γ, ∆ be arbitrary propositional sequents and let A and B be propo- sitions. The rules in the Gentzen System are then as follows:</p><p>Disjunction Rules:</p><formula xml:id="formula_5">(∨-l) Γ, A ∆ Γ, B ∆ Γ, A ∨ B ∆ (∨-r) Γ ∆, A, B Γ ∆, A ∨ B</formula><p>Conjunction Rules:</p><formula xml:id="formula_6">(∧-l) Γ, A, B ∆ Γ, A ∧ B ∆ (∧-r) Γ ∆, A Γ ∆, B Γ ∆, A ∧ B</formula><p>Implication Rules:</p><formula xml:id="formula_7">(⊃-l) Γ ∆, A Γ, B ∆ Γ, A ⊃ B ∆ (⊃-r) Γ, A ∆, B Γ ∆, A ⊃ B</formula><p>Negation Rules:</p><formula xml:id="formula_8">(¬-l) Γ ∆, A Γ, ¬A ∆ (¬-r) Γ, A ∆ Γ ∆, ¬A</formula><p>Every rule consists of one or two upper sequents called premises, and one lower sequent called conclusion.</p><p>Definition 2.10 A sequent A 1 , . . . , A n → B 1 , . . . , B m is falsifiable iff there exists a valuation v such that</p><formula xml:id="formula_9">v |= (A 1 ∧ . . . ∧ A n ) ∧ (¬B 1 ∧ . . . ∧ ¬B m ). Definition 2.11 A sequent A 1 , . . . , A n → B 1 , . . . , B m is valid iff for every valuation v v |= (A 1 ∧ . . . ∧ A n ) ⊃ (B 1 ∨ . . . ∨ B m ).</formula><p>This is also denoted by</p><formula xml:id="formula_10">|= (A 1 , . . . , A n ) → (B 1 , . . . , B m ).</formula><p>Definition 2.12 An axiom is any sequent Γ → ∆ such that Γ and ∆ contain some common formula.</p><p>Proposition 2.13 Every axiom is valid.</p><p>A deduction tree is a tree whose nodes are labelled with sequents. Every sequent at an inner node must be obtained from the sequents at its children nodes by applying one of the rules of sequent calculus. The label on the root is the sequent that is proved. It is called the conclusion. A proof is a deduction tree that has only axioms as leaves. A counterexample is a sequent consisting only of propositional letters that is no axiom. A failed deduction tree is a deduction tree with a counterexample as one of its leaves. A sequent is provable iff there is a proof tree of which it is the conclusion. If a sequent Γ → ∆ is provable, it is denoted as</p><formula xml:id="formula_11">Γ → ∆.</formula><p>Proposition 2.14 The Gentzen calculus for formulas in propositional logic is sound. Thus, if a sequent Γ → ∆ is provable, then it is valid. Proposition 2.15 The Gentzen calculus for propositional formulas is com- plete. Thus, every valid sequent is provable. Furthermore there exists an algorithm for deciding whether a sequent is valid and if so, a proof tree is generated.</p><p>The interested reader may find additional material in Gallier <ref type="bibr">[2003]</ref> and Salzer <ref type="bibr">[2002]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Hoare Calculus</head><p>This calculus was introduced in Hoare <ref type="bibr">[1969]</ref>.</p><p>The input-output relation for a program S is specified as follows:</p><p>{P } S {Q}.</p><p>P and Q are logic formulas. In this context they are often called assertions or conditions. P is the precondition and Q is the postcondition. The precon- dition describes the set of intended initial states for the program S, whereas the postcondition describes the set of final states for S, if S terminates.</p><p>Definition 2.16 {P } S {Q} is partially correct if every terminating com- putation of S starting from a P -state ends up in a Q-state.</p><p>Definition 2.17 {P } S {Q} is called totally correct if every computation of S starting from a P -state terminates and ends up in a Q-state.</p><p>The Hoare calculus proves the correctness of programs with a syntax- driven axiomatic system. The Hoare System consists of the following axioms and rules:</p><p>Skip statement:</p><formula xml:id="formula_12">{P } skip {P } Assignment statement: {P t v } v ← t {P }</formula><p>where P t v describes the state P except that v has the value of t.</p><p>Composition rule:</p><formula xml:id="formula_13">{P } S 1 {R} {R} S 2 {Q} {P } S 1 ; S 2 {Q}</formula><p>Conditional rule:</p><formula xml:id="formula_14">{P ∧ B} S 1 {Q} {P ∧ ¬B} S 2 {Q} {P } if B then S 1 else S 2 {Q}</formula><p>Loop rule:</p><formula xml:id="formula_15">{P ∧ B} S {P } {P } while B do S {P ∧ ¬B}</formula><p>Consequence rule:</p><formula xml:id="formula_16">P ⊃ P 1 {P 1 } S {Q 1 } Q 1 ⊃ Q {P } S {Q}</formula><p>The rules presented so far are not enough to prove the termination of any program. This system is only able to prove partial correctness. In order to prove total correctness, it is necessary to adapt the loop rule:</p><p>Loop rule 2:</p><formula xml:id="formula_17">{P ∧ B} S {P } {P ∧ B ∧ (t = x)} S {t &lt; x} P ⊃ t ≥ 0 {P } while B do S {P ∧ ¬B}</formula><p>Notice that t is an integer expression and x is an integer variable that is not part of P , B, t or S.</p><p>Proposition 2.18 The Hoare calculus for the partial correctness of pro- grams is sound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 2.19</head><p>The Hoare calculus for the total correctness of programs is sound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 2.20</head><p>The Hoare calculus for the partial correctness of pro- grams is complete.</p><p>Further information can be found in Apt and Olderog <ref type="bibr">[1994]</ref> or Salzer <ref type="bibr">[2002]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Weakest Preconditions</head><p>Let S be a program statement and let Q be a predicate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.21</head><p>The weakest precondition wp(S, Q) is the set of initial states, described by a predicate, for which S terminates and Q is true on termination.</p><p>In contrast to the axiomatic Hoare logic the termination is inherent in the definition of pre-and postconditions.</p><p>Proposition 2.22 A program S is correct with respect to the predicates P and Q if P ⊃ wp(S, Q).</p><p>Weakest preconditions satisfy the following properties:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Axioms:</head><p>wp(S, false) = false P ⊃ Q wp(S, P ) ⊃ wp(S, Q) wp(S, P ∨ Q) wp(S, P ) ∨ wp(S, Q) wp(S, P ∧ Q) wp(S, P ) ∧ wp(S, Q) The weakest preconditions for typical program statements can be computed as follows:</p><p>Skip rule:</p><formula xml:id="formula_18">wp(skip, Q) = Q Assignment rule: wp(v ← t, Q) = Q t v</formula><p>Composition rule:</p><formula xml:id="formula_19">wp(S 1 ; S 2 , Q) = wp(S 1 , wp(S 2 , Q))</formula><p>Conditional rule:</p><formula xml:id="formula_20">wp(if B then S 1 else S 2 , Q) = (B ⊃ wp(S 1 , Q)) ∧ (¬B ⊃ wp(S 2 , Q)) = (B ∧ wp(S 1 , Q)) ∨ (¬B ∧ wp(S 2 , Q))</formula><p>Loop rule:</p><formula xml:id="formula_21">wp(while B do S, Q) = H(Q) = H 0 (Q) ∧ H 1 (Q) ∧ H 2 (Q) ∧ H 3 (Q) ∧ . . .</formula><p>where</p><formula xml:id="formula_22">H 0 (Q) = ¬B ⊃ Q H k+1 (Q) = B ⊃ wp(S, H k (q))</formula><p>For additional material consult Gannon et al. <ref type="bibr">[1993]</ref>, <ref type="bibr">Gries [1989]</ref> or Dijk- stra and Scholten <ref type="bibr">[1990]</ref>. For the advanced reader, Winkler <ref type="bibr">[1995]</ref> discusses the different views and implications of weakest precondition as a predicate transformer versus the idea of weakest precondition as a state set transformer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Selected Tools</head><p>This section introduces the reader to the tested tools in a theoretical fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>We evaluate the verification tools with respect to the following intended users:</p><p>Software engineers with a good knowledge of computer science but with- out specific training in formal methods</p><p>Students of computer science and software engineering in the mid- dle of their studies, being confronted with formal verification tools for the first time.</p><p>The four tools selected for this thesis are:</p><p>Frege Program Prover (FPP) FPP was chosen because of its academic nature. It was explicitly designed for teaching formal methods. It is also a candidate for being used in some lectures at the TU Vienna.</p><p>The tested version is available as web service, which was last updated on <ref type="bibr">May 22, 2001</ref>.</p><p>KeY System (KeY) KeY is the successor of the Karlsruhe integrated Ver- ifier (KiV). KiV has a long tradition and is well known in academia.</p><p>The KeY system is, at least concerning its intentions, one of the few systems comparable to FPP and PD.</p><p>The tested version is KeY-0.1342, the most recent internal version pro- vided by the KeY team.</p><p>Perfect Developer (PD) PD was already used for internships and courses at TU Vienna and claims to be one of the few existing commercial tools that can be used by almost any person with just a little knowledge of formal methods.</p><p>The tested version is Perfect Developer 2.00.</p><p>Prototype Verification System (PVS) PVS is famous and widely cited, and has served as a reference for many years. Therefore it is included in this comparison even though it aims mainly at verification of algo- rithms, not programs.</p><p>The tested version is PVS 3.2.</p><p>Further tools We list some other tools, which are of interest in the context of software verification, but which will not be discussed in detail.</p><p>Isabelle A more extensive overview and description on various tools can be found at the formal methods virtual library at http://vl.fmnet.info/#notations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head><p>In general there do not exist many comparisons in the style of this thesis. Special impact on this work had Griffioen and Huisman <ref type="bibr">[1998]</ref>.</p><p>They compare PVS and Isabelle by implementing some examples and inves- tigating the logics behind these tools. They come to the result that both tools are very powerful, but also have some weak points. They give advice on how to combine both tools to obtain even better proofs. Zolda <ref type="bibr">[2004]</ref> compares Isabelle and ACL2 and points out the different approaches. He comes to the conclusion that both tools have a lot of functionality but need a good background in logic. Freining et al. <ref type="bibr">[2002]</ref> compare FPP with NPPV and SPARK. NPPV and SPARK have advantages in special tasks, but FPP is the winner in the specified test environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Frege Program Prover</head><p>The Frege Program Prover, from now on called FPP, was developed at the University of Jena, Department of Mathematics and Computer Science, Pro- gramming Languages and Compilers.</p><p>Find an introduction to FPP at http://psc.informatik.uni-jena.de/ Fpp/fpp-intr.htm, whereas the system itself can be found at http://psc. informatik.uni-jena.de/FPP/FPP-main.htm.</p><p>FPP is an experimental system, implemented as a web application, for analysing the semantics of programs and for performing correctness proofs of annotated programs. FPP supports a subset of Ada -the concrete FPP syntax can be found at psc.informatik.uni-jena.de/Fpp/fpp-synt.htm. Identifiers are assumed to be integer or boolean variables.</p><p>FPP offers various capabilities:</p><p>Computation of the weakest precondition FPP computes the weakest precondition for a given program statement S in combination with a given postcondition Q. The internal mechanism is mainly based on the calculations of weakest preconditions as presented in section 2.5.</p><p>Check for the correctness of a program Given a precondition P , a pro- gram S and a postcondition Q, FPP checks whether the Hoare triple {P } S {Q} is consistent. Such a triple is called consistent, if the pro- gram S satisfies the conditions stated by the precondition P and the postcondition Q. Hence FPP checks consistency by testing</p><formula xml:id="formula_23">P ⊃ wp(S, Q)</formula><p>Theorem prover FPP can be used as a theorem prover by setting the pre- condition P to "true", the program S to "NULL" and the postcondition Q to the theorem that needs to be proved. The typical structure of such an FPP instance looks like:</p><p>--!Pre: true; NULL; --!Post: &lt;theorem to be proved&gt;;</p><p>It should be mentioned that this functionality is a logical consequence of the two previous capabilities. It is not considered to be competitive with other pure theorem provers.</p><p>For checking the correctness of a program, FPP needs to perform mathe- matical proofs. This is done with an extended version of Analytica (confer Clarke and Zhao <ref type="bibr">[1993]</ref>, <ref type="bibr" target="#b0">Bauer et al. [1998]</ref>). FPP does the translation be- tween the input program written in a subset of Ada into a representation that Analytica can handle. In the next step Analytica tests the Hoare triple on validity and returns the result. As Analytica is a main part of FPP for checking the correctness, it will be shortly presented.</p><p>Analytica Analytica is an automated theorem prover, originally intended for elementary analysis. It is written in the Mathematica programming lan- guage, which is based on term rewriting. In fact each step executed by Analytica is the application of a rewriting rule. Mathematica provides a rule-based programming language. Mathematica rules are of the form Pattern op Body with op being one of =, :=, -&gt; or :&gt;. The Pattern part describes a class of expressions, where a rule is applicable. The Body defines the expression to which the left side should be rewritten. Rules are either eager or lazy rules (depending on the op operator), specifying the details of the rewriting process. For details on this process look up a good book on term rewriting (e.g. Baader and Nipkow <ref type="bibr">[1998]</ref>).</p><p>Analytica works in four phases: Skolemisation, simplification, inference and rewriting.</p><p>Skolemisation ∃ quantifiers are replaced by ∀ quantifiers. Within this translation it is necessary to consider free and bound variables and to introduce new function symbols. This is necessary to guarantee that the original formula is only satisfiable iff the skolemised formula is satisfiable.</p><p>Simplification Simplification is considered the most important step in An- alytica. Simplification of a formula is executed in a so-called proof con- text. The proof context describes those formulas that may be assumed true during the simplification process. Analytica features various pow- erful rules to reduce the complexity of formulas.</p><p>Inference The inference phase is based on a sequent calculus as already presented in section 2.3. To Analytica rules have been added to provide easier handling, but the theoretic concept is the same.</p><p>Rewriting Rewriting implements those concepts presented above for Math- ematica. Various tactics are available.</p><p>For details see <ref type="bibr" target="#b0">Bauer et al. [1998]</ref>, <ref type="bibr">Winkler [1997]</ref> and Freining et al. <ref type="bibr">[2002]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">KeY System</head><p>The KeY system is developed and maintained by the Chalmers University of Technology, the University of Koblenz-Landau and the University of Karls- ruhe. The online address for this project is http://www.key-project.org/.</p><p>According to <ref type="bibr">Ahrendt et al. [2004]</ref>, KeY allows to write formal specifica- tions and to verify those specifications in the context of UML based software development. In detail the KeY tool consists of and uses:</p><p>Basis CASE tool KeY is an extension to UML CASE (Computer Aided Software Engineering) tools, mainly the commercial Together Control Center from the Borland Software Corporation. An integration in the Eclipse Java development environment is under construction.</p><p>OCL constraints OCL is short for Object Constraint Language (cf. OMG <ref type="bibr">[2003a]</ref>). It is used to specify constraints on objects in the Unified Modelling Language (UML). UML is in the meantime an accredited and recognised standard in object-oriented software development processes (cf. OMG <ref type="bibr">[2003b]</ref>). KeY uses OCL to define the formal specification.</p><p>KeY supports the user in creating and analysing OCL constraints and offers especially:</p><p>Creation of OCL constraints KeY is able to generate automati- cally constraints by using design pattern instantiations. For stan- dard formulations predefined instantiations of design pattern exist and can be easily used. On the other hand the user is free to for- mulate any valid OCL statement without assistance of KeY.</p><p>Formal analysis of OCL constraints Constraints on classes which affect other constraints are automatically recognised and their re- lations between each other are analysed irrespective of implemen- tation details.</p><p>Verification of implementations From the given OCL constraints KeY can prove whether an implementation satisfies obligations. This way KeY can verify programs. JavaCard The target language of KeY is JavaCard. JavaCard is a subset of the widely used Java programming language -both developed by Sun Microsystems -with some restrictions, tailored for applications with smart cards that need a secure environment. A description of the JavaCard language is described in Sun Microsystems <ref type="bibr">[2003]</ref> and is not given in this document as it is very similar to the well-known Java programming language.</p><p>Architecture KeY consists of various components ( <ref type="figure" target="#fig_0">Figure 1</ref>):</p><p>Modelling component As already mentioned, KeY allows the user to cre- ate, process and analyse OCL constraints. This component handles this task. The CASE tool is responsible for modelling and rendering UML elements, whereas KeY uses external tools to manipulate OCL constraints. In addition OCL specification templates are available in this component.</p><p>Verification middleware KeY internally uses a dynamic logic for Java- Card, which will be explained below. The verification middleware does now the translation of the OCL constraints, the JavaCard program code and the UML model in this JavaCard dynamic logic. This is then the input to the deduction component and hence connects the two layers modelling component and deduction component. Furthermore the proofs are managed and stored in this component.</p><p>Deduction component Based on the proof obligations resulting from the verification middleware, the deduction component tries to find proofs and discharge the proof obligations. The prover is interactive, but is designed to prove as much as possible automatically.</p><p>JavaCard Dynamic Logic Within KeY it is possible to specify precondi- tions, postconditions and class invariants. KeY allows now to check whether those assertions are valid after the execution of an implementation. The logic behind this procedure is a dynamic logic adapted for the JavaCard programming language. Dynamic logic can be seen as an extension to classical Hoare logic that was already introduced in section 2.4. As presented in Ahrendt et al. <ref type="bibr">[2004, p. 11 ff]</ref>, deduction in this dynamic logic uses symbolic program execution and program transformations.</p><p>The dynamic logic is built from non-dynamic standard logic with some modal logic extensions. For every program statement in JavaCard an equiva- lent statement in JavaCard dynamic logic can be found -KeY has an 100% JavaCard coverage.</p><p>Similarly dynamic logic statements can be found for OCL constraints, as the complexity of OCL is not as high as the complexity of the whole JavaCard programming language.</p><p>Once the proof obligations have been collected, and all OCL and Java- Card statements have been transformed into the JavaCard dynamic logic, a deductive calculus is used: This calculus uses techniques like those presented in section 2.3, and is kind of sequent-style calculus. All in all there are about 250 rules as a lot of constructs need to be considered. Some examples are:</p><p>Active statement rules As JavaCard allows different scopes and blocks, it is useful to restrict the computation to only those program statements that have some impact on the further program execution. Then these statements are called active.</p><p>Assignment and update rules The idea is the same as in classical Hoare logic, but object-oriented programming style adds some difficulties. Typically assignments on objects are not as trivial as some references might need to be considered. Special rules were introduced to manage this problem in an efficient way.</p><p>Exception rules JavaCard encourages the use of try-catch-finally and exceptions, which are no issues in standard sequent calculus. Again rules that deal with this issue were added.</p><p>Taclets KeY introduced the principle of taclets in theorem proving: "A taclet combines the logical content of a sequent calculus rule with pragmatic information that indicates when and for what it should be used." <ref type="bibr">[Ahrendt et al., 2004, p. 14]</ref>. Taclets are considered powerful enough for theorem proving in combination with a relatively simple and convenient way for the user to write them. An excellent excursion to the topic of taclets can be found in Beckert et al. <ref type="bibr">[2004]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Perfect Developer</head><p>The Perfect Developer system, abbreviated PD, was designed and developed at Escher Technologies Ltd. in England. The main online reference is http: //www.eschertech.com/products/index.php. PD claims to be a tool for developing software systems that can be verified automatically. As a result a typical development process with PD should incorporate various phases:</p><p>• The user starts with a formal definition of functional requirements, where typical definitions deal with safety properties and expected be- haviours.</p><p>• Based upon this a formal model can be elaborated. Diagrams in the Unified Modelling Language (UML) are supported. This allows the user to specify behaviour in a standardised way, enabling broader use and common understanding. Abstract data and abstract operations are defined, non-determinism is reduced to its minimum. Many times this leads to executable models in a very early development phase of the standard software engineering process.</p><p>• The formal model from the previous phase can now be checked against requirements. The requirements can be stated easily in form of precon- ditions, postconditions, invariants and other assertions within PD.</p><p>• Once the model has been built to encompass all necessary require- ments, the next step is to refine the model to an implementation. PD can generate code directly from the specification. Another way is to specify a separate implementation that is checked against the model. The implementation includes concrete data structures and executable statements of varying complexity.</p><p>• After passing the previous steps the result is a model and an implemen- tation. Verification of the model against the implementation reveals either errors, incomplete and inaccurate specifications or guarantees valid program code.</p><p>• As a final step code for target platforms can be generated. There are C++, Java and Ada available. This allows the code to be used on virtually any important operating system or hardware platform.</p><p>The PD Language Perfect Developer uses a strongly typed specification and implementation language, offering manifold constructs to the user.</p><p>Standard types like bool, byte, char, int, real, string, . . .</p><p>User defined enumerations An enumeration is defined as a collection of values with an ordering relation. In fact an enumeration is a class in PD, with operators for finding the lowest, the highest values, predeces- sor and successors.</p><p>User defined classes Object-oriented principles are implemented in a rig- orous way: From abstract to final classes, single inheritance, polymor- phism and dynamic binding are supported.</p><p>Class templates PD offers six structures for different well defined uses: sets, bags (multi-sets), sequences, pairs, triples and mappings. Map- pings define a relation between elements from the input domain to the output range. Typical applications are lookup tables or relational data- bases. Numerous operations on these structures are built-in, as well as rich theories for proving assertions about them.</p><p>Unions PD allows to combine types to build others. The standard exam- ple are strings, which are just character sequences in the PD language.</p><p>Another example are lists of some type in combination with void rep- resenting the end of the list or the null value in other programming languages.</p><p>Operator and function overloading As PD supports template mecha- nisms, PD can easily build distinct signatures for overloading oper- ator or function symbols. This ensures type safety with user-friendly naming conventions.</p><p>Partial functions Within the typed logic partial functions with equality or arithmetic behaviour are possible. Functions are either interpreted, possibly-interpreted or uninterpreted.</p><p>Expressions Within PD a lot of expressions exist: Quantified expressions, type widening expressions, type enquiry expressions, heap expressions, conversion expressions, scope resolution and ? as a shorthand for not yet specified behaviour. For details see Crocker <ref type="bibr">[2001, chapter 5.4]</ref>.</p><p>The PD Prover With the ongoing development of Perfect Developer the internal mechanisms were upgraded. At the beginning PD was influenced by approaches of Floyd and Hoare and the calculation of weakest preconditions (see sections 2.4 and 2.5).</p><p>Based on this approach a sequent calculus prover system was introduced. A further improvement was the use of a Rasiowa-Sikorsky deduction system. The main inference rules are:</p><p>Primary prover inference rules Those rules unify terms, expand func- tions or create meta-variables. In addition there exist manifold rules for standard connectives of the PD first order logic.</p><p>Term creation rules like transitivity rules are subject to this topic.</p><p>Hard-coded rewrite rules</p><p>Other rewrite rules</p><p>The next version of PD already used a resolution procedure and paramod- ulation with intense help of the built-in term rewriter component. The term rewriter is made up of two sets of rules:</p><p>Hard-coded rules Rules that are frequently used belong to this group or rules that simply cannot be parameterised.</p><p>Parameterised rewrite rules The larger set of rules is part of this group. The spectrum varies from rules with different operands to rules with preconditions.</p><p>The language of PD has the power of first order predicate calculus with some additional higher-order constructs. The prover is basically able to prove classical two-valued logic, what implies that higher-order logic statements are transformed first. Additional rules are necessary for object-oriented features, like polymorphism or dynamic binding.</p><p>Perfect Developer is also strongly influenced by the Verified Design-By- Contract principle:</p><p>Verified Design-By-Contract The Verified Design-By-Contract idea is build upon the principle of Design-By-Contract. Design-By-Contract can be characterised as a system of preconditions and postconditions that have to hold for a given program. The implementations differ regarding the degree of formalisation:</p><p>Comments Comments state conditions in the source code. The problem is that these conditions cannot be automatically checked as they are just comments to the compiler.</p><p>Annotations with run-time checks Special statements in the program- ming language generate code that does not influence the effect of the program but check invariant conditions during run-time. This allows the user to find errors in the testing phase.</p><p>Annotations with static analysis It would be optimal if the compiler (or prover) could check the conditions before the program is even executed. But for common programming languages this is almost impossible due to:</p><p>• Heavy use of pointers and complex data structures for relatively simple data</p><p>• Most languages were simply not designed for verification</p><p>• Standard programming languages lack powerful statements to ex- press useful verification conditions</p><p>Verified Design-By-Contract addresses these problems: In Perfect Developer it is possible to construct specifications that consist of preconditions, post- conditions, invariants and further annotations. The Perfect language is pow- erful enough to write expressive conditions (∀ and ∃ constructs exist within Perfect) such that the behaviour of a program can be exactly defined. As a result code should just serve as an implementation to the specifica- tion. Often it is not even necessary to provide code because PD can construct executable code from the single specification. This ensures maximum consis- tency between code and its behaviour described in the specification.</p><p>A more detailed explanation of (Verified) Design-By-Contract can be looked up in <ref type="bibr">Crocker [2004b]</ref>, <ref type="bibr">Crocker [2004a]</ref>, <ref type="bibr">Crocker [2003b]</ref> and Crocker <ref type="bibr">[2003a]</ref>. They discuss the topics presented here in a far more detailed way and should be consulted for deeper insight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">PVS Specification and Verification System</head><p>The Prototype Verification System PVS was developed at the Stanford Re- search Institute. The main project address is http://pvs.csl.sri.com/.</p><p>PVS is a prototype system for writing specifications and constructing proofs. PVS offers an expressive high-order logic in combination with semi- automatic proving. Hence user interaction is often necessary. PVS appears to the user as an extension to the common "Emacs" editor. The main com- ponents are: Exploratory phase The main objective is to provide meaningful out- put to the user in order to support the user in finding errors or improving the specification.</p><p>Development phase Once the specification is fixed the proof goes into some more details. Very important is the efficiency of the proof development.</p><p>Presentation phase The proof is prepared to be presented to the user. This requires the system to produce good and meaningful explanations to the user.</p><p>Generalisation phase Once the proof is finished, the next aim is to weaken its precondition. This might strengthen the proof by providing a more general statement.</p><p>Maintenance phase Maintenance is an extension to the idea of gen- eralisation. This implies for the proof that its precondition may change. Therefore it might be necessary to redo parts of the proof to adapt to the new situation.</p><p>The PVS Language The lexical structure of the PVS language can be found in <ref type="bibr">[Owre et al., 2001a, p. 7]</ref>. In addition the PVS Specification Lan- guage offers numerous powerful features:</p><p>Type declarations Available are uninterpreted, interpreted and enumer- ated types and subtypes.</p><p>Variable declarations PVS interprets variables as logical variables, not as program variables. As a result it is possible to use binding expressions such as FORALL, EXISTS or LAMBDA.</p><p>Constant declarations As PVS supports high-order logic the term con- stant applies to any n-ary function. Normal constants can be seen as 0-ary functions. As in type declarations, constants can be uninterpreted or interpreted.</p><p>Recursive definitions Recursive definitions are allowed in PVS, but it is necessary to give PVS information on termination. The user has to define a MEASURE function that decreases strictly on recursive calls.</p><p>Macros Macros are available for convenience use. Formula Declarations Formulas are very important in PVS. Formulas can either be axioms, assumptions, lemmas, theorems or obligations (and many more). With them it is possible to describe the behaviour of programs in the specification.</p><p>Conversions Conversions are inserted automatically by the type-checker subcomponent, as soon it appears to be necessary.</p><p>Types PVS offers complex types, subtypes, function types, tuple types, record types and dependent types.  <ref type="bibr">[1999]</ref>.</p><p>• Boolean Expressions</p><p>• IF-THEN-ELSE Expressions</p><p>• Numeric Expressions</p><p>• Applications Function applications as defined in mathematics.</p><p>•</p><note type="other">Binding Expressions The main binding expressions are λ and quantifiers. • LET and WHERE Expressions • Set Expressions • Tuple Expressions • Projection Expressions • Record Expressions • Record Accessors • Override Expressions • Coercion Expressions Furthermore a lot of expressions are possible (especially tables and abstract data types). Again the interested reader may refer Owre et al. [2001a].</note><p>Theories Specifications in PVS are built from theories, that may be para- meterised. The reason for theories was to provide maximal modularity and code-reusability. The Logic of PVS The rules presented here are the theoretical back- ground for the prover. Those rules are implemented in an efficient way but the idea works in the same way as presented here: PVS internals heavily use sequent calculus. For propositional logic a short outline was given in section 2.3. The notation introduced in section 2.3 conforms with the notation used for PVS high-order logic sequent calculus.</p><p>The main connectives that PVS provides and hence need to be considered are:</p><formula xml:id="formula_24">¬ NOT ∧ AND &amp; ∨ OR ⊃ IMPLIES =&gt; ⇐⇒ IFF &lt;=&gt; ∀ FORALL ∃ EXISTS λ LAMBDA</formula><p>All rules presented in section 2.3 are basis for the sequent calculus in PVS. Furthermore there are:</p><p>Equality Rules:</p><formula xml:id="formula_25">if a ≡ b Γ a = b, ∆ a = b, Γ[b] ∆[b] a = b, Γ[a] ∆[a]</formula><p>with Γ[e] denoting one or more occurrences of e in Γ.</p><p>Quantifier Rules:</p><formula xml:id="formula_26">Γ, A t ∆ (∀-l) x Γ, (∀x : A) ∆ Γ A a , ∆ (∀-r) x Γ (∀x : A), ∆ Γ, A a ∆ (∃-l) x Γ, (∃x : A) ∆ Γ A t , ∆ (∃-r) x Γ (∃x : A), ∆</formula><p>with A t x means that in A all free occurrences of x are substituted by a term t (with possible renaming of bound variables). This way it is guaranteed that no free variables in t are captured, what is necessary for a correct high-order calculus. a has to be a new constant.</p><p>Conditional Rules:  <ref type="bibr">[1992]</ref> give a good introduction into PVS, whereas some applications of PVS may be found in Owre et al. <ref type="bibr">[1998]</ref>.</p><formula xml:id="formula_27">Γ, IF (A, B[b], B[c]) ∆ Γ, B[IF (A, b, c)] ∆ Γ IF (A, B[b], B[c]), ∆ Γ B[IF (A, b, c)], ∆ Γ, A, B ∆ Γ, ¬A, C ∆ Γ, IF (A, B, C) ∆ Γ, A B, ∆ Γ, ¬A C∆ Γ IF (A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Examples</head><p>In this section the four chosen tools FPP, KeY, PD and PVS are tested with examples that need to be verified. At first the criteria are defined to build a common evaluation platform. Second, the systems are evaluated according to this criteria. Third, the examples are presented and, finally, the result of the verification process of each tool is discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Criteria</head><p>Criteria define the specific context and environment for practical tests. Thus it is relevant to specify them in a detailed way in order to provide a repro- ducible test scenario.</p><p>Tests of verification tools often end up in a single final result. All invested work is aggregated to the completion of a selected case study. During the evaluation of the criteria for this work, the decision to incorporate the whole process -from the problem formulation to the final proof -was taken. In fact this is similar to the idea mentioned in Bundy <ref type="bibr">[2004]</ref>.</p><p>As already mentioned in section 3.1 on page 17 our target groups are:</p><p>Software engineers with a good knowledge of computer science but with- out specific training in formal methods</p><p>Students of computer science and software engineering in the mid- dle of their studies, being confronted with formal verification tools for the first time.</p><p>Criteria were chosen to test the capabilities in context for this target groups. The criteria are divided up into two categories:</p><p>Program related criteria This set of criteria is applicable for the whole verification tool and not restricted to specific examples. The defined criteria are as follows:</p><p>Commercial or academic nature Gives some background on the tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supported platforms and portability</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Installation</head><p>General support</p><p>Code generation Assuming a verified specification, how easy is it to generate code? Automatic generation avoids introducing errors due to an error-prone manual translation.</p><p>Learning curve How long does it take to work with this tool in an efficient way? Does the system support the user in learning a successful process of verification?</p><p>Problem related criteria These criteria make more sense to be looked at in a context for a specific problem.</p><p>Ease of problem formulation Here is discussed, whether the prob- lem can be formulated in a natural and short way. Complex prob- lem formulations are the first step for the introduction of errors and need to be avoided as far as possible.</p><p>Complexity of user interaction Does the system prove programs automatically? How often is it necessary to give hints to the prover or adapt the specification? How difficult is it to adapt the specification?</p><p>Degree of coverage Is it possible to prove a correct specification un- der all conditions?</p><p>Support in finding errors During the development process no user starts with a perfect specification. To which extent the system can help the user in finding problems or invalid specifications is relevant at this point.</p><p>It should be clear that some criteria are interchangeable within both cate- gories under different test scenarios. In fact, the result of this test should encompass all criteria, and should lead to more insight in the specific advan- tages and disadvantages of each tool. The criteria are deliberately neither rated nor weighted, as the impact of the various criteria differ too much under different scenarios. The plan is to give a comprehensive idea of how these tools work and which purpose they fulfil, not a ranking with winners and underdogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Methodology</head><p>The selected tools are tested with relatively easy and short standard com- puter science problems. This way it should be possible to implement different algorithms for most systems without having too much difficulties. This en- ables the reader to compare the systems in a practical environment, as the reader can follow various implementations for the same problem.</p><p>The problems handle topics of the following fields of interest:</p><p>Elementary number theory Factorial, Fibonacci numbers, sum, prime numbers, iterative multiplication and division</p><p>Array problems Inversions, Quicksort, List maximum</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weakest preconditions</head><p>It should be especially mentioned that some test scenarios or examples were taken in the style of already published papers: Some FPP examples are very similar to the examples presented in Freining et al. <ref type="bibr">[2002]</ref>, whereas the quicksort example for PVS was taken from Griffioen and Huisman <ref type="bibr">[1998]</ref>, as it shows the capabilities for PVS very well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Frege Program Prover</head><p>An introduction to FPP and some theoretical background was given in sec- tion 3.2. As supposed in the foreword on the criteria in this section, program related criteria are discussed: Commercial or academic nature FPP is an academic tool tailored for teaching purposes. FPP is still under development and future versions are announced to support more features and to offer more powerful provers.</p><p>Supported platforms and portability FPP is a web service. So porta- bility and platforms are no point, virtually any device with a web browser is supported by FPP.</p><p>Installation Installation is not needed, making it very convenient for the user.</p><p>General support The team around FPP offered a lot of help. For any problems qualified solutions were found in short time via email, and the FPP team provided help in obtaining specific literature and academic articles on FPP.</p><p>Code generation As FPP supports a subset of Ada natively, no translation is necessary. Assertions are just comments, so a Ada compiler can generate code without further modifications.</p><p>Learning curve As FPP is considered as an academic teaching tool, the learning process should be clear and fast. And in fact FPP is quite easy to learn. With the examples on the FPP homepage and the simple syntax, the user is able to understand and write programs after a very short time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Cubic sum</head><p>Compute the sum of cubed numbers. and obvious manner. The assertions can be specified in an exact math- ematical style, the termination function and invariants were not hard to guess.</p><p>Complexity of user interaction During the first attempts not everything could be proved automatically. It was necessary to refine the specifica- tion and to restrict the variable ranges. With a rigorous specification we achieved complete automatic verification.</p><p>Degree of coverage A total coverage was possible. This FPP program is asserted to stop in finite time and to be correct.</p><p>Support in finding errors As one can see from the quite clear prover out- put, it is traceable to find specification problems. The process of veri- fication with induction is clear and reproducible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Division</head><p>Calculate the quotient and remainder of a division for a given dividend and divisor. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation The problem can be formulated in a so- phisticated way, but it is inevitable to specify the variable ranges (e.g. that dividend &gt;= 0, . . . ) exactly. The only difficulty is finding a termination function that helps FPP in the verification process.</p><p>Complexity of user interaction The proof is done automatically, no ad- justments were necessary in advance except slight modifications con- cerning nonnegative variable ranges.</p><p>Degree of coverage FPP can prove that this program fragment is correct.</p><p>Support in finding errors The first attempt for this program lacked the condition, that divisor &gt; 0. It was not obvious from the output of FPP what was the exact problem. It took some time to identify the problematic part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Factorial</head><p>Compute the factorial for a given number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program code</head><p>--!pre: n &gt;= 0; product := 1; --!pre: product = 1 AND n &gt;= 0; --!post: product = factorial(n); --!inv: product = factorial(i); FOR i IN 1..n LOOP product := product * i; END LOOP;</p><p>Prover output --!pre : (n &gt;= 0) --&gt; wp : (n &gt;= 0) --&gt; vc : (True) --&gt; Result: proved product := 1; --!pre : (product = 1 AND n &gt;= 0) --!post : (product = Factorial(n)) --!inv : (product = Factorial(i)) --&gt;functionality --------------------------- --&gt;func : (initial AND induction AND final AND null loop) --&gt;initial :(1 &lt;= n AND product = 1 AND --&gt; n &gt;= 0 =&gt; product = 1) --&gt; Result : proved --&gt;induction :(1 &lt;= n AND product = Factorial(-1 + i) =&gt; --&gt; i*product = Factorial(i)) --&gt; Result : proved --&gt;final :(1 &lt;= n AND product = Factorial(n) =&gt; --&gt; product = Factorial(n)) --&gt; Result : proved --&gt;null loop :(1 &gt;= 1 + n AND product = 1 AND --&gt; n &gt;= 0 =&gt; product = Factorial(n)) --&gt; Result : proved FOR i IN 1 .. n LOOP product := product * i;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>END LOOP;</head><p>Analysis Ease of problem formulation Very natural formulation. For the asser- tions FPP supports the predefined function factorial, making it triv- ial to write invariants and postconditions.</p><p>Complexity of user interaction No user interaction was necessary.</p><p>Degree of coverage FPP could prove 100% on the first attempt.</p><p>Support in finding errors The prover output is short and obvious. Errors were not found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Fibonacci numbers</head><p>Compute the n-th Fibonacci number. Complexity of user interaction It was necessary to refine the specifica- tion and to tighten variable ranges. Then FPP could prove the correct- ness.</p><p>Degree of coverage After those slight modifications a total coverage was reached.</p><p>Support in finding errors Although the program code is very short, the prover output is already quite long. Nevertheless the output does not offer deep insights into problematic issues for FPP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.5">Inconsistency test</head><p>The idea is to test the prover component with inconsistent input programs and look at its reaction and output. Complexity of user interaction No user interaction. The main point is to look at the prover output when FPP encounters inconsistent program code.</p><p>Degree of coverage Obviously this code cannot be verified.</p><p>Support in finding errors The prover output is very complex and unman- ageable. FPP does not really make clear what the problems is, there is too much output on for the first moment irrelevant conditions. Of course the example was chosen this way to add complexity to the trivial example, but FPP has shown that it cannot produce good output on tricky input. In the examples before the output was often quite rea- sonable. Especially bigger programs with not so exact specifications appear often to a typical software engineer in his daily development process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.6">Multiplication</head><p>Multiply two integer numbers. Complexity of user interaction The constraints for the variables needed some further work, but could be added in short time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Degree of coverage Total coverage after slight modifications.</head><p>Support in finding errors It was immediately clear that FPP needed con- straints on the variables. The output again tends to get longish with those constraints. But all in all this example was no challenge for FPP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.7">False theorem test</head><p>Test FPP's internal prover component with a simple invalid theorem. Ease of problem formulation Theorems can be stated very easily in FPP. The statement block is just NULL and the theorem to be tested is stated as a postcondition.</p><p>Complexity of user interaction Theorems can be proved or discharged completely automatically.</p><p>Degree of coverage Obviously 0%, as the input is an invalid theorem.</p><p>Support in finding errors The explanation is good and specifies a counter example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.8">Correct theorem test</head><p>Test FPP's internal prover component with a small valid theorem. Complexity of user interaction No user interaction necessary.</p><p>Degree of coverage The valid theorem is totally proved by the prover com- ponent.</p><p>Support in finding errors Specification errors leading to invalid formulas result in instructive counter examples (cf. previous example).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.9">Conditional weakest precondition</head><p>Test FPP's ability to compute weakest preconditions. Complexity of user interaction Weakest preconditions can be computed fully automatically by FPP, as long as loops are avoided.</p><p>Degree of coverage The system finds the weakest precondition. However, its inability to simplify expressions disguises the fact that the formula is equivalent to TRUE.</p><p>Support in finding errors Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">KeY System</head><p>KeY was already introduced in section 3.3. At this point KeY is analysed with examples and its practical nature is discussed: General support The KeY team offered excellent support. As the tested version of KeY was still in alpha stage, help was quite often required, as some subcomponents were not implemented or did not work without modifications. At each point the KeY team gave support and did a great job in helping with verifying the examples. The support was a highlight in the work with KeY.</p><formula xml:id="formula_28">Commercial</formula><p>Code generation As the code is written in JavaCard, a standard Java com- piler can build code. This avoids manual error-prone translation, mak- ing the whole process more secure.</p><p>Learning curve The familiarity with the widely used Java language prob- ably helps many users in working with KeY. OCL constraints are rel- atively simple and can be learnt in a short time. A problem was the lack of documentation -but this is acceptable if a tool is still officially considered in alpha stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Cubic sum</head><p>Compute the sum of cubed numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program code</head><p>public class CubicSum { /** * @preconditions n &gt;= 0 * @postconditions 4 * result = n*n * (n+1)*(n+1) */ public static int cubicSum(int n) { int i = 0; int result = 0;</p><formula xml:id="formula_29">while (i &lt; n) { i++; result += i*i*i; } return result; } }</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation The problem can be formulated very easily in a procedural style in the Java syntax. The pre-and postconditions can also be stated in a clear manner according to the syntax of OCL constraints. A problem was that OCL does not support real numbers, which led at first to an exception. It was necessary to bring the factor 4 to the left side in the @postconditions otherwise the result would be typed as real according to KeY. But in fact this can never happen due to the internal structure of the formula.</p><p>Complexity of user interaction The amount of user interaction is unfor- tunately very high. The induction rules for the while construct are complex and tricky. Only with a lot of tricks from the KeY team we could reproduce the whole proof. Without such help it is really hard, what makes the life not easier for a standard software engineer.</p><p>Degree of coverage After a lot of tricks and with a lot of knowledge from the user KeY could verify the correctness of this program.</p><p>Support in finding errors As good the general support from the KeY team was, as intricate we found the reports and output from KeY. The integration of the KeY prover within the Together CC CASE tool and the fact that the prover has a graphical user interface are for sure good ideas, but the realisation was very confusing. It is hard enough to prove a correct program -finding errors from that is even harder with no special knowledge on the internals of the KeY prover.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Conditional</head><p>This example tests KeY on simple conditional statements. Especially the complexity of proofs for very simple programs is here an issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program code</head><p>public class If { /** * @preconditions y &gt; 1 * @postconditions x &gt; y */ public static void ifTest(int x, int y) { x = 3; if ((x + y) &lt; 19) x += 19; else x = y + y; } } Prover output Only a short excerpt from the complete prover output is presented here. In fact it is intended to show the user the complexity for such a short example. Hence for all other tested KeY examples the prover output is left out here and the interested user is advised to consult the external package with all examples and their solutions.</p><p>(branch "dummy ID" (rule "imp_right" (formula "1")) (rule "method_body_expand" (formula "2")) (rule "greater" (formula "1")) (rule "greater" (formula "2") (term "0")) (rule "assignment_allnormalass" (formula "2")) (rule "assignment_allnormalass" (formula "3") (term "4")) (rule "method_call_empty" (formula "3") (term "2")) (rule "empty_modality" (formula "3") (term "2")) )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation The problem formulation is very natural, almost trivial. Anyone starting with programming should be able to come up with this formulation.</p><p>Complexity of user interaction The complexity was considerable high, although the input program is definitely one of the easiest one can imagine. The prover output gives a first hint on the complexity of this job.</p><p>Degree of coverage In the end the correctness of this program could be proven.</p><p>Support in finding errors With a lot of knowledge it might be possible to find errors from the prover output directly, for most users it is a non trivial job. A support in its proper sense is not available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Division</head><p>Calculate the quotient and remainder of a division for a given dividend and divisor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program code</head><p>public class Division { /** * @preconditions rem &gt; 0 and divisor &gt; 0 * @postconditions rem@pre = rem + result * divisor and rem &lt; divisor */ public static int divide(int rem, int divisor) { int quot = 0; while (rem &gt;= divisor) { rem -= divisor; quot++; } return quot; } }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation The executable program part is written in a natural procedural style. The only thing that needed special consid- erations were the OCL constraints, especially that some variables need a restricted variable range. Nevertheless KeY offers here good help with the graphical OCL constraint builder.</p><p>Complexity of user interaction The proof is very complex, especially the induction is presented by KeY in a very technical way. Without the hints and the help of the encouraging KeY team the proof is hard to follow.</p><p>Degree of coverage The program could be proven after longish consider- ations on how to proceed.</p><p>Support in finding errors Due to the complexity of the whole verification process an extra support in finding errors is not available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4">Factorial</head><p>The factorial for a given number shall be computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program code</head><p>public class Fac { /** * @preconditions n &gt;= 0 * @postconditions result &gt; 0 */ public static int fac(int n) { if (n == 0) return 1; else return (n * fac(n -1)); } } Ease of problem formulation The recursive definition of the fac function is very intuitive and fully supported by JavaCard. The OCL constraints are very limited as they deny the use of function calls. On the one hand this keeps constraints short and clear, on the other hand powerful constraints are hard to write in this restricted formalism.</p><p>Complexity of user interaction The recursive definition makes it hard to get an idea on how to start with the verification process. A disad- vantage is that the automatic proving strategies of KeY often do not really simplify the proving process. The required user interaction is relatively high.</p><p>Degree of coverage In the end the claim that the result is always positive could be verified.</p><p>Support in finding errors Once again, the proving process is quite com- plex, making it difficult to find errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.5">List maximum</head><p>Find the maximum from a list of numbers. the natural formulation due to the use of JavaCard. For any Java programmer the program is no challenge. The OCL constraints are not difficult either, but on the first attempt the OCL constraints were unintentionally written in a wrong syntax. The OCL parser accepted OCL constraints, but the prover could not handle them.</p><p>Complexity of user interaction Unfortunately the program could not be verified completely automatically, although the preconditions and post- conditions are very simple.</p><p>Degree of coverage The postcondition could be proved under the assump- tion of the preconditions and the program statements.</p><p>Support in finding errors Due to the complex proving process it is hard to find any errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.6">Multiplication</head><p>Multiply two integer numbers. Complexity of user interaction User interaction is necessary, again an involved induction proof for non-KeY experts.</p><p>Degree of coverage The whole program could be verified.</p><p>Support in finding errors None.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.7">Prime</head><p>Test whether a nonnegative number is prime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program code</head><p>public class Prime { /** * @preconditions n &gt;= 0 * @postconditions n &gt;= 0 */ public static boolean isPrime(int n) { if (n &lt; 2) return false; for (int i=2; i &lt; n; i++) { if ((n % i) != 0) return false; } return true; } }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation This program is somehow tricky: the pro- gram formulation is natural, but there were problems in specifying useful properties for prime numbers in the OCL formalism. Hence in the end the conditions were chosen as easy as possible. But this does not make it easier to prove the obligations, as the conditions do not correlate with the program.</p><p>Complexity of user interaction The complexity is very high, making the proving process very complicated.</p><p>Degree of coverage In spite of the simple conditions the program could not be fully verified.</p><p>Support in finding errors KeY did not help in finding errors in this con- text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Perfect Developer</head><p>Some theoretical background on Perfect Developer was given in section 3.4, whereas the focus is here on its practical usage:</p><p>Commercial or academic nature PD is a commercial tool with special conditions for academic institutions.</p><p>Supported platforms and portability The development environment of PD and the Perfect compiler and verifier kit run under Windows and Linux. The generated code of PD is either Ada, C++ or Java and hence runs on any supported platform for these programming languages.</p><p>Installation The installation process is clear and well documented. On the officially supported platforms standard installation mechanisms pre- pare the system in order to start working immediately with PD. For Windows and certain recent Linux distributions the installation is au- tomatic and is finished within minutes. For other Linux distributions some additional work may be necessary. PD, in particular the graphi- cal user interface, relies on very recent versions of some libraries, which for instance are not available in the stable release of Debian Linux (woody) by default. Backporting and recompiling the libraries solves the problem.</p><p>General support Escher Technologies, the producer of PD, runs a mailing list, where questions of any nature were answered often within one or two days. The support is fast and competent.</p><p>Code generation The standard target languages of the automatic trans- lation of the Perfect language are C++ and Java. So virtually any deployed operating system has support for at least one of these lan- guages. So portability issues are not worth being further discussed.</p><p>Learning curve PD offers a lot of features, that take time to learn. For programmers not familiar with declarative or functional programming it might be a challenge to formulate programs in a non procedural way.</p><p>Once the user has internalised the language structure the user is able to express specifications and programs in a concise and natural way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Cubic sum</head><p>Compute the sum of cubed numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program code</head><p>function cubicSum(n: nat): nat decrease n ^= (</p><formula xml:id="formula_30">[n = 0]: 0, []:</formula><p>n^3 + cubicSum(n -1) ) assert result = (n^2 * (n + 1)^2 / 4);</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation The problem can be easily formulated in a recursive style, which is fully supported by PD. The assertions are also clear.</p><p>Complexity of user interaction No user interaction during the proof is possible.</p><p>Degree of coverage Almost all obligations could be discharged. Type con- straint restrictions could not be proven in this formulation -PD could not show that n^3 + cubicSum(n -1) in combination with the asser- tion is of type nat.</p><p>Support in finding errors PD gives useful hints what seems to be the problem. Of course the user has to look carefully on this part but at least the user has some clue about PD problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Factorial</head><p>Compute the factorial for a given number. Analysis Ease of problem formulation PD supports an implementation part, as used in this example. The declarative formulation describes the behav- iour, whereas the implementation part describes, how the computation shall be done. PD ensures that both parts fit together and verifies them against each other.</p><p>Complexity of user interaction No user interaction was necessary, the program was verified fully automatically.</p><p>Degree of coverage PD could prove the total correctness of this program formulation.</p><p>Support in finding errors The prover output for this program is very long (about 20 pages), but PD generates a separate file if it encounters problems. With some hints of PD the user has good chances to find the source of errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">Intersection</head><p>Count how many elements from the first list also occur in the second one. Both lists have to be sorted. Analysis Ease of problem formulation The declarative part was easy to formulate and written within minutes. The implementation is longish and was difficult to formulate.</p><p>Complexity of user interaction The implementation part was tricky to write and is error prone. Only after a lot of reformulations the number of non verifiable obligations could be reduced. PD still could not prove the invariant of this program.</p><p>Degree of coverage Due to the complex implementation part PD could not verify the whole program. Without the separate implementation part PD could verify the whole program and was still able to produce executable code. So the implementation with its improved performance behaviour leads to not verifiable program fragments for PD.</p><p>Support in finding errors PD gives good hints on errors or problematic formulations in the declarative part, but fails to give such good reports for the implementation part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.4">Inversions</head><p>Compute the number of inversions within a sequence of numbers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation The formulation is tricky and needs intri- cate operators to obtain the correct return type. Nevertheless the for- mulation is very short and compact.</p><p>Complexity of user interaction No modifications were necessary. The proving process by PD is done without any user interaction.</p><p>Degree of coverage All obligations can be discharged except the assertion result &lt; (#A)^2. The proof requires induction, which is not sup- ported by PD.</p><p>Support in finding errors As one can see from the prover output above, PD shows what the problem is in verifying this program, but gives no hint on how to solve it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.5">List maximum</head><p>Find the maximum from a list of numbers. Complexity of user interaction No extra user interaction was necessary.</p><p>Degree of coverage Everything except the final assertion can be proved. The final assertion requires induction, which is not supported by PD.</p><p>Support in finding errors PD signals that it cannot prove the final asser- tion, but gives no help how to solve this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.6">Multiplication</head><p>Multiply two integer numbers. Support in finding errors The output is clear and short for the trivial example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.7">Prime</head><p>Tests whether a nonnegative number is prime. factors(n) = seq of int{} ) assert (result | (n &lt; 2)) = (forall i::2..(n-1) :- (n % i) ~= 0);</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation PD allows to write down the mathemati- cal properties for primes in a very intuitive way. This minimises the probability of introducing intricate errors already in the design phase.</p><p>Complexity of user interaction No fine tuning is necessary. The prover works automatically.</p><p>Degree of coverage All properties could be verified.</p><p>Support in finding errors On the first attempt the assertion was specified in the wrong way. The user could see immediately that PD could not verify the final assertion. Complexity of user interaction No additional help needs to be given to the PD prover.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.8">Quicksort</head><p>Degree of coverage PD could not show that this Quicksort formulation yields the same properties as the built-in isndec property, since it requires induction.</p><p>Support in finding errors No support necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">PVS Specification and Verification System</head><p>PVS was already presented in section 3.5. Its characteristics are:</p><p>Commercial or academic nature PVS is of academic nature, with some commercial additions. The tool can be freely downloaded and used by any end user.</p><p>Supported platforms and portability Supported platforms are only So- laris and Intel Linux platforms. PVS uses heavily Emacs and LISP. Theoretically it is possible to port the application, but so far this has not been done.</p><p>Installation The installation is straightforward. It suffices to copy the whole build into a directory and call a small script to relocate rele- vant links. On a standard Linux system PVS finds immediately Emacs and necessary libraries without problems.</p><p>General support The PVS team runs various mailing lists. Competent and fast answers per e-mail make up a good support.</p><p>Code generation PVS is not intended to produce executable code. PVS is a specification language integrated with support tools and a theorem prover. So the code has to be written in the specification language, which then can be verified. A translation of such algorithms into real code is still necessary.</p><p>Learning curve PVS is hard to learn. PVS offers many possibilities during the proving phase. How and when to use them requires not only inten- sive training with PVS but also a profound knowledge of logic. PVS is highly interactive, advanced knowledge is definitively necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">Cubic sum</head><p>Compute the sum of cubed numbers. Complexity of user interaction The (grind) meta rule is powerful and discharges most obligations. After careful study of the documentation it is also clear that an induction on the recursively decreasing variable is the way to success.</p><p>Degree of coverage With the above commands the whole program could be verified.</p><p>Support in finding errors PVS hardly gives hints on structural problems. Often the proving process becomes so interactive and intricate that it is hard to follow PVS problems. The user has already to have a plan to use induction, otherwise he will fail.</p><p>Ease of problem formulation The function and the lemmas can be ex- pressed in an intuitive functional style.</p><p>Complexity of user interaction The amount of user interaction is quite high, especially for fac_inc. The rewriting and instantiating of already proved lemmas is non trivial and needs insight into the structure of the proof.</p><p>Degree of coverage With the above mentioned tricks everything could be verified.</p><p>Support in finding errors Due to the complex proving procedure, PVS could not give any hints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.3">Inversions</head><p>Prove some properties on inversion pairs of numbers. Complexity of user interaction Sets cause problems with the meta strat- egy (grind). At first one has to use the mechanism of extensionality. It takes time to extract this from the documentation or the PVS mailing list.</p><p>Degree of coverage The properties could be proved, but with a significant amount of interactivity.</p><p>Support in finding errors PVS failed to give any support for this prob- lem. In the beginning in inv_test the order of numbers in the arrays was unwillingly permuted. PVS gave no hints why it could not prove anything. It took hours to find the error manually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.4">Multiplication</head><p>Multiply two integer numbers. Complexity of user interaction At the first try it is hard to find out that the proof of mult_ok2 requires the proof of a more general the- orem, mult_ok. Only the latter can be proved directly by induction. mult_ok2 is then obtained by instantiation and rewriting.</p><p>Degree of coverage With the rewriting complete coverage was possible. The high interactivity of the user shall be mentioned here explicitly.</p><p>Support in finding errors PVS gives only passive support in finding er- rors. By inspecting unprovable sequents one has to deduce which premises are missing or whether errors in the specification occurred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.5">Quicksort</head><p>Sort a sequence of numbers according to the well known Quicksort algorithm developed by Tony Hoare. This example is due to <ref type="bibr">Griffioen and Huisman [1998]</ref>. Proof procedure Due to the length of the proof, the proof was omitted here. It can be found in the source code package accompanying this thesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ease of problem formulation This example shows how powerful the PVS specification language is. Generic and modular theories with abstract data types are used here. PVS allows to write expressive formulas with short code.</p><p>Complexity of user interaction The proof is very complex with high user interactivity due to the massive use of PVS features. Also lists are somehow tricky, as it is sometimes necessary to give PVS hints on the used types (eg. ::nat).</p><p>Degree of coverage All properties could be verified.</p><p>Support in finding errors Similar to the previous example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Summary</head><p>The last two sections compared in detail the four selected tools: section 3 presented the tools from a theoretical point of view, whereas section 4 dis- cussed the implementation of several examples to illustrate the differences and capabilities. This section summarises the results with respect to the two target groups, namely software engineers and students of computer science with a limited background in formal logic.</p><p>Frege Program Prover FPP supports a small subset of Ada consisting of typical imperative program structures like loop, case-and if-statements. The only data types available are integer and boolean. The language for specifying pre-and post-conditions is rather restricted. E.g., func- tion definitions, recursive specifications and structured data types like arrays are not supported.</p><p>FPP is able to verify simple programs and to compute their weakest pre-conditions. The prover, Analytica, acts as a black box signalling either the validity of a formula or returning unprovable sub-formulas; formal proofs are not supplied.</p><p>Due to its simplicity and its web interface, FPP is easy to learn and use. It seems to be a valuable tool for illustrating the ideas of formal program verification in basic courses. It is not suitable, however, for advanced courses on the subject or for real world applications, as it is neither able to deal with standard examples from <ref type="bibr">Gries [1989]</ref> and <ref type="bibr">Dijkstra and Scholten [1990]</ref> involving arrays, nor does it support object-oriented features. Moreover, the terse output in pure ASCII makes it difficult to trace errors.</p><p>The KeY system The KeY system supports a subset of Java known as JavaCard, which is increasingly used for mobile and embedded devices. Verification is based on dynamic logic, a generalisation of the Hoare calculus. The system is integrated into a professional CASE tool (Bor- land's Together Control Center); an integration into the free Eclipse environment is under way. Objects and constraints can be specified using UML and OCL. Java, UML, OCL, and CASE tools are familiar to software engineers and students alike, which helps in getting started. Nevertheless, KeY cannot be recommended for these target groups at present: the in- teractive prover and its interaction with the user are in their infancy (compare the example in section 4.4.2) and are inadequate for any se-rious use. Moreover, OCL is not expressive enough to specify complex program behaviour.</p><p>Considering that KeY is still in alpha stage, it seems to be worthwhile to reevaluate the system in a few years in order to see whether it lives up to expectations.</p><p>Perfect Developer PD consists of a full-fledged object-oriented program- ming language, Perfect, of a powerful automated theorem prover and of a code generator translating programs from Perfect to Java, Ada, and C++. A rich collection of built-in data types, classes, functions and theories allows the user to write concise specifications on a fairly abstract level.</p><p>PD is a technically mature product that is ready for use in a regular development process. However, software engineers will need some time to become sufficiently acquainted with the many features of Perfect. Moreover, at least a basic knowledge of formal logic is required to be able to interpret the prover output and to use it for detecting errors in the specification or in the program. Perfect Developer is also well suited for teaching advanced courses on formal program verification. Usually there will not be enough time to cover all features of Perfect. Therefore a tutorial is required that concentrates on just those elements of the language that are necessary to implement and verify instructive examples like those in <ref type="bibr">Gries [1989]</ref>.</p><p>PD is the only tool of the four that comes close to the ideal of au- tomatic and easy program verification. But there are also still some shortcomings. One is that the prover currently does not support in- duction. Consequently certain recursive functions and loops cannot be verified by the system. Another weakness, at least from an academic point of view, is the lack of information concerning the inner work- ings of the prover. Ideally the logical rules used in correctness proofs should be open for inspection such that independent proof checkers can establish additional trust in the system.</p><p>Prototype Verification System PVS is a powerful interactive theorem prover, which has been used for various real world applications. In contrast to the other systems it does not generate verified program code, but proves properties of algorithms. The prover is versatile and offers many possibilities. It is automatic to a certain degree, but usually requires frequent user interactions.</p><p>Due to its many basic inference rules and tactics it takes a long learning phase to become familiar with the system. Moreover, users of PVS need a firm background in mathematics and formal logic to guide the prover. In our opinion typical software engineers and average students of computer science will have a hard time using PVS. Graduate or Ph.D. students might have a chance, provided they are given enough time. For courses with just a few hours per week in the lab PVS seems to be too complex. <ref type="figure" target="#fig_25">Figure 2</ref> compares the four selected tools FPP, KeY, PD and PVS ac- cording to formal background in logic and the field of application.</p><p>Tools for formal software verification have made considerable progress in recent years. With the advent of tools that offer formal methods on a level accessible to software engineers the costs for formal software verification will decrease such that it will be used in more and more projects. Universities have to react already today by training students in formal methods, using one or the other system.</p><p>Latest announcements have also affirmed that there is ongoing develop- ment in the field of software verification tools and the grand challenge towards the verifying compiler is more up-to-date than ever before. Nevertheless a lot needs to be done to achieve a wide acceptance of formal verification:</p><p>Most of the general public, and even many programmers, are unaware of the possibility that computers might check the cor- rectness of their own programs <ref type="bibr">[Hoare, 2003, p. 65]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resources</head><p>Additional material, like the examples and their source code, and this thesis are available online at http://www.logic.at/staff/feinerer.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of the KeY system, Ahrendt et al. [2004, p. 3]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Inductive definitions It is possible to define a function or behaviour (e.g. predicate) in an inductive style. Some restrictions have to be guaran- teed -for details refer [Owre et al., 2001a, p. 23 ff].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Expressions</head><label></label><figDesc>For the PVS Specification language various expressions are defined. The semantics of the structures is similarly to any other func- tional programming language. For an exact specification look at [Owre et al., 2001a, p. 43 ff] and Owre and Shankar</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>The grammar in an extended Backus-</head><label></label><figDesc>Naur form for the PVS Language is defined in [Owre et al., 2001a, p. 83 ff, Appendix A].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>,</head><label></label><figDesc>B, C), ∆ with IF (A, B, IF (C, D, E)) as an abbreviation for IF A THEN B ELSIF C THEN D ELSE E ENDIF. The transformation of an A[e] to A[a] means that all occurrences of e in A are replaced by a. More exhaustive descriptions about the logic behind PVS and its prover components can be looked up in Owre et al. [2001b]. Owre et al. [2001c] and Owre et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Analysis Ease of problem formulation The problem can be formulated in a clear</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>!pre : n &gt;= 1 AND previous = 0 AND current = 1 AND count = 1; --!post: current = fib(n); --!inv : count &gt;= 1 AND count &lt;= n AND previous = fib(count-1) AND current = fib(count); --!term: n -count; WHILE count &lt;Analysis Ease of problem formulation FPP supports the fib function. This helps to keep the formulation short and expressive. No tricks were necessary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Analysis Ease of problem formulation Not important. The problem just consists of a statement and a postcondition stating a difficult and inconsistent assumption.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Analysis Ease of problem formulation Very intuitive and straight forward.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>AND b ==&gt; a) AND (a AND (a ==&gt; b) ==&gt; b)) --&gt; vc : ((a AND b ==&gt; a) AND (a AND (a ==&gt; b) ==&gt; b)) --&gt; Result: proved NULL; --!post : ((a AND b ==&gt; a) AND (a AND (a ==&gt; b) ==&gt; b)) Analysis Ease of problem formulation The same as in the previous example - very natural.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Analysis Ease of problem formulation Not applicable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Program code public class ListMax { /** * @preconditions l.length() &gt; 0 and l &lt;&gt; null * @postconditions result &gt;= l.get(0) */ public static int listMax(int[] l) { int max = l[0]; for (int i=0; i &lt; l.length; i++) { if (l[i] &gt; max) max = l[i]; } return max; } } Analysis Ease of problem formulation Once more KeY shows its big advantage:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Ease of problem formulation The program itself and the conditions are obvious and easy to formulate. Only for the OCL constraints one has to be careful about the non-negativity conditions and the reference to the variables at program start (with the @pre formalism).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Prover output Failed to prove obligation: Assertion valid In the context of class: Examples Obligation location: Examples.pd (19,9) Condition defined at: Examples.pd (30,19) To prove: #flatten( (for i::0 .. &lt;#A yield for those j::0 .. &lt;#A :-(i &lt; j) &amp; (A[j as nat] &lt; A[i as nat]) yield pair of (nat,nat) {i as nat,j as nat})) &lt; (#A ^ (2 as nat)) Reason: Exhausted rules Could not prove: (+ over for x::0 .. (-1 + #A) yield #(those x::(0 .. (-1 + #A)).ranb :- (A[j] &lt; A[x]) and (j &lt; x))) &lt; (#A ^ 2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Program code function listMax(l: seq of nat, maxValue: nat, maxValueIndex: nat, i: nat): pair of (nat,Analysis Ease of problem formulation The functional recursive definition allows a short formulation. Language constructs like pair and seq allow so- phisticated return types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>Analysis Ease of problem formulation The formulation was very easy and clear. No tricks were necessary. Complexity of user interaction None. Complete automatic verification. Degree of coverage PD could verify the program completely.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>Analysis Ease of problem formulation The recursive specification is natural and constitutes a nice mathematical way to describe this problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>Program code inv: THEORY BEGIN A: VAR ARRAY[nat -&gt; nat] lenA: VAR nat %% A set is defined as a predicate in PVS inv(A, lenA): set[[nat, nat]] = { (i: below(lenA), j: below(lenA)) | i &lt; j AND A(i) &gt; A(j) } %% An array is a (total) function in PVS inv_test: LEMMA inv((LAMBDA (x: nat): IF x = 0 THEN 3 ELSE 1 ENDIF), 2) = add((0,1), emptyset[[nat, nat]]) inv_null: LEMMA inv((LAMBDA (x: nat): 0), 0) = emptyset[[nat, nat]] END inv Proof procedure inv_test: (apply-extensionality) (grind) inv_null: (apply-extensionality) (grind) Analysis Ease of problem formulation PVS makes it quite difficult to handle this problem. The first aspect is that arrays are just functions. This leads to difficulties with return types and getting the length or the number of elements of an array.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>LEMMA mult(x, y, z + c) = mult(x, y, c) + z mult_ok2: LEMMA FORALL (x, y): mult(x, y, 0) = x * y END mult Proof procedure mult_test: (grind) mult_ok: (induct-and-simplify "y") mult_add: (induct-and-simplify "y") mult_ok2: (skosimp*) (rewrite "mult_ok" :subst ("z" 0)) Analysis Ease of problem formulation The program itself can be easily formu- lated in a recursive style. The lemmas for the conditions are also easily stated with the help of quantifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>%</head><label></label><figDesc>def and lems on sorting. sorted_rec(l): RECURSIVE bool = null?(l) OR null?(cdr(l)) OR (car(l) &lt;= car(cdr(l)) AND sorted_rec(cdr(l))) MEASURE length(l) qsort(l:list[T]): RECURSIVE list[T] = IF null?(l) THEN null ELSE LET piv = car(l) IN append(qsort(filter(cdr(l),(LAMBDA e: e &lt;= piv))), cons(piv, qsort(filter(cdr(l),(LAMBDA e: NOT e &lt;= piv))))) ENDIF MEASURE length(l) qsort_sorted : LEMMA sorted_rec(qsort(l)) END sort int_sort: THEORY BEGIN IMPORTING sort[int,&lt;=] int_oke: LEMMA FORALL (l:list[int]): sorted_rec(qsort(l))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of FPP, KeY, PD and PVS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>or academic nature KeY is of academic nature. The tested version of KeY uses a commercial CASE tool, but the KeY prover component can be used separately. Future version will probably use Eclipse which is freely available. Supported platforms and portability Official supported platforms are Linux, Solaris and Windows. Portability of the written code is given as long as a Java compiler exists on the platform. For most modern oper- ating systems this should not be a problem and hence good portability is attested here. Installation The installation is quite a complex task: KeY uses Borland Together Control Center as the basic CASE tool, what means extra installation. Together CC is not freely available in general (there ex- ist evaluation and academic versions) and the installation process was tricky. It took some time to get KeY working.</figDesc><table></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">Factorial</head><p>The factorial for a given number shall be computed. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">David Crocker. The Perfect Developer Language Reference Manual, September 2001. David Crocker. Developing Reliable Software using Object-Oriented Formal Specification and Refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Baar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Beckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Bubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Giese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiner</forename><surname>Hähnle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfram</forename><surname>Menzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Mostowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Schlager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; Andrej</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Zhao ; Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Beckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Giese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiner</forename><surname>Habermalz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Hähnle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rümmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schlager</surname></persName>
		</author>
		<idno>1-85233-800-8</idno>
		<ptr target="http://www-unix.mcs.anl.gov/AAR/issuesept04/index.html#paradox" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Safety-Critical Systems Symposium</title>
		<editor>Redmill and Anderson</editor>
		<meeting>the Twelfth Safety-Critical Systems Symposium<address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="19" to="41" />
		</imprint>
	</monogr>
<note type="report_type">Analytica-A Theorem Prover for Mathematica. The Mathematica Journal</note>
	<note>Franz Baader and Tobias Nipkow. Term Rewriting and All That</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ein Vergleich der Programmbeweiser FPP, NPPV und SPARK. Ada-Deutschland-Tagung</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Freining</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Kauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Winkler</surname></persName>
		</author>
		<idno>1433-9986</idno>
		<ptr target="http://www.cis.upenn.edu/∼jean/gbooks/logic.html.JohnGannon" />
	</analytic>
	<monogr>
		<title level="m">Predicate Calculus and Program Semantics</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1989" />
			<biblScope unit="page" from="127" to="145" />
		</imprint>
	</monogr>
	<note>Logic for Computer Science: Foundations of Automatic Theorem Proving. Gerhard Gentzen. UntersuchungenüberUntersuchungen¨Untersuchungenüber das logische Schließen. Mathematische Zeitschrift, 39, 1935. David Gries. The Science of Programming</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ISBN 0 521 54310X. Cliff Jones. The Early Search for Tractable Ways of Reasoning about Programs</title>
		<idno type="doi">10.1145/363235.363259</idno>
		<idno>ISBN 0-7695-1877-X</idno>
		<ptr target="http://doi.acm.org/10.1145/602382.602403" />
	</analytic>
	<monogr>
		<title level="m">ICSE &apos;03: Proceedings of the 25th International Conference on Software Engineering</title>
		<editor>Isabelle/HOL. In Jim Grundy and Malcolm Newey</editor>
		<meeting><address><addrLine>Canberra, Australia; Bertrand Meyer</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1969" />
			<biblScope unit="volume">1479</biblScope>
			<biblScope unit="page" from="660" to="667" />
		</imprint>
	</monogr>
	<note>Theorem Proving in Higher Order Logics: 11th International Conference, TPHOLs &apos;98</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sam Owre and Natarajan Shankar. The Formal Semantics of PVS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sam Owre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natarajan</forename><surname>Rushby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natarajan</forename><surname>Shankar ; John Rushby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stringer-Calvert</surname></persName>
		</author>
		<idno>0943-7207</idno>
		<ptr target="http://www.csl.sri" />
	</analytic>
	<monogr>
		<title level="m">The Frege Program Prover. 42. Internationales Wissenschaftliches Kolloquium</title>
		<editor>Sam Owre, John Rushby, Natarajan Shankar, and David Stringer-Calvert. PVS System Guide</editor>
		<meeting><address><addrLine>Saratoga, NY; Boppard, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1992-06" />
			<biblScope unit="volume">607</biblScope>
			<biblScope unit="page" from="116" to="121" />
		</imprint>
		<respStmt>
			<orgName>Institute of Computer Languages, Vienna University of Technology ; Jürgen Winkler. wp is Basically a State Set Transformer. Institute of Computer Science, Friedrich-Schiller-University ; Technische Universität Ilmenau</orgName>
		</respStmt>
	</monogr>
	<note>11th International Conference on Automated Deduction</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
