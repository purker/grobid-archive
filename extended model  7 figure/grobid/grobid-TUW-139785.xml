<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Users\Angela\git\grobid\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="de">
		<encodingDesc>
			<appInfo>
				<application version="0.4.5-dummy" ident="GROBID" when="2017-12-29T00:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Eine generische Bibliothek für Metaheuristiken und ihre Anwendung auf das Quadratic Assignment Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Algorithmen</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Computergraphik</orgName>
								<orgName type="laboratory">a.o. Univ.-Prof. Dipl.-Ing</orgName>
								<orgName type="institution">Technischen Universität Wien</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anleitung</forename><surname>Von</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Computergraphik</orgName>
								<orgName type="laboratory">a.o. Univ.-Prof. Dipl.-Ing</orgName>
								<orgName type="institution">Technischen Universität Wien</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Dr.techn</roleName><forename type="first">Raidl</forename><surname>Günther</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Computergraphik</orgName>
								<orgName type="laboratory">a.o. Univ.-Prof. Dipl.-Ing</orgName>
								<orgName type="institution">Technischen Universität Wien</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Durch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Computergraphik</orgName>
								<orgName type="laboratory">a.o. Univ.-Prof. Dipl.-Ing</orgName>
								<orgName type="institution">Technischen Universität Wien</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wagner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Computergraphik</orgName>
								<orgName type="laboratory">a.o. Univ.-Prof. Dipl.-Ing</orgName>
								<orgName type="institution">Technischen Universität Wien</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Eine generische Bibliothek für Metaheuristiken und ihre Anwendung auf das Quadratic Assignment Problem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>D I P L O M A R B E I T Schauleithenstraße 9 3363 Ulmerfeld-Hausmening Datum Unterschrift Version enthält sind lokale Suche, Simulated Annealing, Tabusearch, Guided Local Search und Greedy Randomized Adaptive Search Procedure implementiert worden.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this master thesis a generic libray of efficient metaheuristics for combinatorial optimization is presented. In the version at hand classes that feature local search, simulated annealing, tabu search, guided local search and greedy randomized adap-tive search procedure were implemeted. Most notably a generic implementation features the advantage that the problem dependent classes and methods only need to be realized once without targeting a specific algorithm because these parts of the sourcecode are shared among all present algorithms contained in EAlib. This main advantage is then exemplarily demonstrated with the quadratic assignment problem. The sourcecode of the QAP example can also be used as an commented reference for future problems. Concluding the experimental results of the individual metaheuristics reached with the presented implementation are presented. Kurzfassung In dieser Diplomarbeit wird eine generische Bibliothek von effizienten Metaheuris-tiken für kombinatorische Optimierungsprobleme vorgestellt. In der vorliegenden Eine generische Implementierung bietet vorallem den Vorteil das bei einem neuen zu lösendem Problem nur einige bestimmte problemabhängige Klassen und Metho-den realisiert werden müssen ohne sich schon im Vorhinein einen speziellen Algorith-mus festzulegen, da diese Klassen und Methoden von allen in der EAlib vorhanden Metaheuristiken verwendet werden. Die Vorteile dieser Bibliothek werden anschließend anhand des Quadratic Assignment Problems ausführlich dargestellt. Dieses Beispiel dient zusätzlich auch noch als kommentierte Referenz für zukünftige Problemimplentierungen. Abschließend werden die Resulate der Experimente mit den verschiedenen Meta-heuristiken präsentiert. 1 Danksagung An dieser stelle möchte ich mich bei allen Menschen bedanken die zum Gelingen dieser Diplomarbeit beigetragen haben. Dieser Dank gilt meinem Betreuer Prof. Raidl, der mich mit großer Geduld am Weg zum Abschluß begleitet hat und mit mir in den vielen Treffen oft nützliche Ideen entwickelt hat. Meinen Eltern und meinem Bruder Ronald danke ich für ein sorgloses Studium und die moralische Unterstützung wenn die Motivation einmal nicht so groß war. Bei meinen Studienkollegen, besonders bei Harry und Zamb, bedanke ich mich für die Freundschaft, den Spaß und die gegenseitige Unterstützung. Last but not least möchte ich mich auch bei meinen Mitbewohnern Sic0 und Leo bedanken, die mir während meiner Arbeit die nötige Ruhe zukommen ließen, aber natürlich auch ab und zu für willkommene Ablenkung gesorgt haben. Natascha danke ich für die schöne gemeinsame Zeit. 2</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="de">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kurzfassung</head><p>In dieser Diplomarbeit wird eine generische Bibliothek von effizienten Metaheuris- tiken für kombinatorische Optimierungsprobleme vorgestellt. In der vorliegenden Version enthält sind lokale Suche, Simulated Annealing, Tabusearch, Guided Local Search und Greedy Randomized Adaptive Search Procedure implementiert worden.</p><p>Eine generische Implementierung bietet vorallem den Vorteil das bei einem neuen zu lösendem Problem nur einige bestimmte problemabhängige Klassen und Metho- den realisiert werden müssen ohne sich schon im Vorhinein einen speziellen Algorith- mus festzulegen, da diese Klassen und Methoden von allen in der EAlib vorhanden Metaheuristiken verwendet werden.</p><p>Die Vorteile dieser Bibliothek werden anschließend anhand des Quadratic Assign- ment Problems ausführlich dargestellt. Dieses Beispiel dient zusätzlich auch noch als kommentierte Referenz für zukünftige Problemimplentierungen.</p><p>Abschließend werden die Resulate der Experimente mit den verschiedenen Meta- heuristiken präsentiert. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bibliography 70</head><p>All men by nature desire knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aristotle</head><p>Chapter 1 Introduction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation</head><p>Metaheuristics are a popular approach to handle computationally intractable opti- mization problems. In the course of this master thesis an existing library dedicated to evolutionary algorithms was extended substantially by several common known and used metaheuristics. These metaheuristics are implemented in a generic man- ner so that their application to a widespread variety of combinatorial optimization problems is supported. A generic implementation of metaheuristics is desirable because common por- tions of many metaheuristics can be implemented problem independent and also a significant amount of problem dependent sourcecode can be shared between the metaheuristics, e.g. efficient evaluation of the objective value or neighborhood rele- vant methods.</p><p>The basis for the implementation of the metaheuristics is the EAlib library which is developed at the Vienna University of Technology, Institute of Computergraphics and Algorithms. At the beginning of this master thesis it already contained partic- ular classes for evolutionary algorithms and some supporting infrastructure which was also useful for our project. The aim of this master thesis the was to extend this existing library while trying to keep changes to the existing parts to a minimum to maintain compatibility with present applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Combinatorial Optimization and Metaheuris- tics</head><p>An optimization problem can be characterized as the selection of a "best" config- uration or set of parameters to achieve some objective criteria. If the entities to be optimized are discrete, the number of feasible solutions is finite. We call such problems combinatorial optimization problems.</p><p>A combinatorial optimization problem is specified formally by a set of problem instances and is either a minimization problem or a maximization problem. An instance of a combinatorial minimization problem is a pair (X , f ), where the solution set X is the set of all feasible solutions and the cost function f is a mapping f : X ← R. The problem is to find a globally optimal solution, i.e. an x * ∈ X such that f (x * ) ≤ f (x) for all x ∈ X . Maximization problems can be trivially transformed into minimization problems by changing the sign of the cost function f . Salient examples are the traveling sales problem and related routing and trans- portation problems, scheduling and time-tabling, cutting and packing tasks. Most of these problems are NP-hard. However NP-hardness does not necessarily mean that all practically relevant instances are not solveable within acceptable time. Vice versa, an algorithm for a polynomial-time solvable problem might be too expensive in practice.</p><p>Many different algorithmic strategies exist to deal with this problems and the metaheuristics, which are the main topic of this work, are among of them. Tradi- tionally metaheuristics are considered as solution methods utilizing an interaction between local improvement procedures and higher level strategies to overcome local optima leading to a robust search process. In general metaheuristics contain are not designed for a specific optimization problem. They rather can be applied to a wide range of problems. Therefore many metaheuristics can be implemented in a generic manner straighforward.</p><p>For the library at hand five initial metaheuristics were chosen for implementation which are local search, simulated annealing, tabu search, guided local search and greedy randomized adaptive search procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Guide to the thesis</head><p>The thesis at hand describes the quadratic assignment problem in Chapter 2 which we chose as an example problem to demonstrate the application of EAlib to a new task and to illustrate the pros and cons of the implemented metaheuristics. In Chapter 3 all featured algorithms are explained. The requirements of functionality, design and usability of the targeted library are specified in Chapter 4 while the details of the implemented library are stated in Chapter 5. Finaly experimental results of solving the quadratic assignment problem using the new EAlib are presented in Chapter 6.</p><p>Science is organized knowledge. Wisdom is organized life.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Imanuel Kant</head><p>Chapter 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quadratic Assignment Problem</head><p>Since the quadratic assignment problem (QAP) was mentioned first by Koopmans and Beckmann <ref type="bibr" target="#b32">[23]</ref> in 1957, they used the QAP to model economic activities, many authors contributed to it, see Loiola et al. <ref type="bibr" target="#b36">[27]</ref> for a recent survey article about the QAP. The major attraction points of the QAP are its practical and theoretical importance and its computational complexity -it is one of the most difficult combi- natorial optimization problems. In general problem instances of size n ≥ 30 can not be solved in reasonable time. <ref type="bibr">Sahni and Gonzales [39]</ref> had first shown that the QAP is a member of the class of NP-hard problems and that, unless P = NP, it is not possible to find a polynomial algorithm, for a constant Neverthe- less recent results (Gutin and Yeo <ref type="bibr" target="#b29">[20]</ref>) proved that, in the case of QAP, polynomial approximations with factorial domination number exist. For more information on the theory of NP-completeness Garey and Johnson <ref type="bibr" target="#b23">[14]</ref> is recommended.</p><p>Since the QAP is very versatile, several other NP-hard combinatorial optimiza- tion problems such as traveling salesman problem (TSP), graph partitioning, the bin-packing problem (BPP) or the max clique problem can be formulated and solved using QAPs <ref type="bibr" target="#b14">[5,</ref><ref type="bibr" target="#b36">27]</ref>.</p><p>Prior to an exact definition of the QAP, a simpler related problem, the linear assignment problem (LAP), is presented as a smoother introduction assignment. After a short description of the LAP, a comprehensive explanation of the QAP, which will cover a problem definition and various mathematical formulation approaches, resolution methods and finally applications, will be provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Description</head><p>Assigning objects is a common task for econimic or techinical staff. Therefore it is not a surprise that assigment problems are among the greatest challanges in the area of combinatorial optimization.</p><p>As an introduction the linear assignment problem (LAP) is presented here. As- sume there are two equal sized sets of objects, e.g. persons and jobs, and they are assigned to each other by making up pair of those objects, taking one from each set for a pair. Additionally every possible pair is given a value, which results in a n × n matrix with n 2 elements. The problem now is to find an assignment of all objects for which the sum of the values is minimized. An example application for the LAP is the assignment of persons to jobs. Mathematically this problem can be formulated as follows.</p><formula xml:id="formula_0">n min π∈Π a i,π(i) (2.1) i=1</formula><p>where A = [a i,π(i) ] is the matrix of values for assigning object i to π(i) and further Π is the set of all permutations of the n elements {1, . . . , n}. The LAP is polynomial and is easily solved by the Hungarian method <ref type="bibr" target="#b36">[27]</ref> which was proposed by Harold W. Kuhn in 1955 <ref type="bibr" target="#b33">[24]</ref>.</p><p>Reconsidering the above description the question arises if it really true that an assignment of two objects does not have any sideeffects on other assignments. If this assumption does not hold, the quadratic assignemnt problem may give an appropriate formal description of the real-world problem.</p><p>QAP is a generalization of in the linear assignment problem in a manner that assignment can affect each another. Therefore, in addition to the value matrix - when using QAPs it is called distance matrix -a flow matrix of same dimension is introduced. As an example that is related to the previous mentioned one with persons and jobs, the distance matrix can be interpreted as the distance between the offices and the flow as the amount of interaction between these persons. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Formulations</head><p>Nowadays many different formulations are used. Loiola et al. <ref type="bibr" target="#b36">[27]</ref> and Commander and Pardalos <ref type="bibr" target="#b18">[9]</ref> give a good survey over the existing formulations of the quadratic assignment problem, different resolution methods, lower bound calculation and ap- plications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Permutation Formulation</head><p>As an introduction the popular and very intuitive formulation is based on permuta- tions is given. Thereby the QAP can be stated as follows. Let A, B and C be n × n matrices representing flows between objects, distances between locations and costs for assigning objects to locations, further let Π be the set of all possible permutations of the n elements {1, . . . , n}.</p><formula xml:id="formula_1">n n n min π∈Π a i,j b π(i),π(j) + c i,π(i) (2.2) i=1 j=1 i=1</formula><p>a i,j is the flow between objects i and j, b π(i),π(j) is the distance between locations π(i) and π(j) and c i,π(i) is the fixed cost of assigning object i to location π(i).</p><p>The formulation given contains a linear part to model fixed assignment cost. However many authors neglect this term of the equation, since it is a LAP and thus easy to be solved, e.g. with the Hungarian method, or because they do not need this term for their considerations; the resulting formulation is stated below:</p><formula xml:id="formula_2">n n min π∈Π a i,j b π(i),π(j) (2.3) i=1 j=1</formula><p>In the implementation of this master thesis we used the term to be minimized in the above formula as objective function. Consequently our solution representation consists of the permutation vector π.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Integer Linear Programming</head><p>Koopmans and Beckman <ref type="bibr" target="#b32">[23]</ref> used a different formulation in their initial statement of the quadratic assignment problem; the so-called integer linear programming (IP) formulation. It is still of great use, since IP is a topic of ongoing research. In this formulation the reader also can see why the problem is called quadratic, which is not so obsious in some of the other formulations.</p><p>The general IP formulation is as follows. Let A = [a i,j ] be a matrix of flows between objects i and j and further B = [b k,p ] a matrix of the distances between positions k and p and lastly C = [c i,k ] a matrix of costs for assigning object i to position k:</p><formula xml:id="formula_3">n n n min a i,j b k,p x i,j x k,p + c i,k x i,k (2.4) i,j=1</formula><p>k,p=1</p><p>i,k=1 n s.t.</p><formula xml:id="formula_4">x i,j = 1 1 ≤ j ≤ n, (2.5) i=1 n x i,j = 1 1 ≤ i ≤ n, (2.6) j=1 x i,j ∈ {0, 1} 1 ≤ i, j ≤ n. (2.7)</formula><p>The actual QAP is the problem of minizing equation above, by proper choice of the permutation matrix X = [x i,j ]. The minimand contains a term of second degree in the unknown permutation matrix X and therefor the problem is called quadratic.</p><p>For the same reason as in the prior section the linear term regarding the fixed costs of assigning objects to locatinos can be neglected, leading to the following formulation:</p><formula xml:id="formula_5">n n min a i,j b k,p x i,j x k,p (2.8) i,j=1 k,p=1</formula><p>s.t. (2.5), (2.6) and (2.7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Trace Formulation</head><p>Since the essential information about an actual QAP instance is represented usually with matrices it is not surprising that a formulation evolved which takes advantage of this; the trace formulation is an approach to mathematically describe the QAP that uses the trace of a matrix which is defined by trace A = n i a i,i . It was introduced by Edwards <ref type="bibr" target="#b19">[10]</ref>. Again consider A = [a i,j ] a matrix of flows from object i to object j, B = [b k,p ] distances of location k and p and C = [c i,k ] costs of assigning object i to location k. min</p><formula xml:id="formula_6">T X∈Π trace (AXB T + C)X (2.9)</formula><p>repectively with the linear term of the problem omitted:</p><formula xml:id="formula_7">min T X∈Π trace (AXB T )X (2.10)</formula><p>where Π is the set of all n × n permutation matrices. It is often used in lower bounds related publications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Lower Bounds</head><p>The knowledge of lower bounds is fundamental when developing optimization algo- rithms to solve combinatorial or other mathematical problems. This importance of lower bounds is two-fold. At first they are an essential part of exact algorithms, e.g. branch-and-bound procedures. These methods, while attempting to guarantee the global optimum, also try to avoid the total enumeration of the complete search space. Therefore the performance of such methods depends strongly on the compu- tational quality and efficiency of the utilized lower bounding techniques. An other application of lower bounds is the evaluation of the quality of solutions obtained by some heuristic algorithms (see Section 6.1 on page 52).</p><p>The quality of the lower bound can be measured by the gap between the com- puted bound with the known optimal solution, this referred to as the tightness of the bound, i.e. good lower bounds are closer to the global optimum. For an exact algorithm a good bounding technique, which can find the bounds quickly 1 , should be used. When used in heuristics, lower bound quality is the most important property. One of the first suggested and best known lower bounds for the quadratic assign- ment problem is the one presented by Gilmore <ref type="bibr" target="#b24">[15]</ref> and Lawler <ref type="bibr" target="#b34">[25]</ref>. The Gilmore- Lawler-Bound (GLB) is given by the solution of linear assignment problem whose cost matrix is gained by special inner products of the flow-and distance-matrix of the original QAP. The advantage of the GLB is that is simple and it can be com- puted efficiently. However, its drawback is that the gap to the optimal solution grows with the size of problem. For this reason the GLB is a weak bound for larger problem instances.</p><p>Due to an intensive research activity many other lower bounds have been dis- coverd. Bounds based on mixed integer linear programming (MILP) relaxations, eigenvalues of the flow-and distance matrix, reformulations of the above mentioned GLB exist. Some of them, e.g. eigenvalue based bounds, really outperform the origi- nal GLB so far tightness is concerned, but they suffer from high computation require- ments. The most recent and promising research trends are based on semidefinite programming (SDP), reformulation linearization. Anstreicher and Brixius <ref type="bibr" target="#b10">[1]</ref> pre- sented a lower bound for the QAP based on semidefinite and convex quadratic pro- gramming, a bound using the bundle method is proposed by Rendl and Sotirov <ref type="bibr" target="#b45">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Solution Methods</head><p>Since its statement, many different approaches were applied to solve the quadratic assignment problem. These can be categorized in either exact or heuristic methods. In this section we an overview about some of the most successfull or frequent used methods of these categories are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Exact Algorithms</head><p>The oldest and simplest way, to resolve the quadratic assignment problem, is enu- meration. This causes evaluation of the objective function for all n! possible permu- tations and memorizing the best found solutions; note that there is not necesssarily only oneoptimal solution. The computational effort for evaluating the cost of a permutation requires O(n 2 ) steps, which has to be computed O(n!) times yielding exponentially sized computation times. Enumeration is very simple to code and has small memory requirements, on the other hand its use is very limited and not of practical relevance.</p><p>Other methods include quadratic programming, which reformulates the problem as a 0-1 program (see Section 2.2.2 on page 9) and linear programming, which linearizes the QAP by introducing new variables, the resulting linear program can be solved e.g. with mixed integer linear programming methods.</p><p>Many of the above methods share the same problem; they vastly examine the complete search space and therefore, as mentioned, only small problem instances can be solved within a reasonable amount time.</p><p>The most successful exact resolution methods for the quadratic assignment prob- lem incorporate branch-and-bound (BB) algorithms. Essential for BB is a good bounding technique, because this directly affects the extent to which the search space must be enumerated; the thighter the used bound, the more solutions can be excluded from the exploration.</p><p>Branch-and-bound methods attract many researchers due to their potential. For example Frazer <ref type="bibr" target="#b22">[13]</ref> and Brixius and Anstreicher <ref type="bibr" target="#b14">[5]</ref> describe a BB implementation and Anstreicher et al. <ref type="bibr" target="#b11">[2]</ref> describe a grid enabled BB implementation which was used to solve a problem instance of size 30 to optimality. They report the utilization of an average of 650 worker machines over a one-weekend period, which provides the equivalent of almost 7 years of computation on one single HP9000 C3000 worksta- tion. For an other instance of the same size they utilized the equivalent of 15 years on a single C3000. These examples show the potential of parallelization, which is currently one of the major fields of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Heuristics</head><p>Heuristic algorithms, contrary to exact algorithms, can not provide any guarantee of optimality for the best solution obtained. The reason for the current research on suboptimal solution methods is the fact that many of them can provide good solutions within reasonable time constraints, which is often necessary real-world application environments. Heuristic methods include the following categories: con- structive, enumeration and improvement methods.</p><p>Constructive methods, which are among the earliest heuristics to solve the QAP, try to complete a permutation with each iteration of the algorithm. The selec- tion of each assignment is based on a heuristic selection criterion. For example Gilmore <ref type="bibr" target="#b24">[15]</ref> introduced one of the first constructive algorithms. Nowadays this category of heuristics focuses new interest because metaheuristics, such as the greedy randomized adaptive search procedure (see Section 3.5 on page 27) incorporate them.</p><p>Enumerative methods are motivated by the expectation that an acceptable solu- tion can be found early during a brute force exploration of the search space. For interesting problems these methods do not enumerate the all feasible solu- tions and therefore different termination criteria are used. Usually the number of total iterations, or iterations between successive improvements is used, other common criteria include a limit on the total execution time or lowering the upper bound when no further improvements are possible after a number of iterations. It is important to remind that any of these termination criteria can prohibit the finding of an optimal solution.</p><p>Improvement methods correspond to local search algorithms (see Section 3.1 on page 19. Most of the heuristics for the QAP are part of this category.</p><p>An other worthy to mention category of methods are approximate algorithms, which are heuristics provinding quality guarantees for their solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Metaheuristics</head><p>Metaheuristics are, as their name suggests, heuristic algorithms too, but usually they can be adapted straighforward to a wide range of different problems; this is in general not possible for traditional heuristics. However, as the main focus of this master thesis lays on metaheuristcs we address them extensively in the next chapter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.4">Research Trends</head><p>Current state of the art algorithms can be divided into two major categories, at one side the search for optimal solutions and exact algorithms which can provide them, and on the other side methods that can provide solutions that are good enough in reasonable time. Of course also theoretical developments are of interest.</p><p>The main research focus for the QAP is generated by the growing interest on metaheuristics since the end of the 1980's because it is a popular benchmark to com- pare algorithms. With recent generations of computer technology the QAP attracted new attention, which lead to honorable developments in parallel algorithms.</p><p>Promising future developments seem to be possible through the hybridization of several algorithms, which generated some interest in the past, together with paral- lelization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Applications</head><p>The initial motivation that lead to the formulation of the quadratic assignment problem was:</p><p>In the light of the practical and theoretical importance of indivisi- bilities, it may seem surprising that we possess so little in the way of successful formal analysis of production problems involving indivisible resources. (Koopmans and Beckmann <ref type="bibr" target="#b32">[23]</ref>) <ref type="bibr">[...]</ref> The assumption that the benefit from an economic activity at some location does not depend on the uses of other locations is quite inade- quate to the complexities of locational decisions.</p><p>As the quoted statement suggests, a main field applications is allocation of re- sources with complex interactions of the individual resources. Koopmans and Beck- mann were economists and therefore their focus was on economic activities. Example applications are scheduling of jobs or production lines, facility organization, hospi- tal layout. Nevertheless the QAP is also of practical use where it is not so obvious like dartboard design or typewriter layout. Not to forget many engineering applica- tions. In the remainder of this section we illustrate two applications of the quadratic assignment problem in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Steinberg Wiring Problem</head><p>In a 1961 paper <ref type="bibr" target="#b49">[40]</ref>, Leon Steinberg proposed a backboard wiring problem. The problem is about the optimal placement of computer components on a backboard in such a manner, that the total interconnecting wiring length is minimized. Improved wiring length has two main advantages, most important it increases the performance of the designed system, not less attractive are the decreased manufacturing costs. The original problem instance consisted of 34 components with a total of 2625 inter- connections which were to be placed on a backboard with 36 open positions (circles in <ref type="figure">Figure 2</ref>.2).  Two dummy components, with no connections to any other components, are added so that the number of components equals the number of open positions. The use of dummy elements is a common trick to be able to formulate real-world problems as QAPs. With this addition the mathematical formulation can be given</p><formula xml:id="formula_8">min a i,k b j,l x i,j x kl (2.11) i,j,k.l s.t. x i,j = 1 i = 1, . . . , n j x i,j = 1 j = 1, . . . , n i x i,j ∈ 0, 1 i, j = 1, . . . , n</formula><p>where a i,k is the number of wires interconnection components i and k, b j,l is the distance between positions j and l on the backboard and x i,j = 1 if component i is placed at position j. Special attention is payed on the choice of the b j,l . In the original paper Steinberg considered using 1-norm, 2-norm or squared 2-norm distances. He further concentrated on obtaining good solutions for the 2-norm and squared 2-norm versions of the problem. However, research interest has been directed to the 1-norm version, which was also used by Brixius and Anstreicher <ref type="bibr" target="#b15">[6]</ref> who solved the initial problem instance to optimality with an exact branch-and-bound algorithm, 40 years after its statement. The solution required approximately 186 hours of CPU time on a single Pentium III personal computer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Antenna Assembly Sequence Problem</head><p>At the National Aeronautics and Space Administration (NASA) another interest- ing application of the quadratic assignment problem is reported by <ref type="bibr">Padula and Kincaid [33]</ref>. It is known that NASA often has to design and erect antennas (see <ref type="figure">Figure 2</ref>.3(a)) in space for different purposes like communication with spacecrafts (Deep Space Network). Such an antenna consists of a very large number n of truss elements. For research purposes, the antenna structure is designed as a tetrahedral truss with a flat top surface, which means that all nodes in the top surface of the finite-element model are coplanar (see <ref type="figure">Figure 2</ref>.3(b)). To minimize surface distor- tions and to the avoid internal forces during the assembly process of the antenna, the truss elements have to be of identical length. However, due to limitations in the manufacturing process, the length is never precisely identical. Each truss element j has a small but measurable error e j . To overcome the impact of these errors, the truss elements are assembled in such a way, that the errors offset each other. For a mathematical formulation of the described problem of arranging the truss elements first, an objective value has to be defined. The objective value of a concrete arrangement is stated as the squared L 2 norm of the surface distortion:</p><formula xml:id="formula_9">d 2 = e T U T D U e (2.12) = e T H e</formula><p>where e is the vector of measured errors, U is the influence matrix such that u i,j gives the influence of a truss length error in element j on the surface at node i and D is a positive semidefinite weighting matrix that denotes the relative importance of each node i at which distortion is measured. The calculation of matrix U is can be done with any structural analysis software package and the matrix D is often the identity matrix. Summarizing this, the combinatorial optimization problem for minimizing antenna distortions is stated as:</p><formula xml:id="formula_10">n n min e∈E e i h i,j e j (2.13) j=1 i=1</formula><p>where E are all possible permutations of the error vector e. Clearly the for- mulation above is a quadratic assignment problem, although it is not a common formulation; compare the permutation formulation in equation 2.3 on page 9.</p><p>In case of the antenna assembly sequence problem simulated annealing and tabu search where applied successfully to solve the problem. Prior to this attempts a pairwise interchange heuristic was suggested, which was based on a simple basic local search algorithm. It is not very surprising that the results achieved with local search where inferior to the ones obtained by simulated annealing or tabu search.</p><p>The main advantage for NASA gained by metaheuristically optimized assembling of the truss elements standard precision is adequate which decreases the overall costs since cost for truss elements increase dramatically when unusual precision in length is required.</p><p>This example shows that an engineering description of a problem can lead directly to a convenient solution method; however this is not the usual case.</p><p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Richard Feynman</head><p>Chapter 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metaheuristics</head><p>During the last decades a new kind of heuristic algorithms has emerged which tries to use lower-level heuristic approaches to build higher-level frameworks targeted at efficiently and effectively exploring a search space. The name metaheuristic, first introduced in Glover <ref type="bibr" target="#b25">[16]</ref>, stems from the composition of two Greek words. Heuristic derives from the verb heuriskein ( which means "to find" and the prefix meta means "beyond, in an upper level". This category of algorithms includes 1 Evolutionary Computing (EC) and Genetic</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms (GA), Guided Local Search (GLS), Greedy Randomized Adaptive Search</head><p>Procedure (GRASP), Iterated Local Search (ILS), Simulated Annealing (SA), Tabu Search (TS), Variable Neighborhood Search (VNS) and many more. For example, Glover and Kochenberger <ref type="bibr" target="#b28">[19]</ref> and Blum and Roli <ref type="bibr">[4]</ref> provide a survey on metaheuristics and related topics and current state of the art in the area. In this chapter we focus on the concepts and fundamental principles of the metaheuristics implemented during this master thesis.</p><p>But before we start off some some terms need to be clearyfied. We consider a neighborhood structure as a function N : X → 2 X , which assigns each valid solution</p><p>x ∈ X a set of neighbors N (x) ⊆ X . The set N (x) is commonly named the neighborhood of x. It is usually defined implicity through valid changes (moves) on the solutions x ∈ X . Furthermore we introduce a search space, i.e. a solution representation and an objective function. In other words a search space is a collection of possible solutions to the problem at hand, incorporation some notion of distance between the candidate solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Local Search</head><p>Basic local search (LS) is also called iterative improvement or hill-climbing because at each iteration a move is only performed when the new solution is better than the current solution, regarding to a defined objective function. A move is defined as the selection of a solution s out of a neighborhood N (s) of a solution s.</p><formula xml:id="formula_11">procedure Basic Local Search s ← GenerateInitialSolution() repeat s ← ChooseNeighbor(N (s)) if f (s ) ≤ f (s) then s ← s end if until termination conditions met end procedure</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Basic Local Search</head><p>In Algorithm 1 the basic algorithm is outlined in pseudocode. First of all the most important task is to define a search space. This means a representation of real-world objects and an objective function f are needed. Regarding the chosen representation an appropriate neighborhood structure has to be found. A popular choice for many combinatorial optimization problems is the 2-opt 2 neighborhood because it can be applied easy to many problems. Nevertheless, despite some exemptions, 2-opt tends to get stuck in local optima. Some other neighborhoods are k-flip for binary strings where the neigborhood consits of all solutions that have a Hamming-Distance less or equal to k. A generalized 2-opt, k-opt is also known. The GenerateInitialSolution function is needed to generate an initial solution at which the search begins. This could happen simply by a completely random choice or a more sophisticated construction method. As ChooseNeighbor(N (s)) function, also called step function, theoretically any function that chooses a solution s out of a neighborhood N (s) of solution s is possible, but it has turned out that only a few are commonly used:</p><p>random neighbor picks a neighboring solution out of N (s) at random.</p><p>first improvement systematically searches N (s) and chooses the first neighboring solution that is better than s.</p><p>best improvement completely explores N (s) and takes the best neighboring solu- tion.</p><p>Finally the termination conditions have to be defined. In case of the latter two ChooseNeighbor(N (s)) functions the simple condition stop if no further im- provement is made will almost always only find a local optimum. Other possible termination conditions depend on the amount of passed CPU-Time, number of iter- ations, number of iterations since the last improvement or any combination of these or other conditions, which is virtually always desired.</p><p>Depending on the chosen neighborhood the basic local search algorithm often only yields poor locally optimal solutions and is therefore only of limited use. To address this weakness, many advanced local search methods where proposed. Among others iterated local search <ref type="bibr" target="#b37">[28,</ref><ref type="bibr" target="#b38">29]</ref>, multi-start methods <ref type="bibr" target="#b39">[30]</ref>, guided local search, greedy randomized adaptive search procedure, simulated annealing and tabu search have been developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Simulated Annealing</head><p>Simulated annealing (SA) was the first major attempt to improve basic local search, which does not perform well if caught in a local optima -as pointed out in in the last section. It was proposed independently by Kirkpatrick et al. <ref type="bibr" target="#b31">[22]</ref> and Cerny <ref type="bibr" target="#b17">[8]</ref> during the early 1980s and it is commonly said that SA is the oldest among the metaheuristics. Simulated annealing is inspired by the physical process of cooling crystalline matter, hence it is often referred to as a nature inspired method.</p><p>The fundamental idea of simulated annealing is that in contrary to basic local search moves resulting in solutions of worse quality than the current solution are allowed with a certain probability in order to escape from local optima; these moves are referred to as uphill moves. The probability of accepting an uphill move depends on the actual deterioration and the current temperature, which is decreased during the search process. The simulated annealing metaheuristic is outlined as pseudocode in Algorithm 2 on the following page.</p><p>At first the algorithm generates an initial solution either randomly or with some construction heuristic and initializes the so-called temperature parameter T and the counter t. </p><formula xml:id="formula_12">f (s ) ≥ f (s)</formula><p>, with a probability which is a function of T , f (s) and f (s ). Generally the probability is computed following the Boltzmann distribution. Metropolis et al. <ref type="bibr" target="#b40">[31]</ref> have used this method when they simulated the movement of particles in cooled matter, therefore the name Metropolis-Criterion became popular for the following</p><formula xml:id="formula_13">procedure Simulated Annealing s ← GenerateInitialSolution() t ← 0 T ← T 0 repeat repeat s ← arbitrary solution ∈ N (s) if f (s ) &lt; f (s) then s ← s else if Z &lt; e −|f (x )−f (x)|/T then s ← s end if end if t ← t + 1 until temperature-update conditions met T ← g(T ,t) until termination conditions met end procedure</formula><p>Algorithm 2: Simulated Annealing inequation:</p><formula xml:id="formula_14">Z &lt; e −|f (x )−f (x)|/T (3.1) with Z = random number ∈ [0, 1)</formula><p>The most crucial part in parameterizing simulated annealing is the selection of an appropriate cooling scheme, which strongly affects convergence speed and result quality. The idea is to decrease temperature during the search process so that at the beginning uphill moves are accepted with a high probability which decreases step-by-step with the following iterations. This is analogous to the natural process of annealing metals or glass.</p><p>While temperature is relatively high the search is not biased in a strong way and uphill moves are accepted regularly, with descending temperature the search is biased towards classical iterative improvement and accepting uphill moves will become unlikely; Simulated annealing can therefore be understood as a mixture of a random walk and iterative improvement.</p><p>The cooling scheme defines the temperature T at each iteration t of the annealing process. It consists of the definition of a starting temperature T 0 , a function g(T, t) with which the actual cooling is computed and the number of iterations between updates of the temperature. The choice of T 0 can be made upon statistical data or bounds. The number of iterations at each temperature should allow the procedure to reach a stable state, which means that no more moves that only are allowed at this temperature should be necessary to reach a global optimal solution -physicists call this state an equilibrium. This number of iterations is usually set to a multiple of the size of the neighborhood. For updating the temperature no specific type of function is necessary, but commonly a monotone descend function is used, e.g. geometric cooling.</p><formula xml:id="formula_15">g(T, t) = T · α (3.2) s.t. α &lt; 1</formula><p>The advantages of simulated annealing are that it is one of the best studied metaheuristics existing. For example it is proven that under certain conditions, e.g. infinite runtime, simulated annealing converges to a global optimum (Henderson and Jacobson <ref type="bibr" target="#b30">[21]</ref>). Simulated annealing is easy to implement and can be adopted to a wide range of applications, although for good results often long runtimes are needed.</p><p>Simulated annealing is subject of continued research. Some of the more recent trends to improve practical performance are advanced cooling schemes including non-monotonic cooling (reheating), dynamic cooling, deterministic neighborhood exploration, parallelization and hybridization with for example genetic algorithms or GRASP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Tabu Search</head><p>The elementary ideas of tabu search (TS) were first introduced by Glover <ref type="bibr" target="#b25">[16]</ref> in 1986. Tabu search is one of the most cited and applied metaheuristics in the field of combinatorial optimization problems. In its basic version, described in Algorithm 3 on the next page, tabu search performs a best improvement local search (see Sec- tion 3.1 on page 19) and additionally uses a short term memory, which allows to escape from local optima and avoids cycles during exploration of the search space. This short term memory is implemented as a tabu list that remembers recently vis- ited solutions and forbids moves towards them. The neighborhood of the current solution is restricted to solutions that do not belong to the tabu list, the resulting set is the so-called allowed set.</p><p>Similar to other metaheuristic methods an initial solution is generated randomly or with a construction heuristic, the tabu list T L is initialized with the empty set. At each iteration of the search process the best solution of the allowed set of the neighborhood of the current solution is selected as new current solution and added to the tabu list; an element of the tabu list is removed from it; usually the selection of this element is based on recency, i.e. removal in FIFO order. An essential property</p><formula xml:id="formula_16">procedure Basic Tabu Search s ← GenerateInitialSolution() x ← s T L ← ∅ repeat X ← part of N (x) that does not violate T L x ← best solution ∈ X add x to T L remove elements older than t L iterations from T L x ← x if f (x) &lt; f (s) then s ← x end if until termination conditions met end procedure</formula><p>Algorithm 3: Basic Tabu Search of this process is that it allows to select new solutions with a worse solution quality than the current solution, because the search must not stop when it finds the first local optimum.</p><p>An important parameter is the length of the tabu list (tabu tenure). Small tabu tenures allow the process to concentrate on small areas of the search space. On the other side, large tabu tenures will forbid the process to revisit more solutions and thus a better exploration of the entire search space is enforced. The tabu tenure can be varied during the search process to improve the robustness of the algorithm and quality of results. Robust tabu search (see Taillard <ref type="bibr" target="#b50">[41]</ref>) changes the tabu list length randomly during the search between a mininum and maximum size, while reactive tabu search (see Battiti and Tecchiolli <ref type="bibr">[3]</ref>) increases the tabu tenure if there is evidence that some solutions are visited repeatedly. As a result the diversification of the process is increased, while the tabu tenure is decreased if there is no further improvement, which intensifies the search process.</p><p>However, the major problem of this basic tabu search algorithm is that it stores complete solutions in its short term memory. Managing tabu lists is thus inefficient because they make exhaustive use of memory and it takes significant computational effort to deal with them. Therefore, instead of storing complete solutions only tabu attributes are typically stored. These attributes characterize a performed move.</p><p>E.g. in case of the traveling salesman problem when a 2-opt move is performed the two removed edges or alternatively the two newly introduced edged may be stored as tabu attributes, and every solution that is generated using this attributes does not qualify for the allowed set, it is tabu. Because more than one attribute can be defined, a tabu list is introduced for each of these attributes.</p><p>This new type of tabu lists is much more effective, although it raises a new problem. With forbidding an attribute as tabu, typically more than one solution is declared as tabu. Some of these solutions that must now be avoided might be of excellent quality and have not yet been visited. To overcome this problem, aspiration criteria are introduced which allow to override the tabu state of a solution and thus include it in the allowed set. A commonly used aspiration criterion is to allow solutions which are better than the currently best known solution. A sketch of the procedure summarizing the above techniques is provided in Algorithm 4.</p><formula xml:id="formula_17">procedure Tabu Search s ← GenerateInitialSolution() x ← s T L 1 . . . T L n ← ∅ repeat X ← part of N (x) that does not violate T L 1 . . . T L n or satisfies at least one aspiration criterion x ← best solution ∈ X add x to T L 1 . . . T L n remove elements older than t L iterations from T L 1 . . . T L n x ← x if f (x) &lt; f (s) then</formula><p>s ← x end if until termination conditions met end procedure Algorithm 4: Tabu Search Additionally to the above described tabu lists, which represent a short term mem- ory, other ways of taking advantage from information about the search history are possible. Every piece of information collected during the search process can be use- ful. This long term memory can be structured regarding to four principles: recency, frequency, quality and influence. A recency-based memory records for each solution, or attribute, the most recent iteration it was considered in, while frequency-based memory counts how many times each solution (attribute) has been visited. This information identifies the subset of the search space where the process stayed for a longer number of iterations or where it only examined a limited amount of solutions, so it is useful to control the diversification of the search process. The information regarding quality can be used to determine good solution attributes, which can be integrated in solution construction. Finally influence, a property regarding decisions during the search process, allows to identify the most critical decisions.</p><p>For further information the reader is encouraged to look at two articles by Fred Glover <ref type="bibr" target="#b26">[17,</ref><ref type="bibr" target="#b27">18]</ref>, which provide a good starting-point for deeper insight into tabu search and related methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Guided Local Search</head><p>Guided local search (GLS) is a metaheuristic that sits on top of another local search procedure. It modifies the landscape of the search space to guide the underlying heuristic method away from already encountered local optima. The roots of the GLS metaheuristic are in a neural-network based method called GENET (see Tsang and Wang <ref type="bibr" target="#b52">[43]</ref>) which is a constraint satisfaction resolution method.</p><p>As mentioned, GLS modifies the landscape of the search space, to guide the un- derlying local search method gradually away from known local optima. To accom- plish this it augments the objective function of the underlying local search procedure with penalties, which makes the known local optima less attractive (see <ref type="figure" target="#fig_29">Figure 3.1)</ref>. In Algorithm 5 on page 27 the basic guided local search procedure is described in pseudocode.</p><p>objective function Solution space <ref type="figure" target="#fig_29">Figure 3</ref>.1: Escaping a local optimum with GLS Guided local search applies the penalties to solution features which have to be defined. These features may be any property or characteristic that can be used to distinguish solutions; compare the tabu attributes of tabu search. E.g. in the case of the traveling salesman problem these features could be arcs between pairs of cities and in the case of the quadratic assignment problem facility-location assigments (see Voudouris and Tsang <ref type="bibr" target="#b53">[44]</ref> and Mills et al. <ref type="bibr" target="#b41">[32]</ref>). For each defined feature f i the following components must be provided:</p><p>• An indicator function I i (s) that indicates whether the feature f i is present in the current solution or not. • And finally p i , the penalty parameters, which are initialized with 0 for all features. The penalty parameters are used to penalize features that appear in local optima.</p><p>Given an objective function g(s), which maps each solution of the search space to a numeric value, GLS defines a new augmented objective function h(s) which will be used by the underlying local search procedure.</p><formula xml:id="formula_18">n h(s) = g(s) + λ · I i (s) · p i (3.4) i=1</formula><p>Updating the penalty values p i of the features when reaching a local optimum is the crucial task in guided local search. A common way to do this is to calculate a utility value U til(s, i) of a feature i at the current local optimum s:</p><formula xml:id="formula_19">U til(s, i) = I i (s) · c i (s) 1 + p i (3.5)</formula><p>The penalty values of the features with maximimum utility value will be incre- mented. Then, local search is applied again with the updated penalties and changed augmented objective function.</p><p>The higher the costs c i (s) the higher the utility of the feature. The costs are scaled by the penalty value to permit the search process from being totally cost driven by taking the search history into account. A problem is that during the search process, where more and more features are penalized, the landscape of the search space could be distorted too much. This will make further exploration difficult and so in addition to increasing the penalty values a multiplication rule is applied regularly, which is smoothing the landscape again.</p><p>The λ parameter, also called regularization parameter, is used to specify the influence of the penalty values on the augmented objective function, which controls the diversity of the search process. With increasing λ the diversification will increase, too. The right choice of λ is crucial. This, however, must be done individually for each problem, because it is specific to the used objective function g(s). The difference ∆h of the values of the augmented objective function between two consecutive moves helps to understand this.</p><formula xml:id="formula_20">n ∆h = ∆g + λ · ∆I i · p i (3.6) i=1</formula><p>If the regularization parameter λ is large enough the inner local search procedure will solely remove the penalized features and the information regarding penalty values will fully determine the path of the search process. In contrast if, λ is to small the local search procedure will ignore the penalty values and it will not be able to escape from local optima. A good choice of λ is therefore in the same order of magnitude as ∆g and the resulting moves will aim at the combined objective, which is to improve the solution and to remove penalized features from the generated solutions. A common solution for this problem is to introduce a α parameter which is used to tune the now dynamically computed λ parameter, taking into account information about the problem instance. The advantage of this method is that once α is tuned well enough it can be used for many problem instances (see Voudouris and Tsang <ref type="bibr" target="#b53">[44]</ref>).</p><formula xml:id="formula_21">procedure Guided Local Search s ← GenerateInitialSolution() for i = 1, . . . , n do p i ← 0 end for repeat s ← LocalSearch(s,g + λ · n i=1 I i · p i )</formula><note type="other">for all features i with maximum utility U til(s, i) do p i ← p i + 1 end for until termination conditions met end procedure</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 5: Guided Local Search</head><p>Here only the main concepts of guided local search are described but many addi- tional ideas and improvements where proposed and applied successfully in different applications such as Fast GLS. Also several other refinements of the algorithm are possible such as e.g. iterative penalty value updates (Voudouris and Tsang <ref type="bibr" target="#b51">[42]</ref> and <ref type="bibr" target="#b54">[45]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Greedy Randomized Adaptive Search Proce- dure</head><p>The Greedy Randomized Adaptive Search Procedure (see Feo and Resende <ref type="bibr" target="#b20">[11,</ref><ref type="bibr" target="#b21">12]</ref>) is a simple but powerful metaheuristic that combines a constructive heuristic with local search. The basic structure of GRASP is outlined in Algorithm 6 on the following page. GRASP is an iterative multi-start procedure which consists of two phases, the construction phase builds a feasible solution, whose neighborhood is explored to find a local optimum in the subsequent local search phase. The best solution found in any iteration is returned as final result of the search process.</p><formula xml:id="formula_22">procedure GreedyRandomizedAdaptiveSearchProcedure repeat s ← GreedyConstructSolution() s ← LocalSearch(s ) if f (s ) &lt; f (s) then s ← s</formula><p>end if until termination conditions met end procedure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 6: Greedy Randomized Adaptive Search Procedure</head><p>The construction phase itself, outlined in Algorithm 7 on the next page, is char- acterized by two major properties: a dynamic constructive heuristic and random- ization. It is assumed that a solution consists of a subset of components, analogous to Section 3.4 on page 25 where these components could be used as GLS features. During the construction phase the solution is put together step-by-step, adding a new component in each iteration. The selection of the new component is done at random out of the restricted candidate list (RCL). It is essential that the construc- tion heuristic is dynamic, which means that the score for each solution component is evaluated depending on the current partial solution. In contrast static construc- tion heuristics assign a score to each solution component prior to the construction process.</p><p>The most critical part of the GRASP construction phase is the BuildRestrict- edCandidateList procedure, since it determines the strength of the heuristic bias. An incremental cost c(e) is associated with the inclusion of a component e ∈ CL into the currently constructed solution. Further at each iteration let c min and c max be the smallest and the largest incremental costs and subsequently the restricted candidate list is made up by the most promising components e ∈ CL, i.e. with the best incremental costs c(e).</p><p>An easy solution for this problem is to limit the RCL by the number of its elements. The list is made up by k components with the best incremental costs c(e), where k is a parameter which has to be carefully tuned. In its extremes k is either set equal to 1, resulting in a construction procedure which degenerates to a deterministic greedy heuristic, because only the best element at each iteration would be considered for the RCL. If k = n, where n is the size of CL, i.e the number of possible components, the construction is done completely at random.</p><p>On the other side the restricted candidate list can be limited by the quality of the components. Therefore a threshold parameter α ∈ [0, 1] is associated with the RCL. In both cases k and respectively α are important parameters which strongly determine the sampling of the search space and hence the quality of the resulting solutions. It is essential to the success of GRASP that the most promising regions of the solution space are sampled during the construction phase. Also it is important that the constructed solutions belong to basins of attraction of different local optima to ensure sufficient diversification. The first condition can be achieved by a good choice of the construction heuristic and its parameters. For the second condition an appropriate choice of the construction heuristic and the subsequent local search are the key to success.</p><p>In the given description of the GRASP metaheuristic memory in terms of history was not mentioned. This is one of the reasons why GRASP is often outperformed by other metaheuristics. However, due to its simple concept GRASP is easy to implement for many applications. For example, applications exist for the set covering and maximum independent set problem by Feo and Resende <ref type="bibr" target="#b21">[12]</ref> or the quadratic assignment problem by Li et al. <ref type="bibr" target="#b35">[26]</ref>. Also the iterations for creating candidate solutions usually are fast and so GRASP is able to provide good quality solutions in a short amount of time.</p><p>To improve the performance of GRASP several techniques are possible. As men- tioned above the construction phase, especially the creation of the restricted can- didate list, is critical. Some enhancements address this problem. With Reactive GRASP the RCL parameter α is not constant; in each iteration it is selected from a discrete sequence <ref type="bibr" target="#b46">[37]</ref>, yielding in a more robust algorithm. Other methods include a biased selection of new elements from the RCL, e.g. with a probability proportional to 1/c(e). Parallelization can also be easily applied to GRASP <ref type="bibr" target="#b47">[38]</ref>.</p><p>Current research trends show that GRASP can gain a great performance boost if it is used in a hybrid manner. So it is possible to use greedy constructed solutions as starting population within evolutionary algorithms. The use of simulated annealing or tabu search within GRASP has been applied successfully, too.</p><p>Not even the gods fight against necessity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simonides</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 4 Requirements</head><p>At the beginning of this master thesis the basic idea was to extend the existing EAlib <ref type="bibr" target="#b44">[35]</ref> with some additional metaheuristics, since EAlib at that time only contained evolutionary algorithms. The EAlib is intended to be a problem-independent C++ library suiteable for the development of efficient metaheuristics for combinatorial optimization. It is developed at the Institute of Computergraphics and Algorithms, Vienna University of Technology, Austria since 1999.</p><p>This chapter is structured into a description of the functional, design and usability requirements that were stated initially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Functionality</head><p>Before we start off, a summary of the functionality that EAlib provided already is given. As mentioned, EAlib included initially classes for evolutionary algorithms (EA). In particular classes that provide a generic framework for a generational EA, a steady state EA and an EA using the island model were implemented. Some supporting classes designed for populations and subpopulations, chromosomes, i.e. solutions, parameter handling and logging were provided, too. For demonstration purposes an implementation of the simple ONEMAX problem is also included.</p><p>As mentioned the primary goal is to enhance EAlib with classes that provide a framework for some commonly known metaheuristics. After some consideration we selected the following five:</p><p>• Local Search</p><formula xml:id="formula_23">• Simulated Annealing • Tabu Search • Guided Local Search • Greedy Randomized Adaptive Search Procedure</formula><p>Additionally an auxiliary more complex example problem should be implemented, for which we chose the already described quadratic assignment problem. Another important task is to enhance the existing parameter handling mechanism, because EAlib initially only featured a global parameter namespace.</p><p>In the following we describe in detail the functional requirements on the individ- ual components of the implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local Search</head><p>An iterative improvement algorithm as described in Section 3.1 on page 19 should be developed. Therefore the standard step functions random neighbor, next improve- ment and best improvement are required too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulated Annealing</head><p>The implementation of the simulated annealing algorithm should be straightforward. It should feature geometric as standard scheme, and the acceptance probability of down hill moves is to be calculated with the Metropolis criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tabu Search</head><p>The main features desired for tabu search are handling of an arbitrary number of tabu lists for different purposes. Due to the requirement for tabu attributes are to be used, of course support of aspiration criteria must be provided too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Guided Local Search</head><p>The requirements for the GLS implementation are straightforward. An appropriate mechanism for feature evaluation is needed. Additionally it is desired that the λ GLS parameter is automatically tuned, utilizing user provided α parameter and the size of the current instance, as described in Section 3.4 on page 25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Greedy Randomized Adaptive Search Procedure</head><p>GRASP has not many requirements, a simple construction heuristic must be pro- vided and the underlying local search algorithm should be selectable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example Problem</head><p>Besides the actual implementation of the generic algorithms an example problem has to be addressed. It serves two different purposes, at first it should of course show the possible potential of the used metaheuristics and secondly it should act as a template for developing other applications with EAlib. But of course demonstrating the benefits of a generic implementation of metaheuristic algorithms, like we did in this master thesis, is also one of the aims to be achieved.</p><p>To fulfill this requirements certain aspects have to be considered:</p><p>• it must be a combinatorial optimization problem, since EAlib is designed for this type of problems,</p><p>• computational and pratical hard to solve</p><p>• practical relevance of the problem</p><p>• existence of compareable results</p><p>• existence of standard instancances for testing purposes</p><p>• well known</p><p>• easy understandable problem structure</p><p>• adequate to fulfill demonstration purposes</p><p>Initially we considered three proplems, maximum satisfiability, quadratic assign- ment and glass cutting. The latter one was droppen early because it is too complex for use as a demonstraton problem. As noted, finally the quadratic assignment problem was selected.</p><p>In particular the QAP implementation must feature all algorithms with their specialities. I.e. appropriate step functions, tabu attributes, features for guided local search and a construction heuristic are needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter Handling</head><p>The initial version of EAlib only featured one global parameter namespace in an application. Although this concept is simple and robust the major drawback of it is, that hierarchical parameter settings are not possible. This is not satisfactory when for example nested algorithms, like guided local search or GRASP which incorporate another inner local search algorithm, or other advanced methods are used. It is obvious that the inner local search should be parametrised without tampering the parameter settings of the outer algorithm.</p><p>Apparently the extended parameter handling has to ensure compatibility with existing applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Design</head><p>Building a problem independent library is a complex task and many decisions are not obvious at hand. Therefore designing such a library is a sophisticated task to acccomplish. Though this master thesis is based on an existing library and so many decisions are somewhat constrainted.</p><p>Special attention has to paid for the design of the specialities of the individual algorithms, because they should not interfer each another, but as much as possible of the original ideas should be realised. To accomplish this special functionality is to be declared in a separate interface class which must be inherited if a class implements it. Examples for such interfaces are:</p><p>• augmented objective values</p><p>• construction heuristics</p><p>• features</p><p>• tabus</p><p>• tabulists</p><p>The use of common coding patterns is also encouraged, to make live easier for future changes and enhancements and to help developers understanding the source- code. For example functionality should be divided in reasonable methods within a particular class to ease customizations by users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Usability</head><p>The EAlib is designed to help developing metaheuristics for combinatorial optimiza- tion problems. Therefore it is important that the user-visible part of the desired EAlib extensions meet some fundamental requirements which are summarised here:</p><p>• easy to learn and clear programming interface</p><p>• good documentation, at best with an C++ language integrated tool like doxy- gen</p><p>• support for basic features included Work saves us from three great evils: boredom, vice and need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Voltaire</head><p>Chapter 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation</head><p>In this chapter a detailed description of our implementation is provided. At first a in-depth look on the internals is given in Section 5.2 on page 37 and afterwards an usercentric description of the interface and a guide for using the new classes is give in Section 5.3 on page 46.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overview</head><p>In <ref type="figure">Figure 5</ref>.1 on the next page an instant overview of the most important EAlib classes is given in UML syntax. The figure shows the how the classes are related to each other by inheritance, realization or an other dependency.</p><p>As depicted in the EAlib class overview the most important base classes are ea base and chromosome, where ea base is the top level base class for all algorithms, for both evolutionary and local search alike algorithms and chromosome is the top level base class for user provided problems, i.e. if a new application is to be created using EAlib it is required that the actual problem is implemented as a child class of chromosome and if necessary of some interfaces for to provide specialized methods for certain algorithms, e.g. guided local search. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Class reference</head><p>In this section we present the details of the implementation at hand. It is structured into a description of the individual classes and of the developers view of the new parameter handling mechanism. This is the base class for all chromosomes. In EAlib the problem definition is given by deriving a new class from chromosome and implement all the problem rele- vant methods in a proper way, i.e. all pure virtual methods have to be implemented. additionally depending on the desired use, other virtual methods have to be reim-plemented, e.g. save and load or selectRandomNeighbour and selectImprovement to enable local search alike algorithms.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Class chromosome</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Class ea advbase</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Class lsbase</head><p>This is the base class for local search alike algorithms, i.e. algorithms that are not population base. To be as much compatible as possible with population based algorithms, no additional data members are introduced, instead a fixed subset of the population, namely the first element, is considered to be used. The localSearch class implements the basic local search functionality as outlined in Section 3.1 on page 19. Additionally to its main base class lsbase it inherits the glsSubAlgorithm interface class, too, because we consider localSearch as embedded algorithm for guided local search. This class provides an application independent implementation of the simulated annealing metaheuristic (see Section 3.2 on page 20). The two main steps of the sim- ulated annealing process are subdivided into the accept and the cooling methods. As suggested, the Metropolis-Criterion and geometric cooling are utilized. Compared with local search, simulated annealing adds a temperature to the state; therefor the attribute T is introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Class localSearch</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5">Class simulatedAnnealing</head><p>In the overwritten version of the performGeneration method accept is called when a newly selected neighbour has an inferior objective value than the current solution. The cooling method is called accordingly to the sacint parameter.  The tabuSearch class offers a basic tabu search metaheuristic (see Section 3.3 on page 22). It utilizes a single tabulist and contained tabu attributes are considered as tabu. To overcome the problem of prohibiting a solution that is the best known sofar, a default aspiration criterion is implemented, too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.6">Class tabuSearch</head><p>Chromoses used in combination with tabu search have to inherit the tabuProvider interface class and should therefore take care of the embodied tabulists appropriately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.7">Class guidedLS</head><p>This class provides a guided local search algorithm (see Section 3.4 on page 25), which can only be used in combination with a chromosome class that implements the featureProvider interface; the embedded algorithm has to be derived from glsSub- Algorithm class. This is necessary to ensure all involved classes are well prepared with respect to the requirements of guided local search.</p><p>Statistics of the embedded algorithms are summarized, whereas the generation counter is threated individually to avoid sideeffects related to termination criteria and penalty resets. To provide a population for the embedded algorithm an additional population is created by using the existing chromosomes as a template. This ensures that running the embedding algorithm has no hidden side-effects. The GRASP class implements the greedy randomized adaptive search procedure metaheuristic (see Section 3.5 on page 27). It can only use chromosome derviates that additionally implement the gcProvider interface, because the used chromsomes are required to provide a greedy construction heuristic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.8">Class GRASP</head><p>Analogous to guided local search an additional population is created to be used by the embedded algorithm to circumvent possible side-effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.9">Class feature</head><p>As mentioned, the guided local search metaheuristic requires the definition of fea- tures, i.e. a method to identify if a feature is present in a given solution. This class is an abstract base for those problem dependent feature classes, that handle the iden- tification of the features and their penalization. Although only one feature object is used by the guidedLS class, it is possible to use several different types of features. However, due to this design the, it is very simple to access the features.  This abstract class provides an interface for classes whose objects are used as elements of a tabulist. It is important that the methods equals and hashvalue are implemented in a proper way, because they are invoked by an internal hashing array object of the tabulist, which requires this to methods. So tabus which should be considered matching need to return equal hashvalues and true for the equals method. Vice versa tabus which should not be considered as matching should at best return different hashvalues and false for the equals method. If equal hashvalues are return but the tabus are not matching this must be assured by the equals method. The write method is mainly used for debugging purposes during development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.10">Class tabuAttribute</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.11">Class tabulist</head><p>This class provides the basic tabulist functionality as used by the tabu search meta- heuristic. It is implemented using a hashing array to ensure efficient matching of existing tabu attributes. An additional queue is utilized in order to memorize the insertion sequence of the tabu attributes into the tabulist. The hashing array is uti- lized by the match method to decide if a given tabu attribute matches any existing  This classes represent moves in the neighbourhood of a chromosome. Their objects are can be used for example within incremental update of the objective value or as a base for tabu attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.12">Class move and childs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.13">Class qapChrom</head><p>This is the main problem specific class which coordinates the interaction of all QAP related classes, i.e. qapInstance, qapFeature and qapTabuAttribute. It is derived directly from chromosome and its main member is a vector containing indicies of facilities, which represents a quaratic assignment.</p><p>Mutation is performed by swapping two elements of the solution vector. A cycle crossover is implemented, too. Due to efficiency concerns the static data of the ac- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.14">Class qapInstance</head><p>An object of this class contains all necessary data for one particular quadratic assig- ment instance. It can load the instance data from a file whose filename is supplied as parametere to the constructor; if no filename is specified, the file to which the qapfile parameter is referring is loaded.</p><p>Auxilliary to the basic storage functionality the presorting stage of the con- struction heuristic used by qapChrom is done in this class for performance reasons. because the indices only need to be sorted once for an instance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.15">Class qapFeature</head><p>This is the specialized feature class for the quadratic assignment problem. The essential idea is that every possible facility-location pair is threated as a feature (see Section 3.4 on page 25). The penalties of these features can be efficiently stored in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.16">Class qapTabuAttribute</head><p>This tabu attribute is derived from the swapMove class. Two qapTabuAttributes are considered equal if the resulting chromosomes are equal when the moves they represent are applied to them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.17">Parameter handling</head><p>Originally the mechanism that EAlib used to deal with user provided parameter val- ues had some disturbing deficiencies. At first it was not possible to handle multiple values for one parameter, which are for example distinguished by an additional pa- rameter namespace or parameter key. This is especially a problem when one param- eter is used in a different context at different places within EAlib, e.g. a guided local As mentioned, a convenient solution for the first problem should maintain back- wards compatibility. At this point the way how values of parameters are access in EAlib helps very much, because the operator () is used when a parameter value is access. This operator method can be changed so that it fulfills our requirements appropriately. In particular a string parameter is added to the operator () method, which defaults to an empty string representing the already existing global param- eter namespace. When a different parameter key is specified the actual value is determined in the following order:</p><p>1. value associated with parameter key 2. global parameter value 3. default parameter value defined in the sourcecode An efficent storage container for these parameter key and value pairs is pro- vided by the hash map class, which is an SGI/GNU extension to the C++ standard template library.</p><p>The second problem is solved by adding a validator which can perform an unary check such as greater or equal (≥), greater (&gt;), equal (=), less (&lt;), less or equal (≤) or not equal ( =). Also the already existing range checking validator is extendend in way that bounds can be included or excluded from the allowed range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Usage</head><p>In this section we give a summary on how to use EAlib with new optimization problems. As mentioned the problem description has to be incorporated in a new class which is derived from the chromosome class or one of its already existing derviates depending which ever fits best the actual requirements.</p><p>However, inheriting class chromosome and implementing its pure virtual methods enables only the basic features. Therefore the new problem class is only useable by those algorithms that raise no specific requirements.</p><p>In EAlib this is solved by the introduction of interface classes for specific sets of features. The usage this interface classes is not limited to problem classes and hence it is used for algorithm classes, too. This concept has several advantages compared with collecting all methods in the class chromosome.</p><p>• The class chromosome is kept small and manageable,</p><p>• developers do not need to take care about features they are not interested in,</p><p>• new features can be integrated without affecting existing sourcecode.</p><p>If a class is providing the functionality of an interface class it has to be derived from it. The dynamic cast operator can be used to determine if a certain class implements an interface.</p><p>In the remainder of this section the already existings interface classes are de- scribed. This interface class is to be inherited by algorithm classes that provide an addi- tional term to the objective value of the chromosomes. The interface class glsSub- Provider is derived from this class an should be used if the implemented algorithm should be used nested into guided local search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Interface aObjProvider</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Interface tabulistProvider</head><p>An algorithm class that provides tabulists has to inherit this interface class, to indicate the incorporated chromosome objects that they should use the tabulists. Each chromosome class that is to be used in combination with guided local search has to inherit this interface class. An according class derived from class feature has to be realized, too. If a chromosome class inherits this interface class, this indicates that a greedy construction heuristic is implemented within. This is mandatory if the greedy ran- domized adaptive search procedure metaheuristic is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Interface gcProvider</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5">Interface tabuProvider</head><p>Chromosome classes which are able to deal with tabulists, that means they can fill them with tabu attributes and check if changes to them are currently tabu. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.6">Parameters</head><p>As mentioned EAlib provides a powerful parameter handling feature. These param- eters are used to configure the application. There exist parameters for a variety of domains, e.g.:</p><p>• algorithm configuration,</p><p>• problem specification,</p><p>• termination criteria,</p><p>• logging facility.</p><p>During this master thesis many parameters where added, some where changed in their semantics while others are only used. To illustrate what a user can customize a detailed overview of the parameters affecting this master thesis is given:</p><p>eamod The actual Algorithm to use. Currently the following choices are available:</p><p>• 0: steady-state EA,</p><p>• 1: generational EA,</p><p>• 2: steady-state EA with island model, Default: 0.5 glsri Interval of generations after which a penalty reset should be performed. If this value is 0 penalty resets will be disabled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Default: 0</head><p>sacint Specifies the number of iterations between two successive cooling steps, in other words, the number of iterations for which the simulated annealing process stays at a certain temperature level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Default: 1</head><p>satemp Specifies the starting temperature of the simulated annealing process.</p><p>Default: 1.0</p><p>tlsize Specifies the default size of newly created tabu lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Default: 10</head><p>qapfile This parameter specifies from which file the qapInstance object should read the actual instance data. The format of the problem data is the same as used by the QAPLIB <ref type="bibr" target="#b16">[7]</ref> instances:</p><formula xml:id="formula_24">n A B</formula><p>where n is the size of the instance, and A and B are either flow or distance matrix.</p><p>Default: "" saca Specifies the slope for the geometric cooling of the simulated annealing process.</p><p>g(T, t) = T * saca, 0 &lt; saca &lt; 1</p><p>Default: 0.95 graspa Alpha parameter for GRASP. It is used in the both stages of the QAP construction heuristic and controls the candidate restriction.</p><p>Default: 0.5</p><p>graspb Beta parameter for GRASP. It is used in the first stage of the QAP con- struction heuristic and controls the candidate restriction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Default: 0.1</head><p>By far the best proof is experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sir Francis Bacon</head><p>Chapter 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Results</head><p>To be able to compare the results from this different methods many internet available QAP instances are used, the probably most important collection of instances is the QAPLIB <ref type="bibr" target="#b16">[7]</ref>. Of special interest are problem instances with a known optimal solution, espe- cially if they are of larger size. To address this requirement some algorithms for construction of such instances where proposed, for example the by Palubeckis <ref type="bibr" target="#b43">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Test Cases</head><p>Because the larger quadratic assignment problem instances are computationally intractable, suboptimal algorithms such as the previous mentioned heuristics and metaheuristics are very popular and enjoy wide use. However, when dealing with new methods the quality and other properties such as robustness are important to know before they can be applied in daily business or other critical environments.</p><p>Usually new algorithms are tested on QAP instances from the QAPLIB (see Burkard, Karisch and Rendl <ref type="bibr" target="#b16">[7]</ref>) which is a public internet available collection of well known instances which allows to compare algorithms with each other. However, the problem when using especially larger benchmark problems from QAPLIB is that the optimal solutions are not known in general and one has to rely on lower bounds (see Section 2.3 on page 11).</p><p>To overcome this problem an other set of test cases can be used. Those are generated by special algorithms whose output are not only the matrices which the define the problem but also with a provable known optimal solution. It has been shown that instances generated by such algorithms are rather hard to solve for some metaheuristics, namely simulated annealing, tabu search and others <ref type="bibr" target="#b43">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Test Setup and Procedure</head><p>Our tests were performed on an ordinary desktop computer with GNU Linux in- stalled. The key data of this testing system is listed below:  We compiled EAlib and our test application for the quadratic assignment problem with all documented speed optimizations enabled, i.e. with switch -O4.</p><formula xml:id="formula_25">CPU Intel</formula><p>The test instances are all included in the already mentioned QAPLIB problem library. Each algorithm had to solve each instance 25 times, whereat each run had a time limit of five minutes to complete. The parameter settings for the particu- lar instances were made upon our knowledge which we obtained during preceeding experiments.</p><p>In the following tables the parameter settings for each algorithm are given which were not at their default value.</p><p>Parameter Value maxi 0 ttime 300 tgen 0 tcgen 5000 During the testruns of local search the tcgen parameter was set so that the search process could terminate if now improvement was made for 5000 iterations, which occurred quite of often. However, this parameter setting did not affect the achieved results significantly.</p><p>Parameter Value maxi 0 ttime 300 tgen 0    Additionally the tobj parameter has been set accordingly so that each testrun at which global optimum was found was terminated as soon as this global optimum was reached. This parameter setting did not change the results but sped up the experiments significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>For the comparison of the individual algorithms which were implemented and inter- pretation of the results four different charaterisic values are used, which in combi- nation give a good insight into the data obtained during the experiments.</p><p>• count of reached optima per problem instance. It is a measure for stability of the search process. For the overall statistics the sum of the particular instances is used,</p><p>• best objective value per problem instance indicates primarily the potential qual- ity of the search process,</p><p>• mean objective value is a measure for both quality and stability of an algorithm.</p><p>However, outliers can have great influence on its value,</p><p>• deviation of objective value indicates the robustness of the search process.</p><p>Obviously the latter three indicators can not be compared directly among differ- ent problem instances. Therefore they are presented in %-gap notation relative to the known global optimal solution. The %-gap of an objective value x relative to the global optimum opt is calculated as follows:</p><formula xml:id="formula_26">% − gap(x, opt) = x − opt opt × 100% (6.1)</formula><p>At first table 6.7 and accordingly figures 6.1 and 6.2 show the overall results of each algorithm for all test instances together, i.e. the sum of the number of reached optimas and the mean %-gap across all testruns. With the obtained results no definitive winning algorithm can be declared. Nevertheless the results show clearly which of the implemented methods are well suited to solve quadratic assignment problems.  Looking at the detailed results presented in follwing tables (6.8, 6.9, 6.10, 6.11 and 6.12) show that guided local search and GRASP are indeed clearly outperform- ing the other algorithms. This is not very surprising because both guided local search and GRASP include received considerable more problem dependent knowledge in their implementation than the other metaheuristics implemented during this master thesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>It is also worthy to mention that guided local search and GRASP were the only algorithms which were able to find distinct optimal solutions if the problem instance <ref type="figure">Figure 6</ref>.1: Overall mean %-gap has more than one. This capability is allegable with the major strengths of these algorithms. GLS gradually moves away from attractive solutions and therefor the embedded random local search is able to reach widespread areas of the search space. GRASP operates somewhat different, its strenghts lies the randomized greed heuris- tics which, in the optimal case, produces good starting solutions for the embedded local search procedure, which are distributed among the whole search space.</p><p>An other important feature that table 6.11 and 6.12 show is that the quality of the obtained solutions only decreases somewhat and so these solutions, altough not global optimal, can be adequate, too.</p><p>Tabu search also achieved good results in terms of the mean %-gap. However, it has reached significant fewer global optima than guided local search or GRASP and the deviation values indicate that the stability of the search process is somewhat deteriorated. A reason for this behavior is the fixed tabulist length which could cause a either a lockout of interesting regions of the search space when the tabulist is too long or the search process gets stuck around a local optimum when the tabulist is too short.</p><p>The results obtained with the simulated annealing metaheuristc were mixed. For some problem instances, especially instances from the bur collection and smaller instances from the other collections, simulated annealing clearly performs better than tabu search. On the other side some results, e.g. for instances from the chr collection, are not very satisfactory. This indicates that simulated annealing, in its <ref type="figure">Figure 6</ref>.2: Overall count of reached global optima traditional fashion, suffers from a worse stability of the obtained results when applied to the quadratic assignment problem, which could be an effect of the geometric cooling schedule. An improvement like reheating or an occasional perturbation phase might yield better solutions.</p><p>As expected local search only yields a few global optimal solutions but although no global optimal solution was found for many problem instances especially from the bur set the obtained solutions were nearly optimal. This implies that the chosen neighborhood structure is well suited for solving the quadratic assignment prob- lem which is certainly important for the other metaheuristics, too. However, it is somewhat surprising that only results for the instances from the chr set were very unsatisfactory.</p><p>The   In the following figures the results of the algorithms are grouped per test instance to show which instances were tackled best by what algorithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>After an elaborated introduction of the quadratic assignment problem and the im- plemented metaheuristics this thesis presented a generic library for metaheuristics and its application to the QAP.</p><p>The already existing foundations of the EAlib library have been improved to meet the requirements for the new generic metaheuristics. In particular interfaces classes have been introduced that allow fine grained modelling of new classes and support runtime queries for implemented features of specific components. Additionally the parameter handling mechanism has been extended with parameter groups that allow to denote different groups of parameter values for different components in EAlib.</p><p>With this enhanced EAlib generic versions of the local search, simulated an- nealing, tabu search, guided local search and greedy randomized adapetive search procedure metaheuristics have been implemented. The latter two algorithms also introduced an efficient way of handling an embedded algorithm.</p><p>All considered metaheuristics have then been applied to the quadratic assignment problem which showed that only some special parts need to be implemeted separately and most of the problem dependent sourcecode can be shared among all algorithms involved.</p><p>Of course there are many interesting and useful ideas and task left open for future work.</p><p>• implement more interesting algorithms like antcolony optimization, variable neighborhood search or iterated local search,</p><p>• add more "standard" features to the implemented algorithms, e.g. dynamic tabulist length, reheating, disturbance methods</p><p>• itegrate useful template chromosomes, e.g. a generic string chromosome,</p><p>• provide additional language bindings e.g. for Java and C#.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>List of Algorithms</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 . 1 :</head><label>21</label><figDesc>Figure 2.1: A quadratic assignment example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 . 2 :</head><label>22</label><figDesc>Figure 2.2: Original Backboard of the Steinberg Wiring Problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(</head><label></label><figDesc>Figure 2.3: Conceptual design of a large space antenna (from [33])</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Then at each iteration of the annealing process a solution s ∈ N (s) is randomly chosen and accepted as new current solution depending on f (s), f (s ) and T . The solution s replaces s as new current solution if f (s ) &lt; f (s) or, when</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>I</head><label></label><figDesc>i (s) = 1, solution s exhibits feature i 0, otherwise (3.3) • A cost function c i (s) describes the cost of having the feature f i present in the current solution s. These costs are often defined in analogy to the objective function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>procedure GreedyConstructSolution s ← ∅ while solution s is not complete do CL ← all possible extensions e of solution s RCL ←BuildRestrictedCandidateList(CL) e ← select an element of RCL at random s ← s ⊕ e end while end procedure Algorithm 7: GRASP construction phase All components whose costs c(e) are superior to the threshold value are included, so the condition c(e) ∈ [c min , c min + α · (c max − c min )] has to be fulfilled by each element of the RCL. In analogy to the previous RCL selection method the extreme cases exist, too, with α = 1 resulting in a pure greedy heuristic and α = 0 equivalent to a pure random construction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 5.1: EAlib class overview</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 5.2: Class chromosome</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>ea_advbase +pop: pop_base* +nGeneration: int +nSelections: int +nCrossovers: int +nMutations: int +nDupEliminations: int +nCrossoverDups: int +nMutationDups: int +nLocalImprovements: int +nTabus: int +nAspirations: int +nDeteriorations: int #genBest: int #timGenBest: double #tmpChrom: chromosome* +&lt;&lt;constructor&gt;&gt; ea_advbase(p:pop_base&amp;,pg:pstring&amp;="") +&lt;&lt;constructor&gt;&gt; ea_advbase(pg:pstring&amp;="") +&lt;&lt;destructor&gt;&gt; ~ea_advbase() +clone(p:pop_base&amp;,pg:pstring&amp;=""): ea_advbase* +run(): void +performGeneration(): void +performCrossover(p1:chromosome*,p2:chromosome*,c:chromosome*): void +performMutation(c:chromosome*,prob:double): void +terminate(): bool +replaceIndex(): int +replace(c:chromosome*): chromosome* +printStatistics(ostr:ostream&amp;): void +writeLogEntry(inAnyCase:bool=false): void +writeLogHeader(): void +getBestChrom(): chromosome* +getGen(): int +getGenBest(): int +getTimGenBest(): double +tournamentSelection(): int #checkPopulation(): void #saveBest(): void #checkBest() #perfGenBeginCallback(): void #perfGenEndCallback(): void</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 . 3 :</head><label>53</label><figDesc>Figure 5.3: Class ea advbase</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Figure 5.4: Class lsbase</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Figure 5.5: Class localSearch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Figure 5.6: Class simulatedAnnealing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>tabuSearch +tl_ne: tabulist* +&lt;&lt;constructor&gt;&gt; tabuSearch(p:pop_base&amp;,pg:pstring&amp;="") +&lt;&lt;constructor&gt;&gt; tabuSearch(pg:pstring&amp;="") +clone(p:pop_base&amp;,pg:pstring&amp;=""): ea_advbase* +performGeneration(): void +isTabu(t:tabuAttribute*): bool +aspiration(c:chromosome*): bool</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 5 . 7 :</head><label>57</label><figDesc>Figure 5.7: Class tabuSearch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>Figure 5.8: Class guidedLS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Figure 5.9: Class GRASP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Figure 5.10: Class feature</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>tabuAttribute #pgroup: string +&lt;&lt;constructor&gt;&gt; tabuAttribute(pg:pstring&amp;="") +&lt;&lt;destructor&gt;&gt; ~tabuAttribute() +equals(o:tabuAttribute&amp;): bool +hashvalue(): unsigned long int</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 5 . 11 :</head><label>511</label><figDesc>Figure 5.11: Class tabuAttribute</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>Figure 5.12: Class tabulist</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>Figure 5.13: Class move and childs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>Figure 5.14: Class qapChrom</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>Figure 5.15: Class qapInstance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>Figure 5.17: Class qapTabuAttribute</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>Figure 5.18: Interface aObjProvider</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>Figure 5.19: Interface tabulistProvider</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head></head><label></label><figDesc>Figure 5.21: Interface gcProvider</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>Figure 5.22: Interface tabuProvider</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>• 3 :</head><label>3</label><figDesc>generational EA with island model, • 4: simple randomized local search, • 5: simulated annealing, • 6: tabu search, • 7: greedy randomized adaptive search procedure, • 8: guided local search. Default: 0 maxi Should be maximized? True if maximization, false for minimization. Default: 1 mvnbop Neighbour selection function to use • 0: random neighbour, • 1: next improvement, • 2: best improvement. Default: 0 tgen The number of generations until termination. Default: 100000 tcgen The number of generations for termination according to convergence. Default: 0 tobj The objective value for termination when tcond==2. Default: 0 ttime Specifies the amount of time the algorithm is allowed to run in user-space. Default: 0 glsa Tuning parameter for the influence of penalties in guided local search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 6 . 3 :</head><label>63</label><figDesc>Figure 6.3: Mean %-gap for bur Instances</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table of Contents</head><label>of</label><figDesc></figDesc><table>1 Introduction 
5 
1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 
1.2 Combinatorial Optimization and Metaheuristics . . . . . . . . . . . . 5 
1.3 Guide to the thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 5.2.3 Class lsbase . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 
5.2.4 Class localSearch . . . . . . . . . . . . . . . . . . . . . . . . . 39 
5.2.5 Class simulatedAnnealing . . . . . . . . . . . . . . . . . . . . 39 
5.2.6 Class tabuSearch . . . . . . . . . . . . . . . . . . . . . . . . . 40 
5.2.7 Class guidedLS . . . . . . . . . . . . . . . . . . . . . . . . . . 40 
5.2.8 Class GRASP . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 
5.2.9 Class feature . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 
5.2.10 Class tabuAttribute . . . . . . . . . . . . . . . . . . . . . . . . 42 
5.2.11 Class tabulist . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 
5.2.12 Class move and childs . . . . . . . . . . . . . . . . . . . . . . 43 
5.2.13 Class qapChrom . . . . . . . . . . . . . . . . . . . . . . . . . 43 
5.2.14 Class qapInstance . . . . . . . . . . . . . . . . . . . . . . . . . 44 
5.2.15 Class qapFeature . . . . . . . . . . . . . . . . . . . . . . . . . 44 
5.2.16 Class qapTabuAttribute . . . . . . . . . . . . . . . . . . . . . 45 
5.2.17 Parameter handling . . . . . . . . . . . . . . . . . . . . . . . . 45 
5.3 Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 
5.3.1 Interface aObjProvider . . . . . . . . . . . . . . . . . . . . . . 47 
5.3.2 Interface tabulistProvider . . . . . . . . . . . . . . . . . . . . 47 
5.3.3 Interface featureProvider . . . . . . . . . . . . . . . . . . . . . 48 
5.3.4 Interface gcProvider . . . . . . . . . . . . . . . . . . . . . . . 48 
5.3.5 Interface tabuProvider . . . . . . . . . . . . . . . . . . . . . . 48 
5.3.6 Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 

6 Experimental Results 
52 
6.1 Test Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 
6.2 Test Setup and Procedure . . . . . . . . . . . . . . . . . . . . . . . . 53 
6.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 

7 Conclusions 
66 

List of Algorithms 
67 

List of Figures 
68 

List of Tables 
69 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 6 .1: System setup</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 .2: Parameter settings for Local Search</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 .</head><label>6</label><figDesc>3: Parameter settings for Simulated Annealing For simulated annealing the parameters controlling the temperature schedule were set to estimated values dependig on the size of the problem instance to solve and the order of magnitude of the corresponding objective value.</figDesc><table>Parameter Value 
maxi 
0 
mvnbop 
2 
ttime 
300 
tgen 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 6 .4: Parameter settings for Tabu Search</head><label>6</label><figDesc></figDesc><table>The parameter tlsize which controls the length of the tabulist was set depending 
on the actual problem instance. The value chosen was in order of magnitude of the 
size of instance to solve. 

Parameter Value 
glsri 
5000 
maxi 
0 
ttime 
300 
tgen 
0 
sub.eamod 
4 
sub.ttime 
0 
sub.tcgen 
500 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 .5: Parameter settings for Guided Local Search</head><label>6</label><figDesc></figDesc><table>Parameter Value 
maxi 
0 
ttime 
300 
tgen 
0 
sub.eamod 
4 
sub.ttime 
0 
sub.tcgen 
500 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 .6: Parameter settings for GRASP</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 .7: Overall results</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 6 .8: Local Search results</head><label>6</label><figDesc></figDesc><table>Optimum 
%-gap 
Instance absolute count Best Mean Deviation 
bur26a 
5426670 
1 0.00 
0.14 
0.05 
bur26b 
3817852 
7 0.00 
0.14 
0.09 
bur26c 
5426795 
2 0.00 
0.03 
0.05 
bur26d 
3821225 
1 0.00 
0.03 
0.08 
bur26e 
5386879 
6 0.00 
0.01 
0.01 
bur26f 
3782044 
1 0.00 
0.09 
0.14 
bur26g 
10117172 
2 0.00 
0.02 
0.01 
bur26h 
7098658 
2 0.00 
0.06 
0.17 
chr12a 
9552 
18 0.00 
4.18 
7.74 
chr15a 
9896 
2 0.00 16.68 10.72 
chr20a 
2192 
0 7.21 33.85 50.55 
nug12 
578 
23 0.00 
0.61 
2.77 
nug14 
1014 
5 0.00 
3.66 
5.53 
nug15 
1150 
8 0.00 
1.84 
5.06 
nug20 
2570 
3 0.00 
2.44 
5.05 
nug25 
3744 
4 0.00 
2.93 
6.88 
nug30 
6124 
1 0.00 
2.58 
5.77 
tai10a 
135028 
23 0.00 
0.16 
0.56 
tai12a 
224416 
20 0.00 
0.62 
1.34 
tai15a 
388214 
1 0.00 
1.58 
0.93 
tai17a 
491812 
1 0.00 
1.75 
1.00 
tai20a 
703482 
1 0.00 
2.89 
2.83 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><head>Table 6 .9: Simulated Annealing results</head><label>6</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> Up to now no bound that features both advantages, tightness and computational cheapness has been discovered.</note>

			<note place="foot" n="1"> In alphabetical order.</note>

			<note place="foot" n="2"> A 2-opt move consists of removing two edges of a given solution and reconnect them in a different way.</note>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. .</forename><surname>Basic Tabu Search</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. .. .. .. 23</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">. .</forename><surname>Tabu Search</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. .. .. .. .. .. 24</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">15 2.3 Conceptual design of a large space antenna (from [33])</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. .. .. .. .. .. .. .. .. . ; . . . . ; . . .</forename></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. .. .. . ; .. .. .. .. .. .. .. .. .. .. .. .. 16</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
	<note>16 (b) Finite element model</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Class</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. 43 5.14 Class qapChrom. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . 44 5.15 Class qapInstance. .. .. .. .. .. .. .. .. .. .. .. .. .. .. 45 5.16 Class qapFeature. .. .. .. .. .. .. .. .. .. .. .. .. .. .. 45 5.17 Class qapTabuAttribute. .. .. .. .. .. .. .. .. .. .. .. .. 46 5.18 Interface aObjProvider. .. .. .. .. .. .. .. .. .. .. .. .. . 47 5.19 Interface tabulistProvider. .. .. .. .. .. .. .. .. .. .. .. . 48 5.20 Interface featureProvider. .. .. .. .. .. .. .. .. .. .. .. .. 48 5.21 Interface gcProvider. .. .. .. .. .. .. .. .. .. .. .. .. .. 48 5.22 Interface tabuProvider. .. .. .. .. .. .. .. .. .. .. .. .. . 49</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">.. .. .. .. .. .. .. .. .. .. .</forename><surname>Childs</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. 43 5.14 Class qapChrom. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . 44 5.15 Class qapInstance. .. .. .. .. .. .. .. .. .. .. .. .. .. .. 45 5.16 Class qapFeature. .. .. .. .. .. .. .. .. .. .. .. .. .. .. 45 5.17 Class qapTabuAttribute. .. .. .. .. .. .. .. .. .. .. .. .. 46 5.18 Interface aObjProvider. .. .. .. .. .. .. .. .. .. .. .. .. . 47 5.19 Interface tabulistProvider. .. .. .. .. .. .. .. .. .. .. .. . 48 5.20 Interface featureProvider. .. .. .. .. .. .. .. .. .. .. .. .. 48 5.21 Interface gcProvider. .. .. .. .. .. .. .. .. .. .. .. .. .. 48 5.22 Interface tabuProvider. .. .. .. .. .. .. .. .. .. .. .. .. . 49</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Overall Mean %-Gap</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. .. .. . 56</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Overall count of reached global optima</title>
		<author>
			<orgName type="collaboration">.. .. .. .. .. .. .. .. . 57</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">%-Gap</forename><surname>Mean</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. 63</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">. .</forename><surname>For Bur Instances</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. 63</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">%-Gap</forename><surname>Mean</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. 64</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>For Chr Instances</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. 64</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">%-Gap</forename><surname>Mean</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. 64</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>For Nug Instances</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. 64</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">53 6.2 Parameter settings for Local Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">%-Gap For</forename><surname>Mean</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. . 53 6.3 Parameter settings for Simulated Annealing. .. .. .. .. .. .. . 53 6.4 Parameter settings for Tabu Search. .. .. .. .. .. .. .. .. .. 54 6.5 Parameter settings for Guided Local Search. .. .. .. .. .. .. . 54 6.6 Parameter settings for GRASP. .. .. .. .. .. .. .. .. .. .. 54 6.7 Overall results. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. 55 6.8 Local Search results. .. .. .. .. .. .. .. .. .. .. .. .. .. . 58 6.9 Simulated Annealing results. .. .. .. .. .. .. .. .. .. .. .. 59 6.10 Tabu Search results. .. .. .. .. .. .. .. .. .. .. .. .. .. . 60 6.11 Guided Local Search results. .. .. .. .. .. .. .. .. .. .. .. 61 6.12 GRASP results. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . 62</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">.. .. .. .. .. .. .. .. .. . . ; .. .. .. .. .. .. .. .. .. .. .. .. .. . .</forename><surname>Tai Instances</surname></persName>
			<affiliation>
				<orgName type="collaboration">.. .. .. .. .. .. .. .. .. . 53 6.3 Parameter settings for Simulated Annealing. .. .. .. .. .. .. . 53 6.4 Parameter settings for Tabu Search. .. .. .. .. .. .. .. .. .. 54 6.5 Parameter settings for Guided Local Search. .. .. .. .. .. .. . 54 6.6 Parameter settings for GRASP. .. .. .. .. .. .. .. .. .. .. 54 6.7 Overall results. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. 55 6.8 Local Search results. .. .. .. .. .. .. .. .. .. .. .. .. .. . 58 6.9 Simulated Annealing results. .. .. .. .. .. .. .. .. .. .. .. 59 6.10 Tabu Search results. .. .. .. .. .. .. .. .. .. .. .. .. .. . 60 6.11 Guided Local Search results. .. .. .. .. .. .. .. .. .. .. .. 61 6.12 GRASP results. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . 62</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
	<note>65 List of Tables 6.1 System setup</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A New Bound for the Quadratic Assignment Problem Based on Convex Quadratic Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Anstreicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Brixius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="341" to="357" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Solving large quadratic assignment problems on computational grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Anstreicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Brixius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Goux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Linderoth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="563" to="588" />
			<date type="published" when="2002-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The reactive tabu search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tecchiolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ORSA Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="126" to="140" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Metaheuristics in combinatorial optimization: Overview and conceptual comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="268" to="308" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Solving quadratic assignment problems using convex quadratic programming relaxations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Brixius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Anstreicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization Methods and Software</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="49" to="68" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Steinberg Wiring Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Brixius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Anstreicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Sharpest Cut: The Impact of Manfred Padberg and His Work, M. Grötschel</title>
		<meeting><address><addrLine>Ed. SIAM</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Burkard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rendl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qaplib-A</surname></persName>
		</author>
		<ptr target="http://www.seas.upenn.edu/qaplib/" />
	</analytic>
	<monogr>
		<title level="j">Quadratic Assignment Problem Library. Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="391" to="403" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Approach to the Traveling Salesman Problem: An Efficient Simulation Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cerny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thermodynamical</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optimization Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="41" to="51" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Survey of the Quadratic Assignment Problem, with Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Commander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pardalos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Moreahead Electronic Journal of Applicable Mathematics</title>
		<imprint>
			<date type="published" when="2003-04" />
		</imprint>
	</monogr>
	<note>Submitted to</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The derivation of a greedy approximator for the KoopmansBeckmann quadratic assigment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 77-th Combinatorial Programming Conference</title>
		<meeting>the 77-th Combinatorial Programming Conference</meeting>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="page" from="55" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A probabilistic heuristic for a computationally difficult set covering problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Feo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G C</forename><surname>Resende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research Letters</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="67" to="71" />
			<date type="published" when="1989-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Greedy Randomized Adaptive Search Procedures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Feo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Resende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="133" />
			<date type="published" when="1995-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Exact Solution of the Quadratic Assignment Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Frazer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Computers and Intractability; A Guide to the Theory of NP-Completeness. A series of books in the mathematical sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>W.H. Freeman and Company</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimal and Suboptimal Algorithms for the Quadratic Assignment Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Gilmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="305" to="313" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Future paths for integer programming and links to artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">W</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Operations Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="533" to="549" />
			<date type="published" when="1986-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">W</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tabu Search-Part I. ORSA Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="190" to="206" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tabu Search-Part II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">W</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ORSA Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="4" to="32" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">of International series in operations research and management science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">W</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Kochenberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<meeting><address><addrLine>Boston Hardbound</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">57</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Polynomial approximation algorithms for the TSP and the QAP with a factorial domination number</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gutin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="2002-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">of International series in operations research and management science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Jacobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>F. W. Glover and G. A. Kochenberger</editor>
		<meeting><address><addrLine>Boston Hardbound</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="287" to="319" />
		</imprint>
	</monogr>
	<note>The Theory and Practice of Simulated Annealing</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Optimization by Simulated Annealing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Assignment Problems and the Location of Economic Activities. Economethica</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Koopmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="76" />
			<date type="published" when="1957-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The Hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Quadratic Assignment Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="586" to="599" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Greedy Randomized Adaptive Search Procedure for the Quadratic Assignment Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Pardalos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Resende</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quadratic assignment and related problems</title>
		<editor>P. M. Pardalos and H. Wolkowicz</editor>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1994" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="237" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">An analytical Survey for the Quadratic Assignment Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Loiola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M M</forename><surname>De Abreu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Boaventura-Netto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Querido</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A Beginner&apos;s Introduction to Iterated Local Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Lourenço</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">C</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MIC&apos;2001-Meta-heuristics International Conference</title>
		<meeting>MIC&apos;2001-Meta-heuristics International Conference<address><addrLine>Porto, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">of International series in operations research and management science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Lourenço</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">C</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>F. W. Glover and G. A. Kochenberger</editor>
		<meeting><address><addrLine>Boston Hardbound</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="321" to="353" />
		</imprint>
	</monogr>
	<note>Iterated Local Search</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">of International series in operations research and management science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Multi-Start</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Methods</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>F. W. Glover and G. A. Kochenberger</editor>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="355" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Equation of State Calculations by Fast Computing Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1088" to="1092" />
			<date type="published" when="1953-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Applying an extended Guided Local Search to the Quadratic Assignment Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P K</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ford</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="135" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Aerospace Applications of Integer and Combinatorial Optimization. NASA Technical Memorandum 110210</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Padula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kincaid</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename></persName>
		</author>
		<idno>23681-0001</idno>
		<imprint>
			<date type="published" when="1995-10" />
			<pubPlace>NASA, Langley Research Center, Hampton, Virginia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An Algorithm for Construction of Test Cases for the Quadratic Assigmnet Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Palubeckis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatica</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="281" to="296" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">EAlib 1.1-A Generic Library for Metaheuristics. Institute of Computer Graphics and Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Raidl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>Vienna University of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Bounds for the Quadratic Assignment Problem Using the Bundle Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rendl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sotirov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">of International series in operations research and management science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G C</forename><surname>Resende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>F. W. Glover and G. A. Kochenberger</editor>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="219" to="249" />
		</imprint>
	</monogr>
	<note>Greedy Randomized Adaptive Search Procedures</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Parallel Greedy Randomized Adaptive Search Procedures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G C</forename><surname>Resende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Ribeiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-12" />
		</imprint>
		<respStmt>
			<orgName>AT&amp;T Labs Research</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Rep. TD-67EKXH</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">P-Complete Approximation Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sahni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzales</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="555" to="565" />
			<date type="published" when="1976-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The Backboard Wiring Problem: A Placement Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Steinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="37" to="50" />
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust taboo search for the quadratic assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Taillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="443" to="455" />
			<date type="published" when="1991-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Fast Local Search and Guided Local Search and Their Application to British Telecom&apos;s Workforce Scheduling Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P K</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voudouris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-08" />
			<pubPlace>Colchester CO4 3SQ</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Essex</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Rep. CSM-246</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A Generic Neural Network Approach for Constraint Satisfaction Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P K</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Network Applications</title>
		<editor>J. G. Taylor</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Guided Local Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voudouris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Tsang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-08" />
			<pubPlace>Colchester, C04 3SQ, UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Essex</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Rep. CSM-247</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">of International series in operations research and management science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voudouris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>F. W. Glover and G. A. Kochenberger</editor>
		<meeting><address><addrLine>Boston Hardbound</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="185" to="217" />
		</imprint>
	</monogr>
	<note>Guided Local Search</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
